{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name WITS Cost is illegal; using WITS_Cost instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# np.random.seed(2018)\n",
    "\n",
    "m = 2 # dimension\n",
    "k_sq = 0.5\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "batch_size = 100\n",
    "x_stddev = 3\n",
    "activation_fn_1 = tf.nn.sigmoid\n",
    "activation_fn = tf.nn.relu\n",
    "num_units_1 = 150\n",
    "num_units_2 = 30\n",
    "decay = 1 - 1e-10\n",
    "\n",
    "test_averaging = 100\n",
    "num_test_intervals = 10 # how many intervals to divide the test space into\n",
    "num_test_points = num_test_intervals**m# how many test points across all spaces are evaluated\n",
    "\n",
    "# Allow a batch of values to work\n",
    "x0 = tf.placeholder(tf.float32, [None, m])\n",
    "z = tf.placeholder(tf.float32, [None, m])\n",
    "\n",
    "l1 = tf.layers.dense(\n",
    "  x0, num_units_1, activation=activation_fn_1, use_bias=True)\n",
    "l2 = tf.layers.dense(\n",
    "  l1, m, activation=activation_fn_1, use_bias=True)\n",
    "\n",
    "u1 = l2\n",
    "u1_cost = (tf.norm(u1)**2) / batch_size\n",
    "\n",
    "# The observed value for the second controller is the original controlled with noise\n",
    "x1 = x0 + u1\n",
    "y1 = x1 + z\n",
    "\n",
    "l3 = tf.layers.dense(\n",
    "  y1, num_units_2, activation=activation_fn, use_bias=True)\n",
    "l4 = tf.layers.dense(\n",
    "  l3, m, activation=activation_fn, use_bias=True)\n",
    "\n",
    "u2 = -l4\n",
    "x2 = x1 + u2\n",
    "\n",
    "u2_cost = (tf.norm(x2) ** 2) / batch_size\n",
    "wits_cost = (k_sq * u1_cost) + u2_cost\n",
    "\n",
    "adaptive_learning_rate = tf.placeholder_with_default(learning_rate, [])\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "  learning_rate=adaptive_learning_rate).minimize(wits_cost)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "tf.summary.scalar(\"WITS Cost\", wits_cost)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, value: 19.887954711914062\n",
      "step: 10, value: 12.185107231140137\n",
      "step: 20, value: 11.642644882202148\n",
      "step: 30, value: 11.573141098022461\n",
      "step: 40, value: 11.366171836853027\n",
      "step: 50, value: 11.644564628601074\n",
      "step: 60, value: 11.017277717590332\n",
      "step: 70, value: 10.490015983581543\n",
      "step: 80, value: 10.313693046569824\n",
      "step: 90, value: 10.222064018249512\n",
      "step: 100, value: 9.732610702514648\n",
      "step: 110, value: 9.16919231414795\n",
      "step: 120, value: 9.688143730163574\n",
      "step: 130, value: 10.044449806213379\n",
      "step: 140, value: 9.466249465942383\n",
      "step: 150, value: 9.241371154785156\n",
      "step: 160, value: 9.372459411621094\n",
      "step: 170, value: 9.46480941772461\n",
      "step: 180, value: 9.476212501525879\n",
      "step: 190, value: 9.452720642089844\n",
      "step: 200, value: 9.46340274810791\n",
      "step: 210, value: 9.028080940246582\n",
      "step: 220, value: 9.380175590515137\n",
      "step: 230, value: 9.671955108642578\n",
      "step: 240, value: 9.15774154663086\n",
      "step: 250, value: 8.83651351928711\n",
      "step: 260, value: 8.752248764038086\n",
      "step: 270, value: 9.353014945983887\n",
      "step: 280, value: 9.599313735961914\n",
      "step: 290, value: 10.425068855285645\n",
      "step: 300, value: 10.558438301086426\n",
      "step: 310, value: 10.717341423034668\n",
      "step: 320, value: 8.849226951599121\n",
      "step: 330, value: 7.891392230987549\n",
      "step: 340, value: 8.199947357177734\n",
      "step: 350, value: 8.002043724060059\n",
      "step: 360, value: 7.874564170837402\n",
      "step: 370, value: 7.880684852600098\n",
      "step: 380, value: 8.662347793579102\n",
      "step: 390, value: 9.183294296264648\n",
      "step: 400, value: 9.671087265014648\n",
      "step: 410, value: 9.623074531555176\n",
      "step: 420, value: 10.276934623718262\n",
      "step: 430, value: 9.965576171875\n",
      "step: 440, value: 10.36506462097168\n",
      "step: 450, value: 10.392803192138672\n",
      "step: 460, value: 10.51966381072998\n",
      "step: 470, value: 9.916102409362793\n",
      "step: 480, value: 10.26638412475586\n",
      "step: 490, value: 9.416313171386719\n",
      "step: 500, value: 9.606817245483398\n",
      "step: 510, value: 9.16189193725586\n",
      "step: 520, value: 9.746503829956055\n",
      "step: 530, value: 9.717292785644531\n",
      "step: 540, value: 9.428505897521973\n",
      "step: 550, value: 9.356839179992676\n",
      "step: 560, value: 9.870037078857422\n",
      "step: 570, value: 9.581463813781738\n",
      "step: 580, value: 8.943012237548828\n",
      "step: 590, value: 8.766648292541504\n",
      "step: 600, value: 7.95303201675415\n",
      "step: 610, value: 8.230619430541992\n",
      "step: 620, value: 7.750572681427002\n",
      "step: 630, value: 7.461057662963867\n",
      "step: 640, value: 7.63247013092041\n",
      "step: 650, value: 7.204108238220215\n",
      "step: 660, value: 7.177865505218506\n",
      "step: 670, value: 7.138660430908203\n",
      "step: 680, value: 6.858801364898682\n",
      "step: 690, value: 6.664458274841309\n",
      "step: 700, value: 6.647258758544922\n",
      "step: 710, value: 7.158044815063477\n",
      "step: 720, value: 7.250925540924072\n",
      "step: 730, value: 7.01444149017334\n",
      "step: 740, value: 7.00669002532959\n",
      "step: 750, value: 6.910552024841309\n",
      "step: 760, value: 7.335214138031006\n",
      "step: 770, value: 7.416595935821533\n",
      "step: 780, value: 7.319868564605713\n",
      "step: 790, value: 7.009589672088623\n",
      "step: 800, value: 7.296527862548828\n",
      "step: 810, value: 7.19091272354126\n",
      "step: 820, value: 6.53230094909668\n",
      "step: 830, value: 7.105184555053711\n",
      "step: 840, value: 6.781210899353027\n",
      "step: 850, value: 6.438185691833496\n",
      "step: 860, value: 6.549335479736328\n",
      "step: 870, value: 6.376317024230957\n",
      "step: 880, value: 6.375398635864258\n",
      "step: 890, value: 6.652437210083008\n",
      "step: 900, value: 6.5146484375\n",
      "step: 910, value: 6.15150260925293\n",
      "step: 920, value: 6.138980388641357\n",
      "step: 930, value: 6.242190837860107\n",
      "step: 940, value: 6.349055767059326\n",
      "step: 950, value: 5.9654645919799805\n",
      "step: 960, value: 6.5688252449035645\n",
      "step: 970, value: 6.157307147979736\n",
      "step: 980, value: 5.960118770599365\n",
      "step: 990, value: 6.620201110839844\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  uniq_id = \"/tmp/tensorboard-layers-api/\" + uuid.uuid1().__str__()[:6]\n",
    "  summary_writer = tf.summary.FileWriter(uniq_id, graph=tf.get_default_graph())\n",
    "  x_train = np.random.normal(size=epochs * batch_size * m, scale=x_stddev)\n",
    "\n",
    "  # Train for some epochs\n",
    "  for step in range(epochs):\n",
    "    x_batch = x_train[step: step + (batch_size * m)].reshape((batch_size, m))\n",
    "\n",
    "    # Noise has variance 1\n",
    "    z_batch = np.random.normal(size=(batch_size, m), scale=1)\n",
    "\n",
    "    _, val, summary = sess.run(\n",
    "      [optimizer, wits_cost, merged_summary_op],\n",
    "      feed_dict={x0: x_batch, z: z_batch,\n",
    "                 adaptive_learning_rate: learning_rate * (decay**step)})\n",
    "\n",
    "    if step % 10 == 0:\n",
    "      print(\"step: {}, value: {}\".format(step, val))\n",
    "      summary_writer.add_summary(summary, step)\n",
    "  \n",
    "\n",
    "  # Test over a continuous range of X\n",
    "  x0_test=np.array(np.meshgrid\n",
    "                   (np.linspace(-2*x_stddev, 2*x_stddev, num=num_test_intervals),\n",
    "                    np.linspace(-2*x_stddev, 2*x_stddev, num=num_test_intervals)))\n",
    "#   u1_test, u2_test, x1_test = np.zeros((m, num_test_points)), np.zeros((m, num_test_points)), np.zeros((m, num_test_points))\n",
    "  u1_test = np.array(np.meshgrid(np.zeros(num_test_intervals), np.zeros(num_test_intervals)))\n",
    "  u2_test = np.array(np.meshgrid(np.zeros(num_test_intervals), np.zeros(num_test_intervals)))\n",
    "  x1_test = np.array(np.meshgrid(np.zeros(num_test_intervals), np.zeros(num_test_intervals)))\n",
    "\n",
    "    \n",
    "  for i in range(num_test_intervals):\n",
    "    for j in range(num_test_intervals):\n",
    "        u1t, u2t, x1t = 0, 0, 0\n",
    "        for _ in range(test_averaging):\n",
    "          x0_current_test = np.array([x0_test[0,i,j], x0_test[1,i,j]])\n",
    "          u1tmp, u2tmp, x1tmp = sess.run(\n",
    "                [u1, u2, x1], # return these variables\n",
    "                feed_dict={x0: x0_current_test.reshape((1, 2)), z: np.random.normal(\n",
    "                  size=(1, 2), scale=1)})\n",
    "\n",
    "          u1t += u1tmp\n",
    "          u2t += u2tmp\n",
    "          x1t += x1tmp\n",
    "\n",
    "        u1_test[0, i,j], u1_test[1,i,j] = u1t[0,0] / test_averaging, u1t[0,1]/ test_averaging\n",
    "        u2_test[0, i,j], u2_test[1,i,j] = -u2t[0,0] / test_averaging, -u2t[0,1]/ test_averaging\n",
    "        x1_test[0, i,j], x1_test[1,i,j] = x1t[0,0] / test_averaging, x1t[0,1]/ test_averaging\n",
    "\n",
    "# l1, = plt.plot(x0_test, u1_test[0], label=\"U1 Test\")\n",
    "# l3, = plt.plot(x0_test, u2_test[0], label=\"U2 Test\")\n",
    "# plt.legend(handles=[l1, l3])\n",
    "# plt.title(\"{} Unit NN With Activation Fn {}\".format(\n",
    "#   str(num_units_1), str(activation_fn)))\n",
    "# # plt.savefig(\"figure_u_1.png\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.clf()\n",
    "# l2, = plt.plot(x0_test, x1_test[0], label=\"X1 Test\")\n",
    "# plt.title(\"{} Unit NN With Activation Fn {}\".format(\n",
    "#   str(num_units_1), str(activation_fn)))\n",
    "# plt.legend(handles=[l2])\n",
    "# # plt.savefig(\"figure_x_1.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u0_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-30e90c77a9f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu0_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'u0_test' is not defined"
     ]
    }
   ],
   "source": [
    "u_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
