Seed 132, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 7.273118495941162, Monte Carlo Cost: 3.3315069675445557
Epoch 2000, Train Cost 3.6349267959594727, Monte Carlo Cost: 1.5721312761306763
Epoch 3000, Train Cost 1.3037397861480713, Monte Carlo Cost: 0.8064424991607666
Epoch 4000, Train Cost 1.0819988250732422, Monte Carlo Cost: 0.7955058217048645
Epoch 5000, Train Cost 1.3214516639709473, Monte Carlo Cost: 0.8080389499664307
Epoch 6000, Train Cost 0.9638252258300781, Monte Carlo Cost: 0.796809196472168
Epoch 7000, Train Cost 1.4774320125579834, Monte Carlo Cost: 0.7840334177017212
Epoch 8000, Train Cost 1.1144819259643555, Monte Carlo Cost: 0.7678451538085938
Epoch 9000, Train Cost 0.8960217237472534, Monte Carlo Cost: 0.7584018707275391
Epoch 10000, Train Cost 1.3480770587921143, Monte Carlo Cost: 0.7477778196334839
Epoch 11000, Train Cost 1.5344822406768799, Monte Carlo Cost: 0.7369047999382019
Epoch 12000, Train Cost 1.2673625946044922, Monte Carlo Cost: 0.7302471995353699
Epoch 13000, Train Cost 1.4067174196243286, Monte Carlo Cost: 0.7214602828025818
Epoch 14000, Train Cost 1.5743926763534546, Monte Carlo Cost: 0.7120590209960938
Epoch 15000, Train Cost 1.5613301992416382, Monte Carlo Cost: 0.7050509452819824
Epoch 16000, Train Cost 1.7796440124511719, Monte Carlo Cost: 0.699238657951355
Epoch 17000, Train Cost 1.009929895401001, Monte Carlo Cost: 0.6940075159072876
Epoch 18000, Train Cost 1.2210171222686768, Monte Carlo Cost: 0.686111330986023
Epoch 19000, Train Cost 1.0520386695861816, Monte Carlo Cost: 0.6807542443275452
Epoch 20000, Train Cost 1.054901361465454, Monte Carlo Cost: 0.6778727769851685
Seed 132, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 20.531259536743164, Monte Carlo Cost: 14.386650085449219
Epoch 2000, Train Cost 18.825559616088867, Monte Carlo Cost: 10.258522033691406
Epoch 3000, Train Cost 13.105083465576172, Monte Carlo Cost: 8.073104858398438
Epoch 4000, Train Cost 12.976115226745605, Monte Carlo Cost: 6.83088493347168
Epoch 5000, Train Cost 10.25291633605957, Monte Carlo Cost: 6.049046993255615
Epoch 6000, Train Cost 13.274282455444336, Monte Carlo Cost: 5.594494342803955
Epoch 7000, Train Cost 16.938688278198242, Monte Carlo Cost: 5.264036178588867
Epoch 8000, Train Cost 11.513198852539062, Monte Carlo Cost: 5.1000075340271
Epoch 9000, Train Cost 12.692109107971191, Monte Carlo Cost: 4.962967872619629
Epoch 10000, Train Cost 16.215787887573242, Monte Carlo Cost: 4.880392074584961
Epoch 11000, Train Cost 13.395759582519531, Monte Carlo Cost: 4.805586814880371
Epoch 12000, Train Cost 9.7025728225708, Monte Carlo Cost: 4.746108055114746
Epoch 13000, Train Cost 12.814558029174805, Monte Carlo Cost: 4.7020134925842285
Epoch 14000, Train Cost 14.540760040283203, Monte Carlo Cost: 4.689111709594727
Epoch 15000, Train Cost 15.627626419067383, Monte Carlo Cost: 4.659848213195801
Epoch 16000, Train Cost 11.639508247375488, Monte Carlo Cost: 4.626273155212402
Epoch 17000, Train Cost 15.858024597167969, Monte Carlo Cost: 4.5724101066589355
Epoch 18000, Train Cost 10.748808860778809, Monte Carlo Cost: 4.547463417053223
Epoch 19000, Train Cost 12.843238830566406, Monte Carlo Cost: 4.536181926727295
Epoch 20000, Train Cost 14.727571487426758, Monte Carlo Cost: 4.505760669708252
Seed 132, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 17.52232551574707, Monte Carlo Cost: 12.828960418701172
Epoch 2000, Train Cost 16.932138442993164, Monte Carlo Cost: 12.799795150756836
Epoch 3000, Train Cost 16.064655303955078, Monte Carlo Cost: 12.771235466003418
Epoch 4000, Train Cost 18.7218017578125, Monte Carlo Cost: 12.742581367492676
Epoch 5000, Train Cost 22.077180862426758, Monte Carlo Cost: 12.713815689086914
Epoch 6000, Train Cost 19.354137420654297, Monte Carlo Cost: 12.685568809509277
Epoch 7000, Train Cost 25.180635452270508, Monte Carlo Cost: 12.657044410705566
Epoch 8000, Train Cost 25.646602630615234, Monte Carlo Cost: 12.629242897033691
Epoch 9000, Train Cost 19.593557357788086, Monte Carlo Cost: 12.601105690002441
Epoch 10000, Train Cost 24.702760696411133, Monte Carlo Cost: 12.573332786560059
Epoch 11000, Train Cost 21.281038284301758, Monte Carlo Cost: 12.545842170715332
Epoch 12000, Train Cost 23.1534423828125, Monte Carlo Cost: 12.517838478088379
Epoch 13000, Train Cost 21.336942672729492, Monte Carlo Cost: 12.490426063537598
Epoch 14000, Train Cost 27.74684715270996, Monte Carlo Cost: 12.463193893432617
Epoch 15000, Train Cost 17.546131134033203, Monte Carlo Cost: 12.436562538146973
Epoch 16000, Train Cost 22.996829986572266, Monte Carlo Cost: 12.409710884094238
Epoch 17000, Train Cost 26.588048934936523, Monte Carlo Cost: 12.382966041564941
Epoch 18000, Train Cost 23.932628631591797, Monte Carlo Cost: 12.356122016906738
Epoch 19000, Train Cost 28.562923431396484, Monte Carlo Cost: 12.329644203186035
Epoch 20000, Train Cost 24.40744972229004, Monte Carlo Cost: 12.303444862365723
Seed 132, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 7.657681941986084, Monte Carlo Cost: 3.374926805496216
Epoch 2000, Train Cost 3.9526748657226562, Monte Carlo Cost: 1.7416163682937622
Epoch 3000, Train Cost 1.3208541870117188, Monte Carlo Cost: 0.8144177198410034
Epoch 4000, Train Cost 1.0709651708602905, Monte Carlo Cost: 0.7800737023353577
Epoch 5000, Train Cost 1.307828426361084, Monte Carlo Cost: 0.7954088449478149
Epoch 6000, Train Cost 0.9478498101234436, Monte Carlo Cost: 0.7864018082618713
Epoch 7000, Train Cost 1.4440996646881104, Monte Carlo Cost: 0.774907112121582
Epoch 8000, Train Cost 1.1086902618408203, Monte Carlo Cost: 0.7601902484893799
Epoch 9000, Train Cost 0.8881561756134033, Monte Carlo Cost: 0.7516206502914429
Epoch 10000, Train Cost 1.3361320495605469, Monte Carlo Cost: 0.7418553233146667
Epoch 11000, Train Cost 1.5146234035491943, Monte Carlo Cost: 0.731778621673584
Epoch 12000, Train Cost 1.2609554529190063, Monte Carlo Cost: 0.7256649732589722
Epoch 13000, Train Cost 1.4028441905975342, Monte Carlo Cost: 0.7176175713539124
Epoch 14000, Train Cost 1.5593949556350708, Monte Carlo Cost: 0.7087357044219971
Epoch 15000, Train Cost 1.5533661842346191, Monte Carlo Cost: 0.7020633220672607
Epoch 16000, Train Cost 1.7534945011138916, Monte Carlo Cost: 0.6965846419334412
Epoch 17000, Train Cost 1.0093166828155518, Monte Carlo Cost: 0.6915979981422424
Epoch 18000, Train Cost 1.222800374031067, Monte Carlo Cost: 0.6840479373931885
Epoch 19000, Train Cost 1.051823377609253, Monte Carlo Cost: 0.6789134740829468
Epoch 20000, Train Cost 1.0495988130569458, Monte Carlo Cost: 0.6760317087173462
Seed 132, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 10.568120002746582, Monte Carlo Cost: 3.710280179977417
Epoch 2000, Train Cost 10.714902877807617, Monte Carlo Cost: 3.7654833793640137
Epoch 3000, Train Cost 7.807540416717529, Monte Carlo Cost: 3.8120291233062744
Epoch 4000, Train Cost 8.794147491455078, Monte Carlo Cost: 3.840769052505493
Epoch 5000, Train Cost 9.052355766296387, Monte Carlo Cost: 3.839534282684326
Epoch 6000, Train Cost 10.369002342224121, Monte Carlo Cost: 3.8464341163635254
Epoch 7000, Train Cost 13.94131088256836, Monte Carlo Cost: 3.8253657817840576
Epoch 8000, Train Cost 11.79570484161377, Monte Carlo Cost: 3.8311164379119873
Epoch 9000, Train Cost 9.734245300292969, Monte Carlo Cost: 3.8171465396881104
Epoch 10000, Train Cost 13.081844329833984, Monte Carlo Cost: 3.8127024173736572
Epoch 11000, Train Cost 10.794661521911621, Monte Carlo Cost: 3.800687074661255
Epoch 12000, Train Cost 9.4512300491333, Monte Carlo Cost: 3.7805092334747314
Epoch 13000, Train Cost 10.293850898742676, Monte Carlo Cost: 3.76808762550354
Epoch 14000, Train Cost 13.337250709533691, Monte Carlo Cost: 3.765048027038574
Epoch 15000, Train Cost 10.738195419311523, Monte Carlo Cost: 3.761850595474243
Epoch 16000, Train Cost 10.358229637145996, Monte Carlo Cost: 3.747720718383789
Epoch 17000, Train Cost 13.275038719177246, Monte Carlo Cost: 3.7256641387939453
Epoch 18000, Train Cost 9.675015449523926, Monte Carlo Cost: 3.7121098041534424
Epoch 19000, Train Cost 12.25343132019043, Monte Carlo Cost: 3.7078278064727783
Epoch 20000, Train Cost 12.249761581420898, Monte Carlo Cost: 3.696329355239868
Seed 132, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 11.341146469116211, Monte Carlo Cost: 4.888660907745361
Epoch 2000, Train Cost 12.069552421569824, Monte Carlo Cost: 4.883780002593994
Epoch 3000, Train Cost 9.171525955200195, Monte Carlo Cost: 4.879189491271973
Epoch 4000, Train Cost 10.455617904663086, Monte Carlo Cost: 4.874624729156494
Epoch 5000, Train Cost 10.144562721252441, Monte Carlo Cost: 4.8697686195373535
Epoch 6000, Train Cost 11.34991455078125, Monte Carlo Cost: 4.865138530731201
Epoch 7000, Train Cost 15.735831260681152, Monte Carlo Cost: 4.8601884841918945
Epoch 8000, Train Cost 12.984528541564941, Monte Carlo Cost: 4.85571813583374
Epoch 9000, Train Cost 11.202112197875977, Monte Carlo Cost: 4.850996494293213
Epoch 10000, Train Cost 15.024039268493652, Monte Carlo Cost: 4.846437454223633
Epoch 11000, Train Cost 12.75401782989502, Monte Carlo Cost: 4.841862678527832
Epoch 12000, Train Cost 11.01092529296875, Monte Carlo Cost: 4.837123870849609
Epoch 13000, Train Cost 12.21793270111084, Monte Carlo Cost: 4.832528114318848
Epoch 14000, Train Cost 15.530370712280273, Monte Carlo Cost: 4.828151702880859
Epoch 15000, Train Cost 12.918424606323242, Monte Carlo Cost: 4.823846817016602
Epoch 16000, Train Cost 12.21556282043457, Monte Carlo Cost: 4.819431781768799
Epoch 17000, Train Cost 15.58420181274414, Monte Carlo Cost: 4.814843654632568
Epoch 18000, Train Cost 11.630901336669922, Monte Carlo Cost: 4.8102545738220215
Epoch 19000, Train Cost 14.615333557128906, Monte Carlo Cost: 4.805860996246338
Epoch 20000, Train Cost 14.765158653259277, Monte Carlo Cost: 4.801476955413818
Seed 132, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.602365016937256, Monte Carlo Cost: 2.413132429122925
Epoch 2000, Train Cost 1.6961569786071777, Monte Carlo Cost: 0.7385687828063965
Epoch 3000, Train Cost 1.084561824798584, Monte Carlo Cost: 0.7312598824501038
Epoch 4000, Train Cost 0.9837215542793274, Monte Carlo Cost: 0.6711539030075073
Epoch 5000, Train Cost 1.179228663444519, Monte Carlo Cost: 0.6298856139183044
Epoch 6000, Train Cost 0.8024917244911194, Monte Carlo Cost: 0.6061707139015198
Epoch 7000, Train Cost 1.1193065643310547, Monte Carlo Cost: 0.5905782580375671
Epoch 8000, Train Cost 0.9349878430366516, Monte Carlo Cost: 0.5846036672592163
Epoch 9000, Train Cost 0.768986701965332, Monte Carlo Cost: 0.5825554132461548
Epoch 10000, Train Cost 1.073622226715088, Monte Carlo Cost: 0.5794131755828857
Epoch 11000, Train Cost 1.219448208808899, Monte Carlo Cost: 0.5794969201087952
Perturbing at epoch 11000
Epoch 12000, Train Cost 1.0914016962051392, Monte Carlo Cost: 0.6304452419281006
Epoch 13000, Train Cost 1.1532549858093262, Monte Carlo Cost: 0.6153165698051453
Epoch 14000, Train Cost 1.206153154373169, Monte Carlo Cost: 0.601040244102478
Epoch 15000, Train Cost 1.2169276475906372, Monte Carlo Cost: 0.589942216873169
Epoch 16000, Train Cost 1.2902525663375854, Monte Carlo Cost: 0.5850622653961182
Epoch 17000, Train Cost 0.9059568643569946, Monte Carlo Cost: 0.5778802633285522
Epoch 18000, Train Cost 1.1376116275787354, Monte Carlo Cost: 0.5754542350769043
Epoch 19000, Train Cost 0.993973970413208, Monte Carlo Cost: 0.5770376920700073
Epoch 20000, Train Cost 0.9184345006942749, Monte Carlo Cost: 0.5719054937362671
Seed 132, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 45.632774353027344, Monte Carlo Cost: 30.458681106567383
Epoch 2000, Train Cost 49.786190032958984, Monte Carlo Cost: 29.5295467376709
Epoch 3000, Train Cost 43.237464904785156, Monte Carlo Cost: 28.63840675354004
Epoch 4000, Train Cost 46.868743896484375, Monte Carlo Cost: 27.76750373840332
Epoch 5000, Train Cost 61.38250732421875, Monte Carlo Cost: 26.928354263305664
Epoch 6000, Train Cost 41.23872756958008, Monte Carlo Cost: 26.12277603149414
Epoch 7000, Train Cost 44.97187042236328, Monte Carlo Cost: 25.338266372680664
Epoch 8000, Train Cost 40.30928421020508, Monte Carlo Cost: 24.581541061401367
Epoch 9000, Train Cost 35.77854537963867, Monte Carlo Cost: 23.841522216796875
Epoch 10000, Train Cost 47.09349822998047, Monte Carlo Cost: 23.12470817565918
Epoch 11000, Train Cost 50.5095100402832, Monte Carlo Cost: 22.435691833496094
Epoch 12000, Train Cost 45.366268157958984, Monte Carlo Cost: 21.754405975341797
Epoch 13000, Train Cost 45.513484954833984, Monte Carlo Cost: 21.101428985595703
Epoch 14000, Train Cost 43.790767669677734, Monte Carlo Cost: 20.464553833007812
Epoch 15000, Train Cost 43.303646087646484, Monte Carlo Cost: 19.84946632385254
Epoch 16000, Train Cost 46.751495361328125, Monte Carlo Cost: 19.246553421020508
Epoch 17000, Train Cost 33.17328643798828, Monte Carlo Cost: 18.66294288635254
Epoch 18000, Train Cost 43.22630310058594, Monte Carlo Cost: 18.0965576171875
Epoch 19000, Train Cost 33.95067596435547, Monte Carlo Cost: 17.542314529418945
Epoch 20000, Train Cost 27.80064582824707, Monte Carlo Cost: 17.005287170410156
Seed 132, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 28.671817779541016, Monte Carlo Cost: 20.70838737487793
Epoch 2000, Train Cost 31.87728500366211, Monte Carlo Cost: 20.701711654663086
Epoch 3000, Train Cost 29.469972610473633, Monte Carlo Cost: 20.695064544677734
Epoch 4000, Train Cost 33.698822021484375, Monte Carlo Cost: 20.68836212158203
Epoch 5000, Train Cost 43.66267395019531, Monte Carlo Cost: 20.681684494018555
Epoch 6000, Train Cost 30.48497200012207, Monte Carlo Cost: 20.675031661987305
Epoch 7000, Train Cost 36.60887145996094, Monte Carlo Cost: 20.66837501525879
Epoch 8000, Train Cost 34.15195846557617, Monte Carlo Cost: 20.661724090576172
Epoch 9000, Train Cost 30.495450973510742, Monte Carlo Cost: 20.65504264831543
Epoch 10000, Train Cost 40.907493591308594, Monte Carlo Cost: 20.648393630981445
Epoch 11000, Train Cost 42.96855545043945, Monte Carlo Cost: 20.641738891601562
Epoch 12000, Train Cost 41.433624267578125, Monte Carlo Cost: 20.635046005249023
Epoch 13000, Train Cost 42.1686897277832, Monte Carlo Cost: 20.628400802612305
Epoch 14000, Train Cost 43.51861572265625, Monte Carlo Cost: 20.62172508239746
Epoch 15000, Train Cost 40.64662170410156, Monte Carlo Cost: 20.615121841430664
Epoch 16000, Train Cost 46.65562057495117, Monte Carlo Cost: 20.60848045349121
Epoch 17000, Train Cost 37.591651916503906, Monte Carlo Cost: 20.60187339782715
Epoch 18000, Train Cost 48.01851272583008, Monte Carlo Cost: 20.595205307006836
Epoch 19000, Train Cost 40.80038070678711, Monte Carlo Cost: 20.588560104370117
Epoch 20000, Train Cost 33.58635711669922, Monte Carlo Cost: 20.581951141357422
Seed 132, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.999138832092285, Monte Carlo Cost: 3.4310646057128906
Epoch 2000, Train Cost 2.787691593170166, Monte Carlo Cost: 1.0921165943145752
Epoch 3000, Train Cost 1.318963646888733, Monte Carlo Cost: 0.8741979002952576
Epoch 4000, Train Cost 1.1110808849334717, Monte Carlo Cost: 0.8351413607597351
Epoch 5000, Train Cost 1.222435712814331, Monte Carlo Cost: 0.7655228972434998
Epoch 6000, Train Cost 0.8493160009384155, Monte Carlo Cost: 0.7037574052810669
Epoch 7000, Train Cost 1.1845592260360718, Monte Carlo Cost: 0.6533210277557373
Epoch 8000, Train Cost 0.951339602470398, Monte Carlo Cost: 0.6255156993865967
Epoch 9000, Train Cost 0.7722330689430237, Monte Carlo Cost: 0.6071372628211975
Epoch 10000, Train Cost 1.083520770072937, Monte Carlo Cost: 0.5943130254745483
Epoch 11000, Train Cost 1.2324680089950562, Monte Carlo Cost: 0.5892958045005798
Epoch 12000, Train Cost 1.0676891803741455, Monte Carlo Cost: 0.5846018195152283
Epoch 13000, Train Cost 1.1270196437835693, Monte Carlo Cost: 0.5833559036254883
Epoch 14000, Train Cost 1.194777488708496, Monte Carlo Cost: 0.5787783265113831
Epoch 15000, Train Cost 1.1836313009262085, Monte Carlo Cost: 0.5757559537887573
Epoch 16000, Train Cost 1.274655818939209, Monte Carlo Cost: 0.5765707492828369
Epoch 17000, Train Cost 0.9050187468528748, Monte Carlo Cost: 0.5727719068527222
Epoch 18000, Train Cost 1.1349334716796875, Monte Carlo Cost: 0.5729836225509644
Epoch 19000, Train Cost 0.9919929504394531, Monte Carlo Cost: 0.57515549659729
Epoch 20000, Train Cost 0.9161856770515442, Monte Carlo Cost: 0.5707743167877197
Seed 132, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 83.07415008544922, Monte Carlo Cost: 49.33111572265625
Epoch 2000, Train Cost 94.97369384765625, Monte Carlo Cost: 47.652793884277344
Epoch 3000, Train Cost 77.25851440429688, Monte Carlo Cost: 46.03800582885742
Epoch 4000, Train Cost 70.71072387695312, Monte Carlo Cost: 44.49075698852539
Epoch 5000, Train Cost 84.33631896972656, Monte Carlo Cost: 42.98398208618164
Epoch 6000, Train Cost 58.70771026611328, Monte Carlo Cost: 41.535377502441406
Epoch 7000, Train Cost 61.337684631347656, Monte Carlo Cost: 40.13341522216797
Epoch 8000, Train Cost 59.530521392822266, Monte Carlo Cost: 38.789268493652344
Epoch 9000, Train Cost 46.719974517822266, Monte Carlo Cost: 37.48325729370117
Epoch 10000, Train Cost 62.842281341552734, Monte Carlo Cost: 36.21047592163086
Epoch 11000, Train Cost 83.26187896728516, Monte Carlo Cost: 34.994991302490234
Epoch 12000, Train Cost 66.31228637695312, Monte Carlo Cost: 33.8201904296875
Epoch 13000, Train Cost 67.35021209716797, Monte Carlo Cost: 32.67523193359375
Epoch 14000, Train Cost 60.46521759033203, Monte Carlo Cost: 31.580276489257812
Epoch 15000, Train Cost 74.46698760986328, Monte Carlo Cost: 30.495702743530273
Epoch 16000, Train Cost 75.34996032714844, Monte Carlo Cost: 29.452775955200195
Epoch 17000, Train Cost 40.743064880371094, Monte Carlo Cost: 28.440349578857422
Epoch 18000, Train Cost 61.41578674316406, Monte Carlo Cost: 27.483596801757812
Epoch 19000, Train Cost 43.09574508666992, Monte Carlo Cost: 26.5399169921875
Epoch 20000, Train Cost 39.21036148071289, Monte Carlo Cost: 25.62430191040039
Seed 132, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 132
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 17.93477439880371, Monte Carlo Cost: 12.864752769470215
Epoch 2000, Train Cost 20.16130828857422, Monte Carlo Cost: 12.860433578491211
Epoch 3000, Train Cost 18.497631072998047, Monte Carlo Cost: 12.856131553649902
Epoch 4000, Train Cost 21.071243286132812, Monte Carlo Cost: 12.851798057556152
Epoch 5000, Train Cost 25.184005737304688, Monte Carlo Cost: 12.847467422485352
Epoch 6000, Train Cost 17.907041549682617, Monte Carlo Cost: 12.843156814575195
Epoch 7000, Train Cost 23.754796981811523, Monte Carlo Cost: 12.838838577270508
Epoch 8000, Train Cost 22.058530807495117, Monte Carlo Cost: 12.83453369140625
Epoch 9000, Train Cost 18.537275314331055, Monte Carlo Cost: 12.830208778381348
Epoch 10000, Train Cost 25.230497360229492, Monte Carlo Cost: 12.825897216796875
Epoch 11000, Train Cost 26.484472274780273, Monte Carlo Cost: 12.821588516235352
Epoch 12000, Train Cost 25.083724975585938, Monte Carlo Cost: 12.8172607421875
Epoch 13000, Train Cost 25.462034225463867, Monte Carlo Cost: 12.812952995300293
Epoch 14000, Train Cost 27.814464569091797, Monte Carlo Cost: 12.808643341064453
Epoch 15000, Train Cost 24.420045852661133, Monte Carlo Cost: 12.804356575012207
Epoch 16000, Train Cost 27.831626892089844, Monte Carlo Cost: 12.800054550170898
Epoch 17000, Train Cost 23.336732864379883, Monte Carlo Cost: 12.795766830444336
Epoch 18000, Train Cost 27.8153133392334, Monte Carlo Cost: 12.791462898254395
Epoch 19000, Train Cost 25.57375144958496, Monte Carlo Cost: 12.787156105041504
Epoch 20000, Train Cost 21.89133644104004, Monte Carlo Cost: 12.782872200012207
Seed 180, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 6.627256870269775, Monte Carlo Cost: 5.860681533813477
Epoch 2000, Train Cost 5.413844108581543, Monte Carlo Cost: 3.8006296157836914
Epoch 3000, Train Cost 1.5757546424865723, Monte Carlo Cost: 1.7934354543685913
Epoch 4000, Train Cost 0.9660276174545288, Monte Carlo Cost: 1.357921838760376
Epoch 5000, Train Cost 1.674379587173462, Monte Carlo Cost: 1.3085479736328125
Epoch 6000, Train Cost 1.1513309478759766, Monte Carlo Cost: 1.2806954383850098
Epoch 7000, Train Cost 0.8753191232681274, Monte Carlo Cost: 1.2596499919891357
Epoch 8000, Train Cost 0.9251447916030884, Monte Carlo Cost: 1.2412605285644531
Epoch 9000, Train Cost 1.5162593126296997, Monte Carlo Cost: 1.221749186515808
Epoch 10000, Train Cost 1.2181973457336426, Monte Carlo Cost: 1.2066655158996582
Epoch 11000, Train Cost 1.0460293292999268, Monte Carlo Cost: 1.188493013381958
Epoch 12000, Train Cost 0.6182725429534912, Monte Carlo Cost: 1.175891399383545
Epoch 13000, Train Cost 1.1972315311431885, Monte Carlo Cost: 1.162177324295044
Epoch 14000, Train Cost 1.2481441497802734, Monte Carlo Cost: 1.1495469808578491
Epoch 15000, Train Cost 1.1929965019226074, Monte Carlo Cost: 1.1385774612426758
Epoch 16000, Train Cost 1.1774859428405762, Monte Carlo Cost: 1.1298620700836182
Epoch 17000, Train Cost 1.6828789710998535, Monte Carlo Cost: 1.1207389831542969
Epoch 18000, Train Cost 1.0031145811080933, Monte Carlo Cost: 1.1131205558776855
Epoch 19000, Train Cost 1.5269379615783691, Monte Carlo Cost: 1.1028820276260376
Epoch 20000, Train Cost 1.3645999431610107, Monte Carlo Cost: 1.0967411994934082
Seed 180, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 19.63935089111328, Monte Carlo Cost: 24.59453010559082
Epoch 2000, Train Cost 18.830554962158203, Monte Carlo Cost: 17.065738677978516
Epoch 3000, Train Cost 14.889344215393066, Monte Carlo Cost: 12.887542724609375
Epoch 4000, Train Cost 11.590723037719727, Monte Carlo Cost: 10.510011672973633
Epoch 5000, Train Cost 17.71269416809082, Monte Carlo Cost: 9.04666805267334
Epoch 6000, Train Cost 10.929795265197754, Monte Carlo Cost: 8.13137435913086
Epoch 7000, Train Cost 10.90123176574707, Monte Carlo Cost: 7.539353370666504
Epoch 8000, Train Cost 11.452396392822266, Monte Carlo Cost: 7.172842025756836
Epoch 9000, Train Cost 13.29418659210205, Monte Carlo Cost: 6.954773902893066
Epoch 10000, Train Cost 14.17281723022461, Monte Carlo Cost: 6.796851634979248
Epoch 11000, Train Cost 12.720815658569336, Monte Carlo Cost: 6.706119060516357
Epoch 12000, Train Cost 6.603882789611816, Monte Carlo Cost: 6.591862201690674
Epoch 13000, Train Cost 10.5060453414917, Monte Carlo Cost: 6.529467582702637
Epoch 14000, Train Cost 11.507830619812012, Monte Carlo Cost: 6.509884357452393
Epoch 15000, Train Cost 14.112628936767578, Monte Carlo Cost: 6.517078876495361
Epoch 16000, Train Cost 7.926456928253174, Monte Carlo Cost: 6.5080671310424805
Epoch 17000, Train Cost 15.543763160705566, Monte Carlo Cost: 6.469970703125
Epoch 18000, Train Cost 12.384366035461426, Monte Carlo Cost: 6.46988582611084
Perturbing at epoch 18000
Epoch 19000, Train Cost 12.559420585632324, Monte Carlo Cost: 6.730560302734375
Epoch 20000, Train Cost 12.724647521972656, Monte Carlo Cost: 6.098965644836426
Seed 180, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 52.203670501708984, Monte Carlo Cost: 58.31388854980469
Epoch 2000, Train Cost 66.1320571899414, Monte Carlo Cost: 57.99545669555664
Epoch 3000, Train Cost 51.358116149902344, Monte Carlo Cost: 57.67585754394531
Epoch 4000, Train Cost 52.53007507324219, Monte Carlo Cost: 57.36166000366211
Epoch 5000, Train Cost 77.2341079711914, Monte Carlo Cost: 57.04851150512695
Epoch 6000, Train Cost 52.854610443115234, Monte Carlo Cost: 56.7398796081543
Epoch 7000, Train Cost 52.288978576660156, Monte Carlo Cost: 56.43125915527344
Epoch 8000, Train Cost 51.8370246887207, Monte Carlo Cost: 56.12461471557617
Epoch 9000, Train Cost 80.61376953125, Monte Carlo Cost: 55.8238410949707
Epoch 10000, Train Cost 50.02153015136719, Monte Carlo Cost: 55.525047302246094
Epoch 11000, Train Cost 53.036659240722656, Monte Carlo Cost: 55.23003005981445
Epoch 12000, Train Cost 37.18690490722656, Monte Carlo Cost: 54.93351745605469
Epoch 13000, Train Cost 55.46015930175781, Monte Carlo Cost: 54.637657165527344
Epoch 14000, Train Cost 76.235107421875, Monte Carlo Cost: 54.344749450683594
Epoch 15000, Train Cost 69.08335876464844, Monte Carlo Cost: 54.05634307861328
Epoch 16000, Train Cost 61.14988708496094, Monte Carlo Cost: 53.76833724975586
Epoch 17000, Train Cost 70.83488464355469, Monte Carlo Cost: 53.48594665527344
Epoch 18000, Train Cost 48.951698303222656, Monte Carlo Cost: 53.2060432434082
Epoch 19000, Train Cost 81.18390655517578, Monte Carlo Cost: 52.92350387573242
Epoch 20000, Train Cost 66.7647705078125, Monte Carlo Cost: 52.644039154052734
Seed 180, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 6.677130699157715, Monte Carlo Cost: 5.928589344024658
Epoch 2000, Train Cost 5.71846866607666, Monte Carlo Cost: 3.9247660636901855
Epoch 3000, Train Cost 1.7794533967971802, Monte Carlo Cost: 1.8661952018737793
Epoch 4000, Train Cost 0.9056263566017151, Monte Carlo Cost: 1.3469659090042114
Epoch 5000, Train Cost 1.8296334743499756, Monte Carlo Cost: 1.2884105443954468
Epoch 6000, Train Cost 1.2041313648223877, Monte Carlo Cost: 1.2610924243927002
Epoch 7000, Train Cost 0.9518733620643616, Monte Carlo Cost: 1.240065097808838
Epoch 8000, Train Cost 1.0071436166763306, Monte Carlo Cost: 1.2208490371704102
Epoch 9000, Train Cost 1.602368950843811, Monte Carlo Cost: 1.2011770009994507
Epoch 10000, Train Cost 1.2314146757125854, Monte Carlo Cost: 1.185913324356079
Epoch 11000, Train Cost 1.1455974578857422, Monte Carlo Cost: 1.1679208278656006
Epoch 12000, Train Cost 0.6620408892631531, Monte Carlo Cost: 1.1546683311462402
Epoch 13000, Train Cost 1.203035593032837, Monte Carlo Cost: 1.1408718824386597
Epoch 14000, Train Cost 1.4494879245758057, Monte Carlo Cost: 1.1277998685836792
Epoch 15000, Train Cost 1.1126651763916016, Monte Carlo Cost: 1.116910696029663
Epoch 16000, Train Cost 1.2383053302764893, Monte Carlo Cost: 1.1078678369522095
Epoch 17000, Train Cost 1.7332979440689087, Monte Carlo Cost: 1.0986905097961426
Epoch 18000, Train Cost 1.113706350326538, Monte Carlo Cost: 1.0908722877502441
Epoch 19000, Train Cost 1.5917781591415405, Monte Carlo Cost: 1.080678939819336
Epoch 20000, Train Cost 1.392212152481079, Monte Carlo Cost: 1.0742164850234985
Seed 180, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a14570eb8>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a16fbd240>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 10.069958686828613, Monte Carlo Cost: 10.105926513671875
Epoch 2000, Train Cost 14.582972526550293, Monte Carlo Cost: 8.71241283416748
Epoch 3000, Train Cost 13.97435474395752, Monte Carlo Cost: 7.852234840393066
Epoch 4000, Train Cost 10.871145248413086, Monte Carlo Cost: 7.32919979095459
Epoch 5000, Train Cost 17.19525718688965, Monte Carlo Cost: 6.957826614379883
Epoch 6000, Train Cost 11.229324340820312, Monte Carlo Cost: 6.718783855438232
Epoch 7000, Train Cost 10.974870681762695, Monte Carlo Cost: 6.542318344116211
Epoch 8000, Train Cost 11.578561782836914, Monte Carlo Cost: 6.431527614593506
Epoch 9000, Train Cost 13.417713165283203, Monte Carlo Cost: 6.378926753997803
Epoch 10000, Train Cost 13.762731552124023, Monte Carlo Cost: 6.333449363708496
Epoch 11000, Train Cost 12.854483604431152, Monte Carlo Cost: 6.328617572784424
Epoch 12000, Train Cost 6.46773624420166, Monte Carlo Cost: 6.2626214027404785
Epoch 13000, Train Cost 10.230186462402344, Monte Carlo Cost: 6.234704971313477
Epoch 14000, Train Cost 12.571639060974121, Monte Carlo Cost: 6.238658428192139
Epoch 15000, Train Cost 13.102758407592773, Monte Carlo Cost: 6.263027667999268
Epoch 16000, Train Cost 8.140700340270996, Monte Carlo Cost: 6.266656398773193
Epoch 17000, Train Cost 15.601269721984863, Monte Carlo Cost: 6.237428665161133
Epoch 18000, Train Cost 12.572914123535156, Monte Carlo Cost: 6.244705677032471
Epoch 19000, Train Cost 10.203655242919922, Monte Carlo Cost: 6.193731784820557
Epoch 20000, Train Cost 9.740754127502441, Monte Carlo Cost: 6.1759724617004395
Seed 180, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 34.56551742553711, Monte Carlo Cost: 40.602561950683594
Epoch 2000, Train Cost 44.23616409301758, Monte Carlo Cost: 40.42827606201172
Epoch 3000, Train Cost 35.518558502197266, Monte Carlo Cost: 40.25310516357422
Epoch 4000, Train Cost 33.62529754638672, Monte Carlo Cost: 40.0806999206543
Epoch 5000, Train Cost 54.97203063964844, Monte Carlo Cost: 39.90828323364258
Epoch 6000, Train Cost 36.080718994140625, Monte Carlo Cost: 39.7381591796875
Epoch 7000, Train Cost 34.4946174621582, Monte Carlo Cost: 39.56764221191406
Epoch 8000, Train Cost 34.975364685058594, Monte Carlo Cost: 39.39787673950195
Epoch 9000, Train Cost 54.21416473388672, Monte Carlo Cost: 39.23124694824219
Epoch 10000, Train Cost 36.25401306152344, Monte Carlo Cost: 39.0653076171875
Epoch 11000, Train Cost 36.880401611328125, Monte Carlo Cost: 38.90131759643555
Epoch 12000, Train Cost 24.438392639160156, Monte Carlo Cost: 38.73588180541992
Epoch 13000, Train Cost 37.751495361328125, Monte Carlo Cost: 38.5706901550293
Epoch 14000, Train Cost 52.93117904663086, Monte Carlo Cost: 38.406982421875
Epoch 15000, Train Cost 44.84371566772461, Monte Carlo Cost: 38.24565124511719
Epoch 16000, Train Cost 40.866661071777344, Monte Carlo Cost: 38.084224700927734
Epoch 17000, Train Cost 51.077369689941406, Monte Carlo Cost: 37.925384521484375
Epoch 18000, Train Cost 36.541603088378906, Monte Carlo Cost: 37.76786422729492
Epoch 19000, Train Cost 55.09820556640625, Monte Carlo Cost: 37.60829162597656
Epoch 20000, Train Cost 44.74239730834961, Monte Carlo Cost: 37.45036697387695
Seed 180, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 6.837378978729248, Monte Carlo Cost: 8.05247688293457
Epoch 2000, Train Cost 5.977179050445557, Monte Carlo Cost: 3.6281657218933105
Epoch 3000, Train Cost 1.5671534538269043, Monte Carlo Cost: 1.6302318572998047
Epoch 4000, Train Cost 0.9730361104011536, Monte Carlo Cost: 1.3377642631530762
Epoch 5000, Train Cost 1.6567641496658325, Monte Carlo Cost: 1.2382076978683472
Epoch 6000, Train Cost 1.039223313331604, Monte Carlo Cost: 1.1464202404022217
Epoch 7000, Train Cost 0.8002071976661682, Monte Carlo Cost: 1.0784730911254883
Epoch 8000, Train Cost 0.8131192326545715, Monte Carlo Cost: 1.0362721681594849
Epoch 9000, Train Cost 1.2690635919570923, Monte Carlo Cost: 1.0121159553527832
Epoch 10000, Train Cost 0.996600866317749, Monte Carlo Cost: 0.9958205819129944
Epoch 11000, Train Cost 0.8732749819755554, Monte Carlo Cost: 0.987532913684845
Epoch 12000, Train Cost 0.5305882692337036, Monte Carlo Cost: 0.9784088730812073
Epoch 13000, Train Cost 0.9326678514480591, Monte Carlo Cost: 0.9729406833648682
Epoch 14000, Train Cost 1.1195870637893677, Monte Carlo Cost: 0.9671525955200195
Epoch 15000, Train Cost 1.0679731369018555, Monte Carlo Cost: 0.9642669558525085
Epoch 16000, Train Cost 0.9091807007789612, Monte Carlo Cost: 0.9620122909545898
Epoch 17000, Train Cost 1.315355658531189, Monte Carlo Cost: 0.961351215839386
Epoch 18000, Train Cost 0.8865249156951904, Monte Carlo Cost: 0.9594213962554932
Epoch 19000, Train Cost 1.2340327501296997, Monte Carlo Cost: 0.9578958749771118
Epoch 20000, Train Cost 1.0433275699615479, Monte Carlo Cost: 0.9555395841598511
Seed 180, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 16.737245559692383, Monte Carlo Cost: 24.11033058166504
Epoch 2000, Train Cost 21.190488815307617, Monte Carlo Cost: 23.046918869018555
Epoch 3000, Train Cost 18.250268936157227, Monte Carlo Cost: 22.021442413330078
Epoch 4000, Train Cost 19.116653442382812, Monte Carlo Cost: 21.044504165649414
Epoch 5000, Train Cost 23.536142349243164, Monte Carlo Cost: 20.108383178710938
Epoch 6000, Train Cost 16.133886337280273, Monte Carlo Cost: 19.212635040283203
Epoch 7000, Train Cost 13.698836326599121, Monte Carlo Cost: 18.342443466186523
Epoch 8000, Train Cost 13.788189888000488, Monte Carlo Cost: 17.51971435546875
Epoch 9000, Train Cost 18.413101196289062, Monte Carlo Cost: 16.728572845458984
Epoch 10000, Train Cost 18.364757537841797, Monte Carlo Cost: 15.971138000488281
Epoch 11000, Train Cost 13.721102714538574, Monte Carlo Cost: 15.255858421325684
Epoch 12000, Train Cost 8.202536582946777, Monte Carlo Cost: 14.545392036437988
Epoch 13000, Train Cost 13.930328369140625, Monte Carlo Cost: 13.871637344360352
Epoch 14000, Train Cost 11.82529067993164, Monte Carlo Cost: 13.233307838439941
Epoch 15000, Train Cost 16.992536544799805, Monte Carlo Cost: 12.633522033691406
Epoch 16000, Train Cost 9.744193077087402, Monte Carlo Cost: 12.053314208984375
Epoch 17000, Train Cost 17.637863159179688, Monte Carlo Cost: 11.501007080078125
Epoch 18000, Train Cost 12.20791244506836, Monte Carlo Cost: 10.984293937683105
Epoch 19000, Train Cost 12.15349006652832, Monte Carlo Cost: 10.476490020751953
Epoch 20000, Train Cost 10.628816604614258, Monte Carlo Cost: 10.000616073608398
Seed 180, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 62.648460388183594, Monte Carlo Cost: 71.60516357421875
Epoch 2000, Train Cost 79.70899963378906, Monte Carlo Cost: 71.58715057373047
Epoch 3000, Train Cost 61.567012786865234, Monte Carlo Cost: 71.5689468383789
Epoch 4000, Train Cost 72.42948913574219, Monte Carlo Cost: 71.55075073242188
Epoch 5000, Train Cost 88.87300872802734, Monte Carlo Cost: 71.5327377319336
Epoch 6000, Train Cost 68.50020599365234, Monte Carlo Cost: 71.51460266113281
Epoch 7000, Train Cost 65.76107788085938, Monte Carlo Cost: 71.4963607788086
Epoch 8000, Train Cost 64.68881225585938, Monte Carlo Cost: 71.47840118408203
Epoch 9000, Train Cost 101.01056671142578, Monte Carlo Cost: 71.4603042602539
Epoch 10000, Train Cost 62.6777229309082, Monte Carlo Cost: 71.44225311279297
Epoch 11000, Train Cost 65.73872375488281, Monte Carlo Cost: 71.42440032958984
Epoch 12000, Train Cost 49.83991241455078, Monte Carlo Cost: 71.40618896484375
Epoch 13000, Train Cost 73.95133209228516, Monte Carlo Cost: 71.38805389404297
Epoch 14000, Train Cost 92.61943817138672, Monte Carlo Cost: 71.36988830566406
Epoch 15000, Train Cost 98.32951354980469, Monte Carlo Cost: 71.3519515991211
Epoch 16000, Train Cost 81.98810577392578, Monte Carlo Cost: 71.33390808105469
Epoch 17000, Train Cost 90.72695922851562, Monte Carlo Cost: 71.31598663330078
Epoch 18000, Train Cost 58.290523529052734, Monte Carlo Cost: 71.29811096191406
Epoch 19000, Train Cost 107.2531967163086, Monte Carlo Cost: 71.28005981445312
Epoch 20000, Train Cost 93.11213684082031, Monte Carlo Cost: 71.26188659667969
Seed 180, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 4.949448108673096, Monte Carlo Cost: 4.591375350952148
Epoch 2000, Train Cost 2.2818241119384766, Monte Carlo Cost: 1.5594990253448486
Epoch 3000, Train Cost 1.2022740840911865, Monte Carlo Cost: 1.2771148681640625
Epoch 4000, Train Cost 0.8531441688537598, Monte Carlo Cost: 1.1701627969741821
Epoch 5000, Train Cost 1.5000287294387817, Monte Carlo Cost: 1.08292818069458
Epoch 6000, Train Cost 0.9545236825942993, Monte Carlo Cost: 1.0291354656219482
Epoch 7000, Train Cost 0.7750902771949768, Monte Carlo Cost: 0.9991439580917358
Epoch 8000, Train Cost 0.7955423593521118, Monte Carlo Cost: 0.9849156737327576
Epoch 9000, Train Cost 1.2290663719177246, Monte Carlo Cost: 0.9774571657180786
Epoch 10000, Train Cost 0.9690068960189819, Monte Carlo Cost: 0.972798764705658
Epoch 11000, Train Cost 0.8590058088302612, Monte Carlo Cost: 0.9717869162559509
Epoch 12000, Train Cost 0.5253166556358337, Monte Carlo Cost: 0.9666615724563599
Epoch 13000, Train Cost 0.921554446220398, Monte Carlo Cost: 0.963698148727417
Epoch 14000, Train Cost 1.1137869358062744, Monte Carlo Cost: 0.9598950743675232
Epoch 15000, Train Cost 1.065242886543274, Monte Carlo Cost: 0.9586436748504639
Epoch 16000, Train Cost 0.9006460905075073, Monte Carlo Cost: 0.9572141170501709
Epoch 17000, Train Cost 1.3039993047714233, Monte Carlo Cost: 0.9574132561683655
Epoch 18000, Train Cost 0.8837563991546631, Monte Carlo Cost: 0.9561216831207275
Epoch 19000, Train Cost 1.2269742488861084, Monte Carlo Cost: 0.9552614688873291
Epoch 20000, Train Cost 1.036690354347229, Monte Carlo Cost: 0.9530777335166931
Seed 180, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 12.296923637390137, Monte Carlo Cost: 15.73787784576416
Epoch 2000, Train Cost 16.997058868408203, Monte Carlo Cost: 15.156250953674316
Epoch 3000, Train Cost 15.368298530578613, Monte Carlo Cost: 14.591730117797852
Epoch 4000, Train Cost 13.427441596984863, Monte Carlo Cost: 14.050127029418945
Epoch 5000, Train Cost 20.553964614868164, Monte Carlo Cost: 13.522216796875
Epoch 6000, Train Cost 12.952409744262695, Monte Carlo Cost: 13.016515731811523
Epoch 7000, Train Cost 11.393869400024414, Monte Carlo Cost: 12.521665573120117
Epoch 8000, Train Cost 11.902521133422852, Monte Carlo Cost: 12.05144214630127
Epoch 9000, Train Cost 15.346128463745117, Monte Carlo Cost: 11.601497650146484
Epoch 10000, Train Cost 15.735852241516113, Monte Carlo Cost: 11.165867805480957
Epoch 11000, Train Cost 12.710025787353516, Monte Carlo Cost: 10.75586223602295
Epoch 12000, Train Cost 6.724652290344238, Monte Carlo Cost: 10.345491409301758
Epoch 13000, Train Cost 11.584277153015137, Monte Carlo Cost: 9.958610534667969
Epoch 14000, Train Cost 11.62565803527832, Monte Carlo Cost: 9.598349571228027
Epoch 15000, Train Cost 14.465344429016113, Monte Carlo Cost: 9.262429237365723
Epoch 16000, Train Cost 8.40767765045166, Monte Carlo Cost: 8.93934440612793
Epoch 17000, Train Cost 16.221092224121094, Monte Carlo Cost: 8.631304740905762
Epoch 18000, Train Cost 12.083403587341309, Monte Carlo Cost: 8.355175971984863
Epoch 19000, Train Cost 10.787202835083008, Monte Carlo Cost: 8.078754425048828
Epoch 20000, Train Cost 9.761289596557617, Monte Carlo Cost: 7.835279941558838
Seed 180, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 180
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 29.208192825317383, Monte Carlo Cost: 38.33258819580078
Epoch 2000, Train Cost 37.60927200317383, Monte Carlo Cost: 38.32069396972656
Epoch 3000, Train Cost 30.455745697021484, Monte Carlo Cost: 38.308658599853516
Epoch 4000, Train Cost 34.12751770019531, Monte Carlo Cost: 38.2966423034668
Epoch 5000, Train Cost 45.738311767578125, Monte Carlo Cost: 38.28468704223633
Epoch 6000, Train Cost 33.466651916503906, Monte Carlo Cost: 38.27272415161133
Epoch 7000, Train Cost 29.83116912841797, Monte Carlo Cost: 38.26067352294922
Epoch 8000, Train Cost 30.210432052612305, Monte Carlo Cost: 38.24876022338867
Epoch 9000, Train Cost 47.36427688598633, Monte Carlo Cost: 38.23679733276367
Epoch 10000, Train Cost 34.276947021484375, Monte Carlo Cost: 38.224853515625
Epoch 11000, Train Cost 31.53768539428711, Monte Carlo Cost: 38.213050842285156
Epoch 12000, Train Cost 22.400659561157227, Monte Carlo Cost: 38.200992584228516
Epoch 13000, Train Cost 36.11225509643555, Monte Carlo Cost: 38.18898391723633
Epoch 14000, Train Cost 42.2221565246582, Monte Carlo Cost: 38.17696762084961
Epoch 15000, Train Cost 46.18727111816406, Monte Carlo Cost: 38.16508483886719
Epoch 16000, Train Cost 37.19965744018555, Monte Carlo Cost: 38.153141021728516
Epoch 17000, Train Cost 47.27449035644531, Monte Carlo Cost: 38.14125442504883
Epoch 18000, Train Cost 30.422134399414062, Monte Carlo Cost: 38.12940216064453
Epoch 19000, Train Cost 49.745338439941406, Monte Carlo Cost: 38.117469787597656
Epoch 20000, Train Cost 42.7798957824707, Monte Carlo Cost: 38.10544204711914
Seed 123, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.7323102951049805, Monte Carlo Cost: 8.575929641723633
Epoch 2000, Train Cost 4.822301387786865, Monte Carlo Cost: 5.262457847595215
Epoch 3000, Train Cost 1.1914143562316895, Monte Carlo Cost: 2.8379056453704834
Epoch 4000, Train Cost 1.676419734954834, Monte Carlo Cost: 2.3100552558898926
Epoch 5000, Train Cost 1.6965268850326538, Monte Carlo Cost: 2.16799259185791
Epoch 6000, Train Cost 2.022669792175293, Monte Carlo Cost: 2.1255300045013428
Epoch 7000, Train Cost 1.473602056503296, Monte Carlo Cost: 2.088857889175415
Epoch 8000, Train Cost 1.6996591091156006, Monte Carlo Cost: 2.0383055210113525
Epoch 9000, Train Cost 1.182269811630249, Monte Carlo Cost: 2.0044894218444824
Epoch 10000, Train Cost 1.047163963317871, Monte Carlo Cost: 1.9628063440322876
Epoch 11000, Train Cost 1.4279752969741821, Monte Carlo Cost: 1.9395546913146973
Epoch 12000, Train Cost 0.6360282897949219, Monte Carlo Cost: 1.902718186378479
Epoch 13000, Train Cost 1.0394006967544556, Monte Carlo Cost: 1.883019208908081
Epoch 14000, Train Cost 1.495360016822815, Monte Carlo Cost: 1.8566468954086304
Epoch 15000, Train Cost 1.0110154151916504, Monte Carlo Cost: 1.8269226551055908
Epoch 16000, Train Cost 1.2998965978622437, Monte Carlo Cost: 1.8062996864318848
Epoch 17000, Train Cost 1.3126853704452515, Monte Carlo Cost: 1.7844001054763794
Epoch 18000, Train Cost 1.3102872371673584, Monte Carlo Cost: 1.7704386711120605
Epoch 19000, Train Cost 1.1345398426055908, Monte Carlo Cost: 1.7528436183929443
Epoch 20000, Train Cost 2.9842002391815186, Monte Carlo Cost: 1.7331438064575195
Seed 123, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 12.536025047302246, Monte Carlo Cost: 23.43366241455078
Epoch 2000, Train Cost 18.308223724365234, Monte Carlo Cost: 17.806690216064453
Epoch 3000, Train Cost 14.345948219299316, Monte Carlo Cost: 14.591294288635254
Epoch 4000, Train Cost 13.138504981994629, Monte Carlo Cost: 12.661382675170898
Epoch 5000, Train Cost 12.464794158935547, Monte Carlo Cost: 11.501194953918457
Epoch 6000, Train Cost 12.689162254333496, Monte Carlo Cost: 10.76247787475586
Epoch 7000, Train Cost 14.765327453613281, Monte Carlo Cost: 10.331613540649414
Epoch 8000, Train Cost 16.629138946533203, Monte Carlo Cost: 10.006204605102539
Epoch 9000, Train Cost 11.8149995803833, Monte Carlo Cost: 9.793119430541992
Epoch 10000, Train Cost 15.750713348388672, Monte Carlo Cost: 9.691115379333496
Epoch 11000, Train Cost 9.896257400512695, Monte Carlo Cost: 9.626813888549805
Epoch 12000, Train Cost 11.096264839172363, Monte Carlo Cost: 9.609946250915527
Epoch 13000, Train Cost 10.057633399963379, Monte Carlo Cost: 9.577723503112793
Epoch 14000, Train Cost 16.96725082397461, Monte Carlo Cost: 9.535896301269531
Epoch 15000, Train Cost 13.658103942871094, Monte Carlo Cost: 9.457267761230469
Epoch 16000, Train Cost 9.943889617919922, Monte Carlo Cost: 9.441940307617188
Epoch 17000, Train Cost 12.554351806640625, Monte Carlo Cost: 9.434370040893555
Epoch 18000, Train Cost 15.300952911376953, Monte Carlo Cost: 9.39598274230957
Epoch 19000, Train Cost 14.117589950561523, Monte Carlo Cost: 9.39970588684082
Epoch 20000, Train Cost 13.21840763092041, Monte Carlo Cost: 9.397684097290039
Seed 123, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 25.93800926208496, Monte Carlo Cost: 45.156314849853516
Epoch 2000, Train Cost 39.113468170166016, Monte Carlo Cost: 44.95036697387695
Epoch 3000, Train Cost 24.303972244262695, Monte Carlo Cost: 44.746185302734375
Epoch 4000, Train Cost 40.52591323852539, Monte Carlo Cost: 44.541500091552734
Epoch 5000, Train Cost 32.62504959106445, Monte Carlo Cost: 44.339141845703125
Epoch 6000, Train Cost 35.04263687133789, Monte Carlo Cost: 44.13779067993164
Epoch 7000, Train Cost 32.14583969116211, Monte Carlo Cost: 43.93840789794922
Epoch 8000, Train Cost 37.50320053100586, Monte Carlo Cost: 43.74034118652344
Epoch 9000, Train Cost 30.291292190551758, Monte Carlo Cost: 43.54172897338867
Epoch 10000, Train Cost 26.51370620727539, Monte Carlo Cost: 43.346683502197266
Epoch 11000, Train Cost 38.38674545288086, Monte Carlo Cost: 43.153804779052734
Epoch 12000, Train Cost 18.309795379638672, Monte Carlo Cost: 42.96366882324219
Epoch 13000, Train Cost 28.54705238342285, Monte Carlo Cost: 42.77483367919922
Epoch 14000, Train Cost 34.11953353881836, Monte Carlo Cost: 42.58391571044922
Epoch 15000, Train Cost 26.545753479003906, Monte Carlo Cost: 42.3929443359375
Epoch 16000, Train Cost 33.46124267578125, Monte Carlo Cost: 42.20586013793945
Epoch 17000, Train Cost 35.877044677734375, Monte Carlo Cost: 42.020530700683594
Epoch 18000, Train Cost 36.86083984375, Monte Carlo Cost: 41.83513259887695
Epoch 19000, Train Cost 28.032630920410156, Monte Carlo Cost: 41.65244674682617
Epoch 20000, Train Cost 43.4321403503418, Monte Carlo Cost: 41.46832275390625
Seed 123, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 6.385358810424805, Monte Carlo Cost: 8.896219253540039
Epoch 2000, Train Cost 6.034438133239746, Monte Carlo Cost: 6.124448299407959
Epoch 3000, Train Cost 1.420593500137329, Monte Carlo Cost: 3.188847064971924
Epoch 4000, Train Cost 1.7143018245697021, Monte Carlo Cost: 2.360970973968506
Epoch 5000, Train Cost 1.7230819463729858, Monte Carlo Cost: 2.177379846572876
Epoch 6000, Train Cost 1.9809987545013428, Monte Carlo Cost: 2.1260876655578613
Epoch 7000, Train Cost 1.5108792781829834, Monte Carlo Cost: 2.087080717086792
Epoch 8000, Train Cost 1.7050817012786865, Monte Carlo Cost: 2.03543758392334
Epoch 9000, Train Cost 1.1859573125839233, Monte Carlo Cost: 2.00044322013855
Epoch 10000, Train Cost 1.0598475933074951, Monte Carlo Cost: 1.9593772888183594
Epoch 11000, Train Cost 1.4817825555801392, Monte Carlo Cost: 1.934572458267212
Epoch 12000, Train Cost 0.6460824012756348, Monte Carlo Cost: 1.8985916376113892
Epoch 13000, Train Cost 1.0243042707443237, Monte Carlo Cost: 1.877890706062317
Epoch 14000, Train Cost 1.4684092998504639, Monte Carlo Cost: 1.8508429527282715
Epoch 15000, Train Cost 1.0076546669006348, Monte Carlo Cost: 1.8213858604431152
Epoch 16000, Train Cost 1.2946096658706665, Monte Carlo Cost: 1.800718903541565
Epoch 17000, Train Cost 1.3370990753173828, Monte Carlo Cost: 1.7788220643997192
Epoch 18000, Train Cost 1.3249235153198242, Monte Carlo Cost: 1.7648545503616333
Epoch 19000, Train Cost 1.1158486604690552, Monte Carlo Cost: 1.7467772960662842
Epoch 20000, Train Cost 3.0166847705841064, Monte Carlo Cost: 1.727161169052124
Seed 123, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 18.69347381591797, Monte Carlo Cost: 32.39898681640625
Epoch 2000, Train Cost 21.759450912475586, Monte Carlo Cost: 22.042011260986328
Epoch 3000, Train Cost 16.068288803100586, Monte Carlo Cost: 16.64130210876465
Epoch 4000, Train Cost 14.25384521484375, Monte Carlo Cost: 13.626795768737793
Epoch 5000, Train Cost 13.098430633544922, Monte Carlo Cost: 11.9224214553833
Epoch 6000, Train Cost 13.186573028564453, Monte Carlo Cost: 10.894574165344238
Epoch 7000, Train Cost 15.54188060760498, Monte Carlo Cost: 10.318206787109375
Epoch 8000, Train Cost 17.64683723449707, Monte Carlo Cost: 9.912708282470703
Epoch 9000, Train Cost 12.756815910339355, Monte Carlo Cost: 9.650469779968262
Epoch 10000, Train Cost 17.128995895385742, Monte Carlo Cost: 9.534337043762207
Epoch 11000, Train Cost 9.930953025817871, Monte Carlo Cost: 9.474818229675293
Epoch 12000, Train Cost 11.569293975830078, Monte Carlo Cost: 9.458708763122559
Epoch 13000, Train Cost 10.964118957519531, Monte Carlo Cost: 9.429574966430664
Epoch 14000, Train Cost 18.796674728393555, Monte Carlo Cost: 9.397140502929688
Epoch 15000, Train Cost 14.566774368286133, Monte Carlo Cost: 9.31635570526123
Epoch 16000, Train Cost 10.592737197875977, Monte Carlo Cost: 9.31092357635498
Epoch 17000, Train Cost 12.965214729309082, Monte Carlo Cost: 9.310873031616211
Perturbing at epoch 17000
Epoch 18000, Train Cost 21.1656494140625, Monte Carlo Cost: 17.924673080444336
Epoch 19000, Train Cost 19.814659118652344, Monte Carlo Cost: 12.584671974182129
Epoch 20000, Train Cost 18.359451293945312, Monte Carlo Cost: 10.28542709350586
Seed 123, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 30.357343673706055, Monte Carlo Cost: 47.57839584350586
Epoch 2000, Train Cost 40.86152648925781, Monte Carlo Cost: 47.38786697387695
Epoch 3000, Train Cost 25.32209014892578, Monte Carlo Cost: 47.199222564697266
Epoch 4000, Train Cost 44.01237487792969, Monte Carlo Cost: 47.00994110107422
Epoch 5000, Train Cost 34.22745895385742, Monte Carlo Cost: 46.82270050048828
Epoch 6000, Train Cost 38.10271072387695, Monte Carlo Cost: 46.636226654052734
Epoch 7000, Train Cost 31.666038513183594, Monte Carlo Cost: 46.4515266418457
Epoch 8000, Train Cost 39.555564880371094, Monte Carlo Cost: 46.26780700683594
Epoch 9000, Train Cost 31.25860023498535, Monte Carlo Cost: 46.08284378051758
Epoch 10000, Train Cost 26.590850830078125, Monte Carlo Cost: 45.900978088378906
Epoch 11000, Train Cost 35.81716537475586, Monte Carlo Cost: 45.72163009643555
Epoch 12000, Train Cost 18.459688186645508, Monte Carlo Cost: 45.543800354003906
Epoch 13000, Train Cost 32.85952377319336, Monte Carlo Cost: 45.36746597290039
Epoch 14000, Train Cost 37.18255615234375, Monte Carlo Cost: 45.18918228149414
Epoch 15000, Train Cost 28.33706283569336, Monte Carlo Cost: 45.01055908203125
Epoch 16000, Train Cost 37.44362258911133, Monte Carlo Cost: 44.83567810058594
Epoch 17000, Train Cost 37.09425354003906, Monte Carlo Cost: 44.66183853149414
Epoch 18000, Train Cost 37.28155517578125, Monte Carlo Cost: 44.48767852783203
Epoch 19000, Train Cost 30.955013275146484, Monte Carlo Cost: 44.3161506652832
Epoch 20000, Train Cost 46.309810638427734, Monte Carlo Cost: 44.14329147338867
Seed 123, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 1.5542428493499756, Monte Carlo Cost: 3.840620517730713
Epoch 2000, Train Cost 1.6502044200897217, Monte Carlo Cost: 2.1954588890075684
Epoch 3000, Train Cost 0.9192155599594116, Monte Carlo Cost: 1.947817325592041
Epoch 4000, Train Cost 1.4010549783706665, Monte Carlo Cost: 1.7626166343688965
Epoch 5000, Train Cost 1.231248140335083, Monte Carlo Cost: 1.6208890676498413
Epoch 6000, Train Cost 1.3885936737060547, Monte Carlo Cost: 1.5643970966339111
Epoch 7000, Train Cost 1.0875357389450073, Monte Carlo Cost: 1.5171374082565308
Epoch 8000, Train Cost 1.2492289543151855, Monte Carlo Cost: 1.4867298603057861
Epoch 9000, Train Cost 0.9748873710632324, Monte Carlo Cost: 1.4638447761535645
Epoch 10000, Train Cost 0.8678606748580933, Monte Carlo Cost: 1.448693037033081
Epoch 11000, Train Cost 1.1316719055175781, Monte Carlo Cost: 1.4342280626296997
Epoch 12000, Train Cost 0.5545881390571594, Monte Carlo Cost: 1.4285614490509033
Epoch 13000, Train Cost 0.9166539907455444, Monte Carlo Cost: 1.417812705039978
Epoch 14000, Train Cost 1.1793910264968872, Monte Carlo Cost: 1.4129236936569214
Epoch 15000, Train Cost 0.8959129452705383, Monte Carlo Cost: 1.4077255725860596
Epoch 16000, Train Cost 1.0868867635726929, Monte Carlo Cost: 1.4031548500061035
Epoch 17000, Train Cost 1.1085764169692993, Monte Carlo Cost: 1.4003509283065796
Epoch 18000, Train Cost 1.1802250146865845, Monte Carlo Cost: 1.3973807096481323
Epoch 19000, Train Cost 0.9424238801002502, Monte Carlo Cost: 1.3941543102264404
Epoch 20000, Train Cost 1.6516785621643066, Monte Carlo Cost: 1.396488904953003
Seed 123, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 45.84949493408203, Monte Carlo Cost: 63.82347106933594
Epoch 2000, Train Cost 54.28691864013672, Monte Carlo Cost: 61.96916198730469
Epoch 3000, Train Cost 32.96974563598633, Monte Carlo Cost: 60.17104721069336
Epoch 4000, Train Cost 58.59892272949219, Monte Carlo Cost: 58.4124755859375
Epoch 5000, Train Cost 43.42594909667969, Monte Carlo Cost: 56.70278549194336
Epoch 6000, Train Cost 46.672515869140625, Monte Carlo Cost: 55.03450393676758
Epoch 7000, Train Cost 36.79054641723633, Monte Carlo Cost: 53.4053840637207
Epoch 8000, Train Cost 46.11775207519531, Monte Carlo Cost: 51.81184768676758
Epoch 9000, Train Cost 34.301021575927734, Monte Carlo Cost: 50.244346618652344
Epoch 10000, Train Cost 28.25278663635254, Monte Carlo Cost: 48.7336311340332
Epoch 11000, Train Cost 38.68667221069336, Monte Carlo Cost: 47.2597770690918
Epoch 12000, Train Cost 19.667497634887695, Monte Carlo Cost: 45.820919036865234
Epoch 13000, Train Cost 33.66647720336914, Monte Carlo Cost: 44.40880584716797
Epoch 14000, Train Cost 34.90758514404297, Monte Carlo Cost: 43.01507568359375
Epoch 15000, Train Cost 25.713180541992188, Monte Carlo Cost: 41.656524658203125
Epoch 16000, Train Cost 34.581233978271484, Monte Carlo Cost: 40.34727096557617
Epoch 17000, Train Cost 33.75220489501953, Monte Carlo Cost: 39.068702697753906
Epoch 18000, Train Cost 31.831771850585938, Monte Carlo Cost: 37.8184814453125
Epoch 19000, Train Cost 25.77796173095703, Monte Carlo Cost: 36.60459518432617
Epoch 20000, Train Cost 39.185245513916016, Monte Carlo Cost: 35.411678314208984
Seed 123, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 59.68095016479492, Monte Carlo Cost: 89.0649642944336
Epoch 2000, Train Cost 79.85755157470703, Monte Carlo Cost: 89.04273986816406
Epoch 3000, Train Cost 51.64966583251953, Monte Carlo Cost: 89.02040100097656
Epoch 4000, Train Cost 91.16302490234375, Monte Carlo Cost: 88.99808502197266
Epoch 5000, Train Cost 71.8813705444336, Monte Carlo Cost: 88.97579956054688
Epoch 6000, Train Cost 74.17050170898438, Monte Carlo Cost: 88.95350646972656
Epoch 7000, Train Cost 69.45342254638672, Monte Carlo Cost: 88.93125915527344
Epoch 8000, Train Cost 83.03921508789062, Monte Carlo Cost: 88.90898132324219
Epoch 9000, Train Cost 66.20169830322266, Monte Carlo Cost: 88.88677215576172
Epoch 10000, Train Cost 58.03705596923828, Monte Carlo Cost: 88.86463928222656
Epoch 11000, Train Cost 94.29698181152344, Monte Carlo Cost: 88.84233856201172
Epoch 12000, Train Cost 44.89253234863281, Monte Carlo Cost: 88.82024383544922
Epoch 13000, Train Cost 68.62847900390625, Monte Carlo Cost: 88.79798126220703
Epoch 14000, Train Cost 71.17359924316406, Monte Carlo Cost: 88.775634765625
Epoch 15000, Train Cost 54.439048767089844, Monte Carlo Cost: 88.75340270996094
Epoch 16000, Train Cost 79.19001007080078, Monte Carlo Cost: 88.73117065429688
Epoch 17000, Train Cost 89.36687469482422, Monte Carlo Cost: 88.708984375
Epoch 18000, Train Cost 84.55265045166016, Monte Carlo Cost: 88.68680572509766
Epoch 19000, Train Cost 64.70174407958984, Monte Carlo Cost: 88.6645736694336
Epoch 20000, Train Cost 110.68107604980469, Monte Carlo Cost: 88.64234161376953
Seed 123, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 2.014529228210449, Monte Carlo Cost: 3.9424211978912354
Epoch 2000, Train Cost 1.6150046586990356, Monte Carlo Cost: 2.1277108192443848
Epoch 3000, Train Cost 0.9074409008026123, Monte Carlo Cost: 1.8729569911956787
Epoch 4000, Train Cost 1.3741945028305054, Monte Carlo Cost: 1.7054954767227173
Epoch 5000, Train Cost 1.1921591758728027, Monte Carlo Cost: 1.583457112312317
Epoch 6000, Train Cost 1.3548710346221924, Monte Carlo Cost: 1.5374455451965332
Epoch 7000, Train Cost 1.072830319404602, Monte Carlo Cost: 1.4981989860534668
Epoch 8000, Train Cost 1.2392990589141846, Monte Carlo Cost: 1.4739824533462524
Epoch 9000, Train Cost 0.9718573689460754, Monte Carlo Cost: 1.4546070098876953
Epoch 10000, Train Cost 0.8662692904472351, Monte Carlo Cost: 1.441631555557251
Epoch 11000, Train Cost 1.1295057535171509, Monte Carlo Cost: 1.4290850162506104
Epoch 12000, Train Cost 0.5545588731765747, Monte Carlo Cost: 1.4240986108779907
Epoch 13000, Train Cost 0.915463387966156, Monte Carlo Cost: 1.4142357110977173
Epoch 14000, Train Cost 1.1769298315048218, Monte Carlo Cost: 1.410193920135498
Epoch 15000, Train Cost 0.8953002691268921, Monte Carlo Cost: 1.4049237966537476
Epoch 16000, Train Cost 1.085465431213379, Monte Carlo Cost: 1.400840401649475
Epoch 17000, Train Cost 1.107620120048523, Monte Carlo Cost: 1.3983614444732666
Epoch 18000, Train Cost 1.179612398147583, Monte Carlo Cost: 1.395740032196045
Epoch 19000, Train Cost 0.9421805143356323, Monte Carlo Cost: 1.3926312923431396
Epoch 20000, Train Cost 1.6421802043914795, Monte Carlo Cost: 1.3952383995056152
Seed 123, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 24.237199783325195, Monte Carlo Cost: 41.6910400390625
Epoch 2000, Train Cost 35.08256912231445, Monte Carlo Cost: 40.23181915283203
Epoch 3000, Train Cost 21.684890747070312, Monte Carlo Cost: 38.824710845947266
Epoch 4000, Train Cost 33.04993438720703, Monte Carlo Cost: 37.45668029785156
Epoch 5000, Train Cost 25.896955490112305, Monte Carlo Cost: 36.135040283203125
Epoch 6000, Train Cost 27.676090240478516, Monte Carlo Cost: 34.85102081298828
Epoch 7000, Train Cost 24.38041877746582, Monte Carlo Cost: 33.60599899291992
Epoch 8000, Train Cost 27.63129234313965, Monte Carlo Cost: 32.392669677734375
Epoch 9000, Train Cost 21.928756713867188, Monte Carlo Cost: 31.205942153930664
Epoch 10000, Train Cost 19.402002334594727, Monte Carlo Cost: 30.071626663208008
Epoch 11000, Train Cost 22.910524368286133, Monte Carlo Cost: 28.971023559570312
Epoch 12000, Train Cost 11.51667308807373, Monte Carlo Cost: 27.902759552001953
Epoch 13000, Train Cost 17.16849136352539, Monte Carlo Cost: 26.85882568359375
Epoch 14000, Train Cost 23.309894561767578, Monte Carlo Cost: 25.833946228027344
Epoch 15000, Train Cost 17.48236656188965, Monte Carlo Cost: 24.838756561279297
Epoch 16000, Train Cost 18.075328826904297, Monte Carlo Cost: 23.890899658203125
Epoch 17000, Train Cost 18.22498893737793, Monte Carlo Cost: 22.97206687927246
Epoch 18000, Train Cost 20.315027236938477, Monte Carlo Cost: 22.076765060424805
Epoch 19000, Train Cost 15.730666160583496, Monte Carlo Cost: 21.216808319091797
Epoch 20000, Train Cost 19.854997634887695, Monte Carlo Cost: 20.377182006835938
Seed 123, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 123
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 69.83989715576172, Monte Carlo Cost: 81.37361145019531
Epoch 2000, Train Cost 72.0126953125, Monte Carlo Cost: 81.35053253173828
Epoch 3000, Train Cost 51.07927322387695, Monte Carlo Cost: 81.32756042480469
Epoch 4000, Train Cost 81.30765533447266, Monte Carlo Cost: 81.30459594726562
Epoch 5000, Train Cost 63.57529067993164, Monte Carlo Cost: 81.28162384033203
Epoch 6000, Train Cost 75.20846557617188, Monte Carlo Cost: 81.2586441040039
Epoch 7000, Train Cost 52.830955505371094, Monte Carlo Cost: 81.2356948852539
Epoch 8000, Train Cost 72.52165985107422, Monte Carlo Cost: 81.21271514892578
Epoch 9000, Train Cost 56.77689743041992, Monte Carlo Cost: 81.18962860107422
Epoch 10000, Train Cost 49.57304382324219, Monte Carlo Cost: 81.16667938232422
Epoch 11000, Train Cost 46.62202072143555, Monte Carlo Cost: 81.14388275146484
Epoch 12000, Train Cost 43.82814407348633, Monte Carlo Cost: 81.12088775634766
Epoch 13000, Train Cost 74.07649993896484, Monte Carlo Cost: 81.09794616699219
Epoch 14000, Train Cost 72.27928924560547, Monte Carlo Cost: 81.07501220703125
Epoch 15000, Train Cost 61.30001449584961, Monte Carlo Cost: 81.05194854736328
Epoch 16000, Train Cost 77.83943176269531, Monte Carlo Cost: 81.02912139892578
Epoch 17000, Train Cost 68.47028350830078, Monte Carlo Cost: 81.00621032714844
Epoch 18000, Train Cost 65.37225341796875, Monte Carlo Cost: 80.9832534790039
Epoch 19000, Train Cost 68.82315063476562, Monte Carlo Cost: 80.96046447753906
Epoch 20000, Train Cost 80.82481384277344, Monte Carlo Cost: 80.9375991821289
Seed 21, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 9.899989128112793, Monte Carlo Cost: 4.768155574798584
Epoch 2000, Train Cost 3.003401041030884, Monte Carlo Cost: 2.3828768730163574
Epoch 3000, Train Cost 1.1101101636886597, Monte Carlo Cost: 1.0929330587387085
Epoch 4000, Train Cost 1.0274841785430908, Monte Carlo Cost: 1.0082108974456787
Epoch 5000, Train Cost 1.1355377435684204, Monte Carlo Cost: 1.0087909698486328
Epoch 6000, Train Cost 1.4666073322296143, Monte Carlo Cost: 1.0046025514602661
Epoch 7000, Train Cost 1.1068785190582275, Monte Carlo Cost: 0.9986267685890198
Epoch 8000, Train Cost 1.256211280822754, Monte Carlo Cost: 0.9884748458862305
Epoch 9000, Train Cost 1.4017138481140137, Monte Carlo Cost: 0.9825612306594849
Epoch 10000, Train Cost 1.2302677631378174, Monte Carlo Cost: 0.9767789244651794
Epoch 11000, Train Cost 0.941479504108429, Monte Carlo Cost: 0.9710012674331665
Epoch 12000, Train Cost 0.8995095491409302, Monte Carlo Cost: 0.9650880098342896
Epoch 13000, Train Cost 0.8097822070121765, Monte Carlo Cost: 0.9600293040275574
Epoch 14000, Train Cost 1.873683214187622, Monte Carlo Cost: 0.9549996256828308
Epoch 15000, Train Cost 1.042829155921936, Monte Carlo Cost: 0.9509987235069275
Epoch 16000, Train Cost 0.8990675210952759, Monte Carlo Cost: 0.9476971626281738
Epoch 17000, Train Cost 1.4481556415557861, Monte Carlo Cost: 0.9432494640350342
Epoch 18000, Train Cost 0.855087161064148, Monte Carlo Cost: 0.9401718974113464
Epoch 19000, Train Cost 1.3302252292633057, Monte Carlo Cost: 0.9384109377861023
Epoch 20000, Train Cost 0.9032168388366699, Monte Carlo Cost: 0.9365280866622925
Seed 21, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 24.254552841186523, Monte Carlo Cost: 17.476848602294922
Epoch 2000, Train Cost 16.410743713378906, Monte Carlo Cost: 13.27560806274414
Epoch 3000, Train Cost 12.49014663696289, Monte Carlo Cost: 10.860931396484375
Epoch 4000, Train Cost 13.00529670715332, Monte Carlo Cost: 9.377340316772461
Epoch 5000, Train Cost 16.258556365966797, Monte Carlo Cost: 8.487408638000488
Epoch 6000, Train Cost 11.510858535766602, Monte Carlo Cost: 7.870347023010254
Epoch 7000, Train Cost 10.036829948425293, Monte Carlo Cost: 7.477198600769043
Epoch 8000, Train Cost 11.955390930175781, Monte Carlo Cost: 7.168118476867676
Epoch 9000, Train Cost 11.704880714416504, Monte Carlo Cost: 6.947804927825928
Epoch 10000, Train Cost 11.60080623626709, Monte Carlo Cost: 6.787027835845947
Epoch 11000, Train Cost 12.84838581085205, Monte Carlo Cost: 6.690211772918701
Epoch 12000, Train Cost 16.678199768066406, Monte Carlo Cost: 6.585816383361816
Epoch 13000, Train Cost 14.619781494140625, Monte Carlo Cost: 6.521682262420654
Epoch 14000, Train Cost 15.499268531799316, Monte Carlo Cost: 6.448323726654053
Epoch 15000, Train Cost 10.056777000427246, Monte Carlo Cost: 6.433135986328125
Epoch 16000, Train Cost 11.13971996307373, Monte Carlo Cost: 6.372339725494385
Epoch 17000, Train Cost 11.943897247314453, Monte Carlo Cost: 6.3544793128967285
Epoch 18000, Train Cost 14.247078895568848, Monte Carlo Cost: 6.295094966888428
Epoch 19000, Train Cost 13.470564842224121, Monte Carlo Cost: 6.247503280639648
Epoch 20000, Train Cost 11.433854103088379, Monte Carlo Cost: 6.184104919433594
Seed 21, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 37.16855239868164, Monte Carlo Cost: 29.621875762939453
Epoch 2000, Train Cost 28.59342384338379, Monte Carlo Cost: 29.467403411865234
Epoch 3000, Train Cost 32.01545715332031, Monte Carlo Cost: 29.313329696655273
Epoch 4000, Train Cost 24.610729217529297, Monte Carlo Cost: 29.160213470458984
Epoch 5000, Train Cost 26.451019287109375, Monte Carlo Cost: 29.009151458740234
Epoch 6000, Train Cost 24.52089500427246, Monte Carlo Cost: 28.858022689819336
Epoch 7000, Train Cost 31.917499542236328, Monte Carlo Cost: 28.710277557373047
Epoch 8000, Train Cost 39.754295349121094, Monte Carlo Cost: 28.562644958496094
Epoch 9000, Train Cost 32.42493438720703, Monte Carlo Cost: 28.416915893554688
Epoch 10000, Train Cost 27.817607879638672, Monte Carlo Cost: 28.27140998840332
Epoch 11000, Train Cost 25.91654396057129, Monte Carlo Cost: 28.12774658203125
Epoch 12000, Train Cost 21.942073822021484, Monte Carlo Cost: 27.983997344970703
Epoch 13000, Train Cost 23.21999168395996, Monte Carlo Cost: 27.841632843017578
Epoch 14000, Train Cost 34.78633499145508, Monte Carlo Cost: 27.700368881225586
Epoch 15000, Train Cost 30.283714294433594, Monte Carlo Cost: 27.561203002929688
Epoch 16000, Train Cost 21.44501495361328, Monte Carlo Cost: 27.4217472076416
Epoch 17000, Train Cost 27.716630935668945, Monte Carlo Cost: 27.285001754760742
Epoch 18000, Train Cost 23.228271484375, Monte Carlo Cost: 27.148839950561523
Epoch 19000, Train Cost 28.291378021240234, Monte Carlo Cost: 27.012365341186523
Epoch 20000, Train Cost 25.704484939575195, Monte Carlo Cost: 26.876298904418945
Seed 21, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 10.940427780151367, Monte Carlo Cost: 5.075660705566406
Epoch 2000, Train Cost 3.7144012451171875, Monte Carlo Cost: 2.8607852458953857
Epoch 3000, Train Cost 1.17021906375885, Monte Carlo Cost: 1.1571507453918457
Epoch 4000, Train Cost 1.0456795692443848, Monte Carlo Cost: 1.000548005104065
Epoch 5000, Train Cost 1.1371772289276123, Monte Carlo Cost: 1.0033533573150635
Epoch 6000, Train Cost 1.4692192077636719, Monte Carlo Cost: 1.0003597736358643
Epoch 7000, Train Cost 1.0788105726242065, Monte Carlo Cost: 0.9954992532730103
Epoch 8000, Train Cost 1.225784182548523, Monte Carlo Cost: 0.9851797223091125
Epoch 9000, Train Cost 1.389016032218933, Monte Carlo Cost: 0.9795544147491455
Epoch 10000, Train Cost 1.2388464212417603, Monte Carlo Cost: 0.9748735427856445
Epoch 11000, Train Cost 0.9368055462837219, Monte Carlo Cost: 0.9687203764915466
Epoch 12000, Train Cost 0.9156289100646973, Monte Carlo Cost: 0.9632032513618469
Epoch 13000, Train Cost 0.8110212087631226, Monte Carlo Cost: 0.9584616422653198
Epoch 14000, Train Cost 1.8868589401245117, Monte Carlo Cost: 0.9531829357147217
Epoch 15000, Train Cost 1.0353848934173584, Monte Carlo Cost: 0.949669361114502
Epoch 16000, Train Cost 0.9098843336105347, Monte Carlo Cost: 0.9463685750961304
Epoch 17000, Train Cost 1.4656760692596436, Monte Carlo Cost: 0.9416842460632324
Epoch 18000, Train Cost 0.8613095879554749, Monte Carlo Cost: 0.9389466643333435
Epoch 19000, Train Cost 1.3546206951141357, Monte Carlo Cost: 0.9372824430465698
Epoch 20000, Train Cost 0.8990193009376526, Monte Carlo Cost: 0.9352335333824158
Seed 21, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 19.364673614501953, Monte Carlo Cost: 12.223726272583008
Epoch 2000, Train Cost 16.10797691345215, Monte Carlo Cost: 10.67493724822998
Epoch 3000, Train Cost 17.939678192138672, Monte Carlo Cost: 9.727524757385254
Epoch 4000, Train Cost 11.563020706176758, Monte Carlo Cost: 9.109515190124512
Epoch 5000, Train Cost 12.497611999511719, Monte Carlo Cost: 8.680132865905762
Epoch 6000, Train Cost 12.959284782409668, Monte Carlo Cost: 8.357717514038086
Epoch 7000, Train Cost 12.211584091186523, Monte Carlo Cost: 8.139592170715332
Epoch 8000, Train Cost 13.40868091583252, Monte Carlo Cost: 7.954887866973877
Epoch 9000, Train Cost 11.452476501464844, Monte Carlo Cost: 7.800117015838623
Epoch 10000, Train Cost 11.223456382751465, Monte Carlo Cost: 7.666370391845703
Epoch 11000, Train Cost 15.766420364379883, Monte Carlo Cost: 7.566019535064697
Epoch 12000, Train Cost 14.972833633422852, Monte Carlo Cost: 7.454750061035156
Epoch 13000, Train Cost 11.603350639343262, Monte Carlo Cost: 7.35316276550293
Epoch 14000, Train Cost 13.143671989440918, Monte Carlo Cost: 7.267592430114746
Epoch 15000, Train Cost 12.991230964660645, Monte Carlo Cost: 7.207813262939453
Epoch 16000, Train Cost 9.082283020019531, Monte Carlo Cost: 7.111081123352051
Epoch 17000, Train Cost 12.353922843933105, Monte Carlo Cost: 7.05979061126709
Epoch 18000, Train Cost 12.875877380371094, Monte Carlo Cost: 6.981817245483398
Epoch 19000, Train Cost 10.03967571258545, Monte Carlo Cost: 6.894949436187744
Epoch 20000, Train Cost 9.925981521606445, Monte Carlo Cost: 6.807214736938477
Seed 21, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 14.67911434173584, Monte Carlo Cost: 5.703322887420654
Epoch 2000, Train Cost 11.975640296936035, Monte Carlo Cost: 5.703108787536621
Epoch 3000, Train Cost 11.678648948669434, Monte Carlo Cost: 5.703042984008789
Perturbing at epoch 3000
Epoch 4000, Train Cost 18.40769386291504, Monte Carlo Cost: 14.57666301727295
Epoch 5000, Train Cost 22.212854385375977, Monte Carlo Cost: 14.52070140838623
Epoch 6000, Train Cost 15.869757652282715, Monte Carlo Cost: 14.463943481445312
Epoch 7000, Train Cost 14.3484468460083, Monte Carlo Cost: 14.408515930175781
Epoch 8000, Train Cost 16.36204719543457, Monte Carlo Cost: 14.352214813232422
Epoch 9000, Train Cost 17.891504287719727, Monte Carlo Cost: 14.296316146850586
Epoch 10000, Train Cost 19.038570404052734, Monte Carlo Cost: 14.240826606750488
Epoch 11000, Train Cost 16.390430450439453, Monte Carlo Cost: 14.18649959564209
Epoch 12000, Train Cost 22.38512420654297, Monte Carlo Cost: 14.131891250610352
Epoch 13000, Train Cost 20.173723220825195, Monte Carlo Cost: 14.078545570373535
Epoch 14000, Train Cost 24.079437255859375, Monte Carlo Cost: 14.02483081817627
Epoch 15000, Train Cost 15.246578216552734, Monte Carlo Cost: 13.973442077636719
Epoch 16000, Train Cost 18.760204315185547, Monte Carlo Cost: 13.921175956726074
Epoch 17000, Train Cost 19.704275131225586, Monte Carlo Cost: 13.870126724243164
Epoch 18000, Train Cost 21.32545280456543, Monte Carlo Cost: 13.818289756774902
Epoch 19000, Train Cost 23.740257263183594, Monte Carlo Cost: 13.767269134521484
Epoch 20000, Train Cost 17.709186553955078, Monte Carlo Cost: 13.715822219848633
Seed 21, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 8.650056838989258, Monte Carlo Cost: 4.122002601623535
Epoch 2000, Train Cost 1.3430976867675781, Monte Carlo Cost: 1.145031213760376
Epoch 3000, Train Cost 1.142778992652893, Monte Carlo Cost: 1.067652940750122
Epoch 4000, Train Cost 0.9558480978012085, Monte Carlo Cost: 1.0066187381744385
Epoch 5000, Train Cost 0.9751349091529846, Monte Carlo Cost: 0.9533997774124146
Epoch 6000, Train Cost 1.082343339920044, Monte Carlo Cost: 0.9277306795120239
Epoch 7000, Train Cost 0.9343057870864868, Monte Carlo Cost: 0.909830629825592
Epoch 8000, Train Cost 1.1226670742034912, Monte Carlo Cost: 0.9007139801979065
Epoch 9000, Train Cost 1.0916248559951782, Monte Carlo Cost: 0.8944491744041443
Epoch 10000, Train Cost 1.0146071910858154, Monte Carlo Cost: 0.889909029006958
Epoch 11000, Train Cost 0.7886863946914673, Monte Carlo Cost: 0.8852972984313965
Epoch 12000, Train Cost 0.8135375380516052, Monte Carlo Cost: 0.885257363319397
Perturbing at epoch 12000
Epoch 13000, Train Cost 0.743206262588501, Monte Carlo Cost: 0.9060520529747009
Epoch 14000, Train Cost 1.3685147762298584, Monte Carlo Cost: 0.8953540921211243
Epoch 15000, Train Cost 0.936720073223114, Monte Carlo Cost: 0.8899954557418823
Epoch 16000, Train Cost 0.7830080986022949, Monte Carlo Cost: 0.887218177318573
Epoch 17000, Train Cost 1.1639869213104248, Monte Carlo Cost: 0.8851316571235657
Epoch 18000, Train Cost 0.7908097505569458, Monte Carlo Cost: 0.8842294216156006
Epoch 19000, Train Cost 1.226085901260376, Monte Carlo Cost: 0.8819689750671387
Epoch 20000, Train Cost 0.8169336318969727, Monte Carlo Cost: 0.8812873363494873
Seed 21, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 39.61838912963867, Monte Carlo Cost: 31.521648406982422
Epoch 2000, Train Cost 32.209693908691406, Monte Carlo Cost: 30.439804077148438
Epoch 3000, Train Cost 25.189456939697266, Monte Carlo Cost: 29.389293670654297
Epoch 4000, Train Cost 30.967710494995117, Monte Carlo Cost: 28.371753692626953
Epoch 5000, Train Cost 25.607255935668945, Monte Carlo Cost: 27.402265548706055
Epoch 6000, Train Cost 22.772724151611328, Monte Carlo Cost: 26.447423934936523
Epoch 7000, Train Cost 22.495161056518555, Monte Carlo Cost: 25.53073501586914
Epoch 8000, Train Cost 27.00457763671875, Monte Carlo Cost: 24.628440856933594
Epoch 9000, Train Cost 27.265295028686523, Monte Carlo Cost: 23.758480072021484
Epoch 10000, Train Cost 26.665468215942383, Monte Carlo Cost: 22.91295623779297
Epoch 11000, Train Cost 19.258956909179688, Monte Carlo Cost: 22.10088539123535
Epoch 12000, Train Cost 21.19577980041504, Monte Carlo Cost: 21.3027400970459
Epoch 13000, Train Cost 16.87386131286621, Monte Carlo Cost: 20.539196014404297
Epoch 14000, Train Cost 28.406005859375, Monte Carlo Cost: 19.789997100830078
Epoch 15000, Train Cost 19.312238693237305, Monte Carlo Cost: 19.076948165893555
Epoch 16000, Train Cost 17.30950927734375, Monte Carlo Cost: 18.37397003173828
Epoch 17000, Train Cost 23.66712760925293, Monte Carlo Cost: 17.698068618774414
Epoch 18000, Train Cost 16.566123962402344, Monte Carlo Cost: 17.034528732299805
Epoch 19000, Train Cost 23.84674835205078, Monte Carlo Cost: 16.39439582824707
Epoch 20000, Train Cost 14.280461311340332, Monte Carlo Cost: 15.771566390991211
Seed 21, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 17.051015853881836, Monte Carlo Cost: 9.966909408569336
Epoch 2000, Train Cost 13.220582962036133, Monte Carlo Cost: 9.963077545166016
Epoch 3000, Train Cost 14.180109977722168, Monte Carlo Cost: 9.959203720092773
Epoch 4000, Train Cost 10.469247817993164, Monte Carlo Cost: 9.955296516418457
Epoch 5000, Train Cost 13.058769226074219, Monte Carlo Cost: 9.951451301574707
Epoch 6000, Train Cost 10.44334888458252, Monte Carlo Cost: 9.94754695892334
Epoch 7000, Train Cost 11.526961326599121, Monte Carlo Cost: 9.943653106689453
Epoch 8000, Train Cost 13.914941787719727, Monte Carlo Cost: 9.939765930175781
Epoch 9000, Train Cost 12.325508117675781, Monte Carlo Cost: 9.935873031616211
Epoch 10000, Train Cost 12.199760437011719, Monte Carlo Cost: 9.932026863098145
Epoch 11000, Train Cost 12.593199729919434, Monte Carlo Cost: 9.92821216583252
Epoch 12000, Train Cost 12.933813095092773, Monte Carlo Cost: 9.924304008483887
Epoch 13000, Train Cost 10.997426986694336, Monte Carlo Cost: 9.92043399810791
Epoch 14000, Train Cost 16.10630226135254, Monte Carlo Cost: 9.916552543640137
Epoch 15000, Train Cost 13.222487449645996, Monte Carlo Cost: 9.912667274475098
Epoch 16000, Train Cost 10.057488441467285, Monte Carlo Cost: 9.908766746520996
Epoch 17000, Train Cost 13.282768249511719, Monte Carlo Cost: 9.905020713806152
Epoch 18000, Train Cost 13.337536811828613, Monte Carlo Cost: 9.90113639831543
Epoch 19000, Train Cost 13.081583976745605, Monte Carlo Cost: 9.897250175476074
Epoch 20000, Train Cost 10.622562408447266, Monte Carlo Cost: 9.893348693847656
Seed 21, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 8.989072799682617, Monte Carlo Cost: 5.455252647399902
Epoch 2000, Train Cost 2.389819860458374, Monte Carlo Cost: 1.7343084812164307
Epoch 3000, Train Cost 1.0123634338378906, Monte Carlo Cost: 1.0038096904754639
Epoch 4000, Train Cost 1.03097403049469, Monte Carlo Cost: 0.9978078603744507
Epoch 5000, Train Cost 1.0397850275039673, Monte Carlo Cost: 0.959456205368042
Epoch 6000, Train Cost 1.1809204816818237, Monte Carlo Cost: 0.9356292486190796
Epoch 7000, Train Cost 0.9270637631416321, Monte Carlo Cost: 0.9151071906089783
Epoch 8000, Train Cost 1.1048569679260254, Monte Carlo Cost: 0.9042299389839172
Epoch 9000, Train Cost 1.1052263975143433, Monte Carlo Cost: 0.8972586393356323
Epoch 10000, Train Cost 1.024259090423584, Monte Carlo Cost: 0.8916434049606323
Epoch 11000, Train Cost 0.7913958430290222, Monte Carlo Cost: 0.8867325782775879
Epoch 12000, Train Cost 0.8159142136573792, Monte Carlo Cost: 0.8864782452583313
Epoch 13000, Train Cost 0.7249614000320435, Monte Carlo Cost: 0.888552725315094
Epoch 14000, Train Cost 1.3278247117996216, Monte Carlo Cost: 0.8840445280075073
Epoch 15000, Train Cost 0.9178864359855652, Monte Carlo Cost: 0.8831582069396973
Epoch 16000, Train Cost 0.7876174449920654, Monte Carlo Cost: 0.8827508091926575
Epoch 17000, Train Cost 1.1584751605987549, Monte Carlo Cost: 0.8821910619735718
Epoch 18000, Train Cost 0.7893587350845337, Monte Carlo Cost: 0.8818073868751526
Epoch 19000, Train Cost 1.223174810409546, Monte Carlo Cost: 0.8803542256355286
Epoch 20000, Train Cost 0.8152559995651245, Monte Carlo Cost: 0.8799501061439514
Seed 21, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 52.03043746948242, Monte Carlo Cost: 40.79751205444336
Epoch 2000, Train Cost 41.44246292114258, Monte Carlo Cost: 39.539608001708984
Epoch 3000, Train Cost 35.61735916137695, Monte Carlo Cost: 38.29929733276367
Epoch 4000, Train Cost 38.98530197143555, Monte Carlo Cost: 37.092308044433594
Epoch 5000, Train Cost 30.982433319091797, Monte Carlo Cost: 35.927730560302734
Epoch 6000, Train Cost 31.59086036682129, Monte Carlo Cost: 34.778900146484375
Epoch 7000, Train Cost 34.523651123046875, Monte Carlo Cost: 33.670021057128906
Epoch 8000, Train Cost 43.40681076049805, Monte Carlo Cost: 32.57477569580078
Epoch 9000, Train Cost 39.022518157958984, Monte Carlo Cost: 31.51118278503418
Epoch 10000, Train Cost 34.40896224975586, Monte Carlo Cost: 30.47129249572754
Epoch 11000, Train Cost 27.510536193847656, Monte Carlo Cost: 29.46379852294922
Epoch 12000, Train Cost 26.869909286499023, Monte Carlo Cost: 28.47103500366211
Epoch 13000, Train Cost 23.264516830444336, Monte Carlo Cost: 27.512218475341797
Epoch 14000, Train Cost 37.16447830200195, Monte Carlo Cost: 26.572105407714844
Epoch 15000, Train Cost 26.734697341918945, Monte Carlo Cost: 25.6668701171875
Epoch 16000, Train Cost 22.07745933532715, Monte Carlo Cost: 24.77444076538086
Epoch 17000, Train Cost 31.8314266204834, Monte Carlo Cost: 23.913440704345703
Epoch 18000, Train Cost 19.606792449951172, Monte Carlo Cost: 23.066272735595703
Epoch 19000, Train Cost 31.6593017578125, Monte Carlo Cost: 22.240976333618164
Epoch 20000, Train Cost 20.675403594970703, Monte Carlo Cost: 21.436588287353516
Seed 21, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 21
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 55.43559646606445, Monte Carlo Cost: 43.42726516723633
Epoch 2000, Train Cost 45.18562316894531, Monte Carlo Cost: 43.416324615478516
Epoch 3000, Train Cost 41.60780715942383, Monte Carlo Cost: 43.40530776977539
Epoch 4000, Train Cost 44.91427230834961, Monte Carlo Cost: 43.39431381225586
Epoch 5000, Train Cost 37.31975555419922, Monte Carlo Cost: 43.38332748413086
Epoch 6000, Train Cost 40.60128402709961, Monte Carlo Cost: 43.372314453125
Epoch 7000, Train Cost 47.50059509277344, Monte Carlo Cost: 43.36137390136719
Epoch 8000, Train Cost 62.53042984008789, Monte Carlo Cost: 43.35038375854492
Epoch 9000, Train Cost 55.709999084472656, Monte Carlo Cost: 43.339420318603516
Epoch 10000, Train Cost 48.34947204589844, Monte Carlo Cost: 43.32844924926758
Epoch 11000, Train Cost 43.0256233215332, Monte Carlo Cost: 43.31749725341797
Epoch 12000, Train Cost 41.793739318847656, Monte Carlo Cost: 43.306514739990234
Epoch 13000, Train Cost 40.19121551513672, Monte Carlo Cost: 43.2955207824707
Epoch 14000, Train Cost 60.0677490234375, Monte Carlo Cost: 43.28457260131836
Epoch 15000, Train Cost 46.44485092163086, Monte Carlo Cost: 43.27362060546875
Epoch 16000, Train Cost 39.10797119140625, Monte Carlo Cost: 43.26261520385742
Epoch 17000, Train Cost 57.6942024230957, Monte Carlo Cost: 43.251686096191406
Epoch 18000, Train Cost 35.826541900634766, Monte Carlo Cost: 43.24075698852539
Epoch 19000, Train Cost 62.33489227294922, Monte Carlo Cost: 43.22976303100586
Epoch 20000, Train Cost 48.20168685913086, Monte Carlo Cost: 43.218780517578125
Seed 70, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 6.0710368156433105, Monte Carlo Cost: 6.95919942855835
Epoch 2000, Train Cost 5.572756767272949, Monte Carlo Cost: 4.962350845336914
Epoch 3000, Train Cost 1.9076464176177979, Monte Carlo Cost: 3.01511812210083
Epoch 4000, Train Cost 1.1353118419647217, Monte Carlo Cost: 2.5802440643310547
Epoch 5000, Train Cost 1.0897306203842163, Monte Carlo Cost: 2.434558391571045
Epoch 6000, Train Cost 1.348802924156189, Monte Carlo Cost: 2.356767416000366
Epoch 7000, Train Cost 1.6847045421600342, Monte Carlo Cost: 2.318446159362793
Epoch 8000, Train Cost 0.9470330476760864, Monte Carlo Cost: 2.2587335109710693
Epoch 9000, Train Cost 2.3089241981506348, Monte Carlo Cost: 2.198500156402588
Epoch 10000, Train Cost 0.9942196011543274, Monte Carlo Cost: 2.1618406772613525
Epoch 11000, Train Cost 1.3841729164123535, Monte Carlo Cost: 2.1133742332458496
Epoch 12000, Train Cost 1.276671051979065, Monte Carlo Cost: 2.071483850479126
Epoch 13000, Train Cost 1.7735579013824463, Monte Carlo Cost: 2.0381641387939453
Epoch 14000, Train Cost 1.336820125579834, Monte Carlo Cost: 2.012444496154785
Epoch 15000, Train Cost 0.9939765930175781, Monte Carlo Cost: 1.972093105316162
Epoch 16000, Train Cost 1.0123610496520996, Monte Carlo Cost: 1.9420762062072754
Epoch 17000, Train Cost 1.0964792966842651, Monte Carlo Cost: 1.915163516998291
Epoch 18000, Train Cost 1.2013685703277588, Monte Carlo Cost: 1.880030632019043
Epoch 19000, Train Cost 0.7045454978942871, Monte Carlo Cost: 1.8612232208251953
Epoch 20000, Train Cost 0.9174062013626099, Monte Carlo Cost: 1.8321120738983154
Seed 70, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 22.95236587524414, Monte Carlo Cost: 27.48371696472168
Epoch 2000, Train Cost 24.34405517578125, Monte Carlo Cost: 19.14516258239746
Epoch 3000, Train Cost 14.442453384399414, Monte Carlo Cost: 14.668505668640137
Epoch 4000, Train Cost 12.872003555297852, Monte Carlo Cost: 12.115607261657715
Epoch 5000, Train Cost 12.911261558532715, Monte Carlo Cost: 10.524307250976562
Epoch 6000, Train Cost 18.27737045288086, Monte Carlo Cost: 9.578232765197754
Epoch 7000, Train Cost 15.087265968322754, Monte Carlo Cost: 9.008220672607422
Epoch 8000, Train Cost 12.50922679901123, Monte Carlo Cost: 8.624606132507324
Epoch 9000, Train Cost 17.026927947998047, Monte Carlo Cost: 8.347293853759766
Epoch 10000, Train Cost 13.027713775634766, Monte Carlo Cost: 8.176570892333984
Epoch 11000, Train Cost 12.357758522033691, Monte Carlo Cost: 8.048352241516113
Epoch 12000, Train Cost 12.224059104919434, Monte Carlo Cost: 8.000061988830566
Epoch 13000, Train Cost 16.19886016845703, Monte Carlo Cost: 7.939888000488281
Epoch 14000, Train Cost 12.783281326293945, Monte Carlo Cost: 7.928569793701172
Epoch 15000, Train Cost 8.810497283935547, Monte Carlo Cost: 7.871989727020264
Epoch 16000, Train Cost 9.618911743164062, Monte Carlo Cost: 7.845757961273193
Epoch 17000, Train Cost 15.078628540039062, Monte Carlo Cost: 7.842094898223877
Epoch 18000, Train Cost 10.714668273925781, Monte Carlo Cost: 7.8006110191345215
Epoch 19000, Train Cost 8.558229446411133, Monte Carlo Cost: 7.810360908508301
Epoch 20000, Train Cost 14.791008949279785, Monte Carlo Cost: 7.784215450286865
Seed 70, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 21.87712287902832, Monte Carlo Cost: 28.484243392944336
Epoch 2000, Train Cost 31.88741111755371, Monte Carlo Cost: 28.398101806640625
Epoch 3000, Train Cost 23.77341651916504, Monte Carlo Cost: 28.31329345703125
Epoch 4000, Train Cost 19.486804962158203, Monte Carlo Cost: 28.228965759277344
Epoch 5000, Train Cost 19.91261100769043, Monte Carlo Cost: 28.143611907958984
Epoch 6000, Train Cost 25.21903419494629, Monte Carlo Cost: 28.059986114501953
Epoch 7000, Train Cost 27.598417282104492, Monte Carlo Cost: 27.977258682250977
Epoch 8000, Train Cost 19.128551483154297, Monte Carlo Cost: 27.894149780273438
Epoch 9000, Train Cost 26.222620010375977, Monte Carlo Cost: 27.812246322631836
Epoch 10000, Train Cost 20.334815979003906, Monte Carlo Cost: 27.730504989624023
Epoch 11000, Train Cost 25.843761444091797, Monte Carlo Cost: 27.648462295532227
Epoch 12000, Train Cost 26.440105438232422, Monte Carlo Cost: 27.568117141723633
Epoch 13000, Train Cost 33.5969123840332, Monte Carlo Cost: 27.487131118774414
Epoch 14000, Train Cost 25.61264419555664, Monte Carlo Cost: 27.408227920532227
Epoch 15000, Train Cost 19.893199920654297, Monte Carlo Cost: 27.328325271606445
Epoch 16000, Train Cost 19.665468215942383, Monte Carlo Cost: 27.248334884643555
Epoch 17000, Train Cost 24.483074188232422, Monte Carlo Cost: 27.17043113708496
Epoch 18000, Train Cost 20.631078720092773, Monte Carlo Cost: 27.091171264648438
Epoch 19000, Train Cost 14.339518547058105, Monte Carlo Cost: 27.013124465942383
Epoch 20000, Train Cost 18.707143783569336, Monte Carlo Cost: 26.934965133666992
Seed 70, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.344490051269531, Monte Carlo Cost: 6.635697841644287
Epoch 2000, Train Cost 4.541674613952637, Monte Carlo Cost: 4.422781467437744
Epoch 3000, Train Cost 1.783528447151184, Monte Carlo Cost: 2.828782558441162
Epoch 4000, Train Cost 1.1683552265167236, Monte Carlo Cost: 2.5206689834594727
Epoch 5000, Train Cost 1.1029719114303589, Monte Carlo Cost: 2.392709255218506
Epoch 6000, Train Cost 1.3788371086120605, Monte Carlo Cost: 2.3171846866607666
Epoch 7000, Train Cost 1.6238071918487549, Monte Carlo Cost: 2.278911590576172
Epoch 8000, Train Cost 0.9254655838012695, Monte Carlo Cost: 2.2196273803710938
Epoch 9000, Train Cost 2.379507541656494, Monte Carlo Cost: 2.158700466156006
Epoch 10000, Train Cost 0.9886667728424072, Monte Carlo Cost: 2.1221811771392822
Epoch 11000, Train Cost 1.3660577535629272, Monte Carlo Cost: 2.073787212371826
Epoch 12000, Train Cost 1.275815486907959, Monte Carlo Cost: 2.031277656555176
Epoch 13000, Train Cost 1.7274705171585083, Monte Carlo Cost: 1.998610019683838
Epoch 14000, Train Cost 1.338613510131836, Monte Carlo Cost: 1.9725675582885742
Epoch 15000, Train Cost 0.9447911381721497, Monte Carlo Cost: 1.9323294162750244
Epoch 16000, Train Cost 0.9819602370262146, Monte Carlo Cost: 1.9025630950927734
Epoch 17000, Train Cost 1.1135683059692383, Monte Carlo Cost: 1.8763158321380615
Epoch 18000, Train Cost 1.1820859909057617, Monte Carlo Cost: 1.8408622741699219
Epoch 19000, Train Cost 0.6784148216247559, Monte Carlo Cost: 1.8230587244033813
Epoch 20000, Train Cost 0.9129836559295654, Monte Carlo Cost: 1.7934309244155884
Seed 70, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 16.25286293029785, Monte Carlo Cost: 21.241159439086914
Epoch 2000, Train Cost 20.067890167236328, Monte Carlo Cost: 16.0090274810791
Epoch 3000, Train Cost 13.223783493041992, Monte Carlo Cost: 13.170211791992188
Epoch 4000, Train Cost 9.758270263671875, Monte Carlo Cost: 11.528459548950195
Epoch 5000, Train Cost 13.441965103149414, Monte Carlo Cost: 10.494552612304688
Epoch 6000, Train Cost 17.593833923339844, Monte Carlo Cost: 9.861734390258789
Epoch 7000, Train Cost 16.37435531616211, Monte Carlo Cost: 9.5023775100708
Epoch 8000, Train Cost 13.421871185302734, Monte Carlo Cost: 9.257184028625488
Epoch 9000, Train Cost 14.829366683959961, Monte Carlo Cost: 9.06448745727539
Epoch 10000, Train Cost 12.690468788146973, Monte Carlo Cost: 8.949602127075195
Epoch 11000, Train Cost 13.536128044128418, Monte Carlo Cost: 8.828873634338379
Epoch 12000, Train Cost 13.671874046325684, Monte Carlo Cost: 8.790604591369629
Epoch 13000, Train Cost 16.535724639892578, Monte Carlo Cost: 8.737761497497559
Epoch 14000, Train Cost 12.787443161010742, Monte Carlo Cost: 8.728872299194336
Epoch 15000, Train Cost 10.92697811126709, Monte Carlo Cost: 8.6527738571167
Epoch 16000, Train Cost 10.392066955566406, Monte Carlo Cost: 8.635603904724121
Epoch 17000, Train Cost 14.801441192626953, Monte Carlo Cost: 8.601481437683105
Epoch 18000, Train Cost 11.147907257080078, Monte Carlo Cost: 8.546640396118164
Epoch 19000, Train Cost 10.349713325500488, Monte Carlo Cost: 8.550278663635254
Epoch 20000, Train Cost 16.68767547607422, Monte Carlo Cost: 8.498780250549316
Seed 70, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 42.81045913696289, Monte Carlo Cost: 43.26450729370117
Epoch 2000, Train Cost 53.71754455566406, Monte Carlo Cost: 43.00031280517578
Epoch 3000, Train Cost 45.03490447998047, Monte Carlo Cost: 42.741233825683594
Epoch 4000, Train Cost 45.37812423706055, Monte Carlo Cost: 42.48640441894531
Epoch 5000, Train Cost 41.20104217529297, Monte Carlo Cost: 42.22737503051758
Epoch 6000, Train Cost 47.651371002197266, Monte Carlo Cost: 41.977027893066406
Epoch 7000, Train Cost 38.428794860839844, Monte Carlo Cost: 41.727725982666016
Epoch 8000, Train Cost 33.335479736328125, Monte Carlo Cost: 41.479400634765625
Epoch 9000, Train Cost 51.119693756103516, Monte Carlo Cost: 41.23481750488281
Epoch 10000, Train Cost 37.62368392944336, Monte Carlo Cost: 40.99188995361328
Epoch 11000, Train Cost 43.788448333740234, Monte Carlo Cost: 40.74970245361328
Epoch 12000, Train Cost 49.16883087158203, Monte Carlo Cost: 40.5122184753418
Epoch 13000, Train Cost 48.61184310913086, Monte Carlo Cost: 40.274654388427734
Epoch 14000, Train Cost 44.115108489990234, Monte Carlo Cost: 40.04257583618164
Epoch 15000, Train Cost 28.614086151123047, Monte Carlo Cost: 39.809635162353516
Epoch 16000, Train Cost 32.437808990478516, Monte Carlo Cost: 39.57803726196289
Epoch 17000, Train Cost 46.7435188293457, Monte Carlo Cost: 39.35088348388672
Epoch 18000, Train Cost 36.001461029052734, Monte Carlo Cost: 39.123741149902344
Epoch 19000, Train Cost 26.82057762145996, Monte Carlo Cost: 38.899044036865234
Epoch 20000, Train Cost 33.35544204711914, Monte Carlo Cost: 38.675960540771484
Seed 70, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.068839073181152, Monte Carlo Cost: 6.554555416107178
Epoch 2000, Train Cost 2.5929183959960938, Monte Carlo Cost: 3.1261234283447266
Epoch 3000, Train Cost 1.6191039085388184, Monte Carlo Cost: 2.5673763751983643
Epoch 4000, Train Cost 1.0037729740142822, Monte Carlo Cost: 2.2496492862701416
Epoch 5000, Train Cost 0.9381387829780579, Monte Carlo Cost: 1.9294489622116089
Epoch 6000, Train Cost 1.119269847869873, Monte Carlo Cost: 1.7027785778045654
Epoch 7000, Train Cost 1.3127543926239014, Monte Carlo Cost: 1.5645751953125
Epoch 8000, Train Cost 0.8130853772163391, Monte Carlo Cost: 1.4555416107177734
Epoch 9000, Train Cost 1.4017815589904785, Monte Carlo Cost: 1.3877991437911987
Epoch 10000, Train Cost 0.8525320291519165, Monte Carlo Cost: 1.345285177230835
Epoch 11000, Train Cost 1.1013380289077759, Monte Carlo Cost: 1.3157955408096313
Epoch 12000, Train Cost 1.106266975402832, Monte Carlo Cost: 1.2920079231262207
Epoch 13000, Train Cost 1.4290159940719604, Monte Carlo Cost: 1.2726532220840454
Epoch 14000, Train Cost 1.0876481533050537, Monte Carlo Cost: 1.2613338232040405
Epoch 15000, Train Cost 0.8444223403930664, Monte Carlo Cost: 1.2460821866989136
Epoch 16000, Train Cost 0.8365797400474548, Monte Carlo Cost: 1.235654354095459
Epoch 17000, Train Cost 1.017493486404419, Monte Carlo Cost: 1.2287379503250122
Epoch 18000, Train Cost 0.90135258436203, Monte Carlo Cost: 1.2172179222106934
Epoch 19000, Train Cost 0.6175057888031006, Monte Carlo Cost: 1.212820053100586
Epoch 20000, Train Cost 0.7902600169181824, Monte Carlo Cost: 1.2057974338531494
Seed 70, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 42.45685577392578, Monte Carlo Cost: 56.08517074584961
Epoch 2000, Train Cost 54.81756591796875, Monte Carlo Cost: 54.151466369628906
Epoch 3000, Train Cost 40.109798431396484, Monte Carlo Cost: 52.296695709228516
Epoch 4000, Train Cost 30.928770065307617, Monte Carlo Cost: 50.49600601196289
Epoch 5000, Train Cost 27.98335075378418, Monte Carlo Cost: 48.7760124206543
Epoch 6000, Train Cost 30.9873104095459, Monte Carlo Cost: 47.10173797607422
Epoch 7000, Train Cost 44.9481315612793, Monte Carlo Cost: 45.50242614746094
Epoch 8000, Train Cost 28.81234359741211, Monte Carlo Cost: 43.94060516357422
Epoch 9000, Train Cost 30.033222198486328, Monte Carlo Cost: 42.445709228515625
Epoch 10000, Train Cost 27.577669143676758, Monte Carlo Cost: 40.99081802368164
Epoch 11000, Train Cost 34.45120620727539, Monte Carlo Cost: 39.58259963989258
Epoch 12000, Train Cost 31.697654724121094, Monte Carlo Cost: 38.22461700439453
Epoch 13000, Train Cost 42.624969482421875, Monte Carlo Cost: 36.90904998779297
Epoch 14000, Train Cost 29.863561630249023, Monte Carlo Cost: 35.64835739135742
Epoch 15000, Train Cost 27.134267807006836, Monte Carlo Cost: 34.41698455810547
Epoch 16000, Train Cost 24.512704849243164, Monte Carlo Cost: 33.22360610961914
Epoch 17000, Train Cost 22.641555786132812, Monte Carlo Cost: 32.08564376831055
Epoch 18000, Train Cost 22.29460906982422, Monte Carlo Cost: 30.96568489074707
Epoch 19000, Train Cost 16.866025924682617, Monte Carlo Cost: 29.89540672302246
Epoch 20000, Train Cost 17.586698532104492, Monte Carlo Cost: 28.856918334960938
Seed 70, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 24.83441162109375, Monte Carlo Cost: 34.17716598510742
Epoch 2000, Train Cost 34.99024200439453, Monte Carlo Cost: 34.16565704345703
Epoch 3000, Train Cost 26.598848342895508, Monte Carlo Cost: 34.154151916503906
Epoch 4000, Train Cost 19.439525604248047, Monte Carlo Cost: 34.14259719848633
Epoch 5000, Train Cost 21.25950813293457, Monte Carlo Cost: 34.13118362426758
Epoch 6000, Train Cost 25.46855354309082, Monte Carlo Cost: 34.119625091552734
Epoch 7000, Train Cost 34.141639709472656, Monte Carlo Cost: 34.108184814453125
Epoch 8000, Train Cost 22.9099063873291, Monte Carlo Cost: 34.09667205810547
Epoch 9000, Train Cost 25.645570755004883, Monte Carlo Cost: 34.08523178100586
Epoch 10000, Train Cost 23.072919845581055, Monte Carlo Cost: 34.07374954223633
Epoch 11000, Train Cost 30.114965438842773, Monte Carlo Cost: 34.062286376953125
Epoch 12000, Train Cost 29.19290542602539, Monte Carlo Cost: 34.05083084106445
Epoch 13000, Train Cost 39.749961853027344, Monte Carlo Cost: 34.039371490478516
Epoch 14000, Train Cost 29.036170959472656, Monte Carlo Cost: 34.02793502807617
Epoch 15000, Train Cost 27.14336395263672, Monte Carlo Cost: 34.01648712158203
Epoch 16000, Train Cost 25.05487823486328, Monte Carlo Cost: 34.00497055053711
Epoch 17000, Train Cost 25.077945709228516, Monte Carlo Cost: 33.993614196777344
Epoch 18000, Train Cost 24.69275665283203, Monte Carlo Cost: 33.98212814331055
Epoch 19000, Train Cost 19.606889724731445, Monte Carlo Cost: 33.97072219848633
Epoch 20000, Train Cost 21.781463623046875, Monte Carlo Cost: 33.95929718017578
Seed 70, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 4.072515964508057, Monte Carlo Cost: 5.482739448547363
Epoch 2000, Train Cost 2.0070362091064453, Monte Carlo Cost: 2.6154487133026123
Epoch 3000, Train Cost 1.4851840734481812, Monte Carlo Cost: 2.268185615539551
Epoch 4000, Train Cost 0.9973758459091187, Monte Carlo Cost: 1.9739211797714233
Epoch 5000, Train Cost 0.9114908576011658, Monte Carlo Cost: 1.7180836200714111
Epoch 6000, Train Cost 1.1155585050582886, Monte Carlo Cost: 1.5623705387115479
Epoch 7000, Train Cost 1.2444641590118408, Monte Carlo Cost: 1.4711815118789673
Epoch 8000, Train Cost 0.8029821515083313, Monte Carlo Cost: 1.39572274684906
Epoch 9000, Train Cost 1.3834409713745117, Monte Carlo Cost: 1.3494317531585693
Epoch 10000, Train Cost 0.8497352004051208, Monte Carlo Cost: 1.3191416263580322
Epoch 11000, Train Cost 1.097219467163086, Monte Carlo Cost: 1.2967653274536133
Epoch 12000, Train Cost 1.1046528816223145, Monte Carlo Cost: 1.2777916193008423
Epoch 13000, Train Cost 1.423216700553894, Monte Carlo Cost: 1.2611684799194336
Epoch 14000, Train Cost 1.0868483781814575, Monte Carlo Cost: 1.2522000074386597
Epoch 15000, Train Cost 0.8446044325828552, Monte Carlo Cost: 1.2388415336608887
Epoch 16000, Train Cost 0.8354911804199219, Monte Carlo Cost: 1.2293355464935303
Epoch 17000, Train Cost 1.0162715911865234, Monte Carlo Cost: 1.2231935262680054
Epoch 18000, Train Cost 0.8978499174118042, Monte Carlo Cost: 1.212640404701233
Epoch 19000, Train Cost 0.6174305081367493, Monte Carlo Cost: 1.2084481716156006
Epoch 20000, Train Cost 0.7899426221847534, Monte Carlo Cost: 1.2024521827697754
Seed 70, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 13.837177276611328, Monte Carlo Cost: 15.510846138000488
Epoch 2000, Train Cost 21.512266159057617, Monte Carlo Cost: 14.85127067565918
Epoch 3000, Train Cost 14.704713821411133, Monte Carlo Cost: 14.235234260559082
Epoch 4000, Train Cost 14.813966751098633, Monte Carlo Cost: 13.649800300598145
Epoch 5000, Train Cost 14.506635665893555, Monte Carlo Cost: 13.077771186828613
Epoch 6000, Train Cost 20.343402862548828, Monte Carlo Cost: 12.54362964630127
Epoch 7000, Train Cost 16.666706085205078, Monte Carlo Cost: 12.040499687194824
Epoch 8000, Train Cost 13.392656326293945, Monte Carlo Cost: 11.55828857421875
Epoch 9000, Train Cost 19.177017211914062, Monte Carlo Cost: 11.099579811096191
Epoch 10000, Train Cost 13.95453929901123, Monte Carlo Cost: 10.671141624450684
Epoch 11000, Train Cost 13.582836151123047, Monte Carlo Cost: 10.267090797424316
Epoch 12000, Train Cost 13.362751007080078, Monte Carlo Cost: 9.912300109863281
Epoch 13000, Train Cost 17.532085418701172, Monte Carlo Cost: 9.576471328735352
Epoch 14000, Train Cost 13.792399406433105, Monte Carlo Cost: 9.290886878967285
Epoch 15000, Train Cost 9.154091835021973, Monte Carlo Cost: 9.013071060180664
Epoch 16000, Train Cost 10.055646896362305, Monte Carlo Cost: 8.779544830322266
Epoch 17000, Train Cost 15.8190336227417, Monte Carlo Cost: 8.585556983947754
Epoch 18000, Train Cost 11.152593612670898, Monte Carlo Cost: 8.402819633483887
Epoch 19000, Train Cost 8.619091987609863, Monte Carlo Cost: 8.267546653747559
Epoch 20000, Train Cost 15.001005172729492, Monte Carlo Cost: 8.138176918029785
Seed 70, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 70
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 14.086686134338379, Monte Carlo Cost: 18.140871047973633
Epoch 2000, Train Cost 20.504257202148438, Monte Carlo Cost: 18.132291793823242
Epoch 3000, Train Cost 16.923316955566406, Monte Carlo Cost: 18.12368392944336
Epoch 4000, Train Cost 10.75284194946289, Monte Carlo Cost: 18.115060806274414
Epoch 5000, Train Cost 16.898006439208984, Monte Carlo Cost: 18.106504440307617
Epoch 6000, Train Cost 20.266674041748047, Monte Carlo Cost: 18.09787368774414
Epoch 7000, Train Cost 22.70315170288086, Monte Carlo Cost: 18.089323043823242
Epoch 8000, Train Cost 17.259876251220703, Monte Carlo Cost: 18.080751419067383
Epoch 9000, Train Cost 17.193639755249023, Monte Carlo Cost: 18.072179794311523
Epoch 10000, Train Cost 15.711932182312012, Monte Carlo Cost: 18.063602447509766
Epoch 11000, Train Cost 19.298860549926758, Monte Carlo Cost: 18.0550537109375
Epoch 12000, Train Cost 19.135129928588867, Monte Carlo Cost: 18.0465030670166
Epoch 13000, Train Cost 23.7110538482666, Monte Carlo Cost: 18.03795051574707
Epoch 14000, Train Cost 17.811676025390625, Monte Carlo Cost: 18.029415130615234
Epoch 15000, Train Cost 17.80615234375, Monte Carlo Cost: 18.020854949951172
Epoch 16000, Train Cost 15.419881820678711, Monte Carlo Cost: 18.012258529663086
Epoch 17000, Train Cost 17.77873420715332, Monte Carlo Cost: 18.003782272338867
Epoch 18000, Train Cost 15.562193870544434, Monte Carlo Cost: 17.995197296142578
Epoch 19000, Train Cost 14.069635391235352, Monte Carlo Cost: 17.986724853515625
Epoch 20000, Train Cost 19.660646438598633, Monte Carlo Cost: 17.978199005126953
Seed 129, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.067474842071533, Monte Carlo Cost: 4.108397960662842
Epoch 2000, Train Cost 2.627575397491455, Monte Carlo Cost: 1.7457672357559204
Epoch 3000, Train Cost 0.7222010493278503, Monte Carlo Cost: 0.8100440502166748
Epoch 4000, Train Cost 1.9192147254943848, Monte Carlo Cost: 0.7846235036849976
Epoch 5000, Train Cost 1.2667008638381958, Monte Carlo Cost: 0.7949028611183167
Epoch 6000, Train Cost 1.456500768661499, Monte Carlo Cost: 0.7903634905815125
Epoch 7000, Train Cost 0.8863981366157532, Monte Carlo Cost: 0.7839087247848511
Epoch 8000, Train Cost 1.1852658987045288, Monte Carlo Cost: 0.7795997858047485
Epoch 9000, Train Cost 0.9415540099143982, Monte Carlo Cost: 0.7704890370368958
Epoch 10000, Train Cost 1.0836073160171509, Monte Carlo Cost: 0.7638876438140869
Epoch 11000, Train Cost 1.384619116783142, Monte Carlo Cost: 0.7629776000976562
Epoch 12000, Train Cost 1.934958815574646, Monte Carlo Cost: 0.756386935710907
Epoch 13000, Train Cost 1.2576178312301636, Monte Carlo Cost: 0.7501154541969299
Epoch 14000, Train Cost 0.6816624402999878, Monte Carlo Cost: 0.746902585029602
Epoch 15000, Train Cost 1.1357284784317017, Monte Carlo Cost: 0.7461674213409424
Epoch 16000, Train Cost 1.332513451576233, Monte Carlo Cost: 0.7422899007797241
Epoch 17000, Train Cost 1.8546819686889648, Monte Carlo Cost: 0.7410038709640503
Epoch 18000, Train Cost 1.4325050115585327, Monte Carlo Cost: 0.7375649213790894
Epoch 19000, Train Cost 0.8199833035469055, Monte Carlo Cost: 0.7373398542404175
Epoch 20000, Train Cost 0.8101125955581665, Monte Carlo Cost: 0.7344679236412048
Seed 129, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 43.533931732177734, Monte Carlo Cost: 21.95194435119629
Epoch 2000, Train Cost 24.12786102294922, Monte Carlo Cost: 15.05700397491455
Epoch 3000, Train Cost 15.63778018951416, Monte Carlo Cost: 11.382281303405762
Epoch 4000, Train Cost 13.398611068725586, Monte Carlo Cost: 9.312634468078613
Epoch 5000, Train Cost 18.442995071411133, Monte Carlo Cost: 8.105572700500488
Epoch 6000, Train Cost 15.111350059509277, Monte Carlo Cost: 7.362329483032227
Epoch 7000, Train Cost 13.170090675354004, Monte Carlo Cost: 6.870655059814453
Epoch 8000, Train Cost 11.109723091125488, Monte Carlo Cost: 6.529122352600098
Epoch 9000, Train Cost 15.686583518981934, Monte Carlo Cost: 6.292572021484375
Epoch 10000, Train Cost 12.394841194152832, Monte Carlo Cost: 6.125974178314209
Epoch 11000, Train Cost 19.787715911865234, Monte Carlo Cost: 5.99575138092041
Epoch 12000, Train Cost 12.224737167358398, Monte Carlo Cost: 5.9088521003723145
Epoch 13000, Train Cost 10.178004264831543, Monte Carlo Cost: 5.849131107330322
Epoch 14000, Train Cost 11.402341842651367, Monte Carlo Cost: 5.785269260406494
Epoch 15000, Train Cost 13.147753715515137, Monte Carlo Cost: 5.733135223388672
Epoch 16000, Train Cost 15.586685180664062, Monte Carlo Cost: 5.694974422454834
Epoch 17000, Train Cost 13.286359786987305, Monte Carlo Cost: 5.650656223297119
Epoch 18000, Train Cost 15.139918327331543, Monte Carlo Cost: 5.633190155029297
Epoch 19000, Train Cost 11.01697826385498, Monte Carlo Cost: 5.6049089431762695
Epoch 20000, Train Cost 15.496927261352539, Monte Carlo Cost: 5.579882621765137
Seed 129, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 16.013561248779297, Monte Carlo Cost: 10.328516960144043
Epoch 2000, Train Cost 16.929758071899414, Monte Carlo Cost: 10.301193237304688
Epoch 3000, Train Cost 15.433475494384766, Monte Carlo Cost: 10.274273872375488
Epoch 4000, Train Cost 14.476402282714844, Monte Carlo Cost: 10.24736213684082
Epoch 5000, Train Cost 20.945798873901367, Monte Carlo Cost: 10.221004486083984
Epoch 6000, Train Cost 18.24311637878418, Monte Carlo Cost: 10.1947021484375
Epoch 7000, Train Cost 14.769180297851562, Monte Carlo Cost: 10.168299674987793
Epoch 8000, Train Cost 14.749431610107422, Monte Carlo Cost: 10.14166259765625
Epoch 9000, Train Cost 17.279516220092773, Monte Carlo Cost: 10.11546516418457
Epoch 10000, Train Cost 15.4812593460083, Monte Carlo Cost: 10.089183807373047
Epoch 11000, Train Cost 23.801321029663086, Monte Carlo Cost: 10.062926292419434
Epoch 12000, Train Cost 17.392004013061523, Monte Carlo Cost: 10.037086486816406
Epoch 13000, Train Cost 16.266817092895508, Monte Carlo Cost: 10.0116548538208
Epoch 14000, Train Cost 12.430459022521973, Monte Carlo Cost: 9.986140251159668
Epoch 15000, Train Cost 17.203739166259766, Monte Carlo Cost: 9.960674285888672
Epoch 16000, Train Cost 20.156551361083984, Monte Carlo Cost: 9.935450553894043
Epoch 17000, Train Cost 20.76612091064453, Monte Carlo Cost: 9.910277366638184
Epoch 18000, Train Cost 19.798099517822266, Monte Carlo Cost: 9.885599136352539
Epoch 19000, Train Cost 13.091455459594727, Monte Carlo Cost: 9.86075496673584
Epoch 20000, Train Cost 17.400344848632812, Monte Carlo Cost: 9.836094856262207
Seed 129, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.42803430557251, Monte Carlo Cost: 4.721582412719727
Epoch 2000, Train Cost 3.1327781677246094, Monte Carlo Cost: 2.2444560527801514
Epoch 3000, Train Cost 0.7534022331237793, Monte Carlo Cost: 0.9875820875167847
Epoch 4000, Train Cost 1.959594964981079, Monte Carlo Cost: 0.9275159239768982
Epoch 5000, Train Cost 1.3292529582977295, Monte Carlo Cost: 0.9345202445983887
Epoch 6000, Train Cost 1.4113497734069824, Monte Carlo Cost: 0.9262509346008301
Epoch 7000, Train Cost 0.9330902695655823, Monte Carlo Cost: 0.9160224199295044
Epoch 8000, Train Cost 1.1514666080474854, Monte Carlo Cost: 0.9084059596061707
Epoch 9000, Train Cost 0.9312319755554199, Monte Carlo Cost: 0.8961077332496643
Epoch 10000, Train Cost 1.0634804964065552, Monte Carlo Cost: 0.8862911462783813
Epoch 11000, Train Cost 1.3074944019317627, Monte Carlo Cost: 0.8814447522163391
Epoch 12000, Train Cost 1.903254747390747, Monte Carlo Cost: 0.8715915679931641
Epoch 13000, Train Cost 1.2421014308929443, Monte Carlo Cost: 0.8619748950004578
Epoch 14000, Train Cost 0.7137632369995117, Monte Carlo Cost: 0.8559579253196716
Epoch 15000, Train Cost 1.0758498907089233, Monte Carlo Cost: 0.8518272638320923
Epoch 16000, Train Cost 1.309745192527771, Monte Carlo Cost: 0.8449141979217529
Epoch 17000, Train Cost 1.8041985034942627, Monte Carlo Cost: 0.8406051993370056
Epoch 18000, Train Cost 1.368605613708496, Monte Carlo Cost: 0.8342097401618958
Epoch 19000, Train Cost 0.8394357562065125, Monte Carlo Cost: 0.8314502835273743
Epoch 20000, Train Cost 0.727154552936554, Monte Carlo Cost: 0.8258510231971741
Seed 129, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 39.12272262573242, Monte Carlo Cost: 18.759565353393555
Epoch 2000, Train Cost 19.89278221130371, Monte Carlo Cost: 12.09668254852295
Epoch 3000, Train Cost 13.932104110717773, Monte Carlo Cost: 8.856635093688965
Epoch 4000, Train Cost 11.092113494873047, Monte Carlo Cost: 7.114015579223633
Epoch 5000, Train Cost 17.12155532836914, Monte Carlo Cost: 6.148549556732178
Epoch 6000, Train Cost 12.328749656677246, Monte Carlo Cost: 5.581010341644287
Epoch 7000, Train Cost 11.193093299865723, Monte Carlo Cost: 5.223970413208008
Epoch 8000, Train Cost 9.096403121948242, Monte Carlo Cost: 4.9906721115112305
Epoch 9000, Train Cost 13.437115669250488, Monte Carlo Cost: 4.836214542388916
Epoch 10000, Train Cost 10.879469871520996, Monte Carlo Cost: 4.745607376098633
Epoch 11000, Train Cost 17.515634536743164, Monte Carlo Cost: 4.680413246154785
Epoch 12000, Train Cost 10.299489974975586, Monte Carlo Cost: 4.648585319519043
Epoch 13000, Train Cost 8.365924835205078, Monte Carlo Cost: 4.637501239776611
Epoch 14000, Train Cost 10.0418062210083, Monte Carlo Cost: 4.619112014770508
Epoch 15000, Train Cost 11.08059310913086, Monte Carlo Cost: 4.609080791473389
Epoch 16000, Train Cost 13.212555885314941, Monte Carlo Cost: 4.605422019958496
Epoch 17000, Train Cost 11.405957221984863, Monte Carlo Cost: 4.604952812194824
Epoch 18000, Train Cost 12.874603271484375, Monte Carlo Cost: 4.613532543182373
Epoch 19000, Train Cost 9.582660675048828, Monte Carlo Cost: 4.614702224731445
Epoch 20000, Train Cost 13.632950782775879, Monte Carlo Cost: 4.620244026184082
Seed 129, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 19.330705642700195, Monte Carlo Cost: 26.86350440979004
Epoch 2000, Train Cost 23.776559829711914, Monte Carlo Cost: 26.77349281311035
Epoch 3000, Train Cost 21.132761001586914, Monte Carlo Cost: 26.682384490966797
Epoch 4000, Train Cost 29.540748596191406, Monte Carlo Cost: 26.593358993530273
Epoch 5000, Train Cost 35.02275085449219, Monte Carlo Cost: 26.50476837158203
Epoch 6000, Train Cost 25.477357864379883, Monte Carlo Cost: 26.415138244628906
Epoch 7000, Train Cost 23.52033805847168, Monte Carlo Cost: 26.327293395996094
Epoch 8000, Train Cost 21.911191940307617, Monte Carlo Cost: 26.239444732666016
Epoch 9000, Train Cost 21.76831817626953, Monte Carlo Cost: 26.153547286987305
Epoch 10000, Train Cost 22.848834991455078, Monte Carlo Cost: 26.067710876464844
Epoch 11000, Train Cost 26.480390548706055, Monte Carlo Cost: 25.98102569580078
Epoch 12000, Train Cost 27.93198013305664, Monte Carlo Cost: 25.89596176147461
Epoch 13000, Train Cost 25.28670310974121, Monte Carlo Cost: 25.81254005432129
Epoch 14000, Train Cost 19.97764015197754, Monte Carlo Cost: 25.727798461914062
Epoch 15000, Train Cost 20.42310333251953, Monte Carlo Cost: 25.642988204956055
Epoch 16000, Train Cost 24.977083206176758, Monte Carlo Cost: 25.56022071838379
Epoch 17000, Train Cost 29.578887939453125, Monte Carlo Cost: 25.47707176208496
Epoch 18000, Train Cost 22.18448829650879, Monte Carlo Cost: 25.39636993408203
Epoch 19000, Train Cost 20.22085952758789, Monte Carlo Cost: 25.315174102783203
Epoch 20000, Train Cost 14.50037956237793, Monte Carlo Cost: 25.23516082763672
Seed 129, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 7.536348342895508, Monte Carlo Cost: 4.941522121429443
Epoch 2000, Train Cost 4.648576259613037, Monte Carlo Cost: 2.4870595932006836
Epoch 3000, Train Cost 0.7824853658676147, Monte Carlo Cost: 0.804314374923706
Epoch 4000, Train Cost 1.9056522846221924, Monte Carlo Cost: 0.7851611971855164
Epoch 5000, Train Cost 1.1929707527160645, Monte Carlo Cost: 0.7501883506774902
Epoch 6000, Train Cost 1.2562248706817627, Monte Carlo Cost: 0.7183961272239685
Epoch 7000, Train Cost 0.791531503200531, Monte Carlo Cost: 0.7071320414543152
Epoch 8000, Train Cost 0.9935773611068726, Monte Carlo Cost: 0.709828794002533
Epoch 9000, Train Cost 0.8337027430534363, Monte Carlo Cost: 0.7101196050643921
Epoch 10000, Train Cost 0.9058974385261536, Monte Carlo Cost: 0.7164835333824158
Epoch 11000, Train Cost 1.1717008352279663, Monte Carlo Cost: 0.7159819006919861
Epoch 12000, Train Cost 1.3221251964569092, Monte Carlo Cost: 0.7216357588768005
Epoch 13000, Train Cost 1.0912809371948242, Monte Carlo Cost: 0.7196025252342224
Epoch 14000, Train Cost 0.6269274950027466, Monte Carlo Cost: 0.7218387722969055
Epoch 15000, Train Cost 0.9215148687362671, Monte Carlo Cost: 0.7189029455184937
Epoch 16000, Train Cost 1.0954669713974, Monte Carlo Cost: 0.7179480791091919
Epoch 17000, Train Cost 1.398543357849121, Monte Carlo Cost: 0.7169522047042847
Epoch 18000, Train Cost 1.0481518507003784, Monte Carlo Cost: 0.7186846137046814
Epoch 19000, Train Cost 0.7114713788032532, Monte Carlo Cost: 0.7200490832328796
Epoch 20000, Train Cost 0.7135147452354431, Monte Carlo Cost: 0.7180997133255005
Seed 129, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 34.991641998291016, Monte Carlo Cost: 23.340534210205078
Epoch 2000, Train Cost 29.18963050842285, Monte Carlo Cost: 22.603137969970703
Epoch 3000, Train Cost 16.7675838470459, Monte Carlo Cost: 21.867765426635742
Epoch 4000, Train Cost 34.1314811706543, Monte Carlo Cost: 21.17283058166504
Epoch 5000, Train Cost 28.287809371948242, Monte Carlo Cost: 20.485401153564453
Epoch 6000, Train Cost 27.013996124267578, Monte Carlo Cost: 19.80780029296875
Epoch 7000, Train Cost 20.498825073242188, Monte Carlo Cost: 19.163537979125977
Epoch 8000, Train Cost 24.187641143798828, Monte Carlo Cost: 18.531435012817383
Epoch 9000, Train Cost 20.632658004760742, Monte Carlo Cost: 17.92745590209961
Epoch 10000, Train Cost 21.52285385131836, Monte Carlo Cost: 17.333452224731445
Epoch 11000, Train Cost 27.30488395690918, Monte Carlo Cost: 16.74509620666504
Epoch 12000, Train Cost 27.37779426574707, Monte Carlo Cost: 16.183273315429688
Epoch 13000, Train Cost 24.102767944335938, Monte Carlo Cost: 15.640681266784668
Epoch 14000, Train Cost 13.232186317443848, Monte Carlo Cost: 15.101030349731445
Epoch 15000, Train Cost 18.890913009643555, Monte Carlo Cost: 14.573996543884277
Epoch 16000, Train Cost 21.70067024230957, Monte Carlo Cost: 14.074047088623047
Epoch 17000, Train Cost 26.147302627563477, Monte Carlo Cost: 13.576682090759277
Epoch 18000, Train Cost 19.286779403686523, Monte Carlo Cost: 13.11080551147461
Epoch 19000, Train Cost 12.503888130187988, Monte Carlo Cost: 12.648527145385742
Epoch 20000, Train Cost 12.50658130645752, Monte Carlo Cost: 12.203436851501465
Seed 129, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 16.59843635559082, Monte Carlo Cost: 9.410324096679688
Epoch 2000, Train Cost 16.836477279663086, Monte Carlo Cost: 9.40686321258545
Epoch 3000, Train Cost 16.340492248535156, Monte Carlo Cost: 9.403443336486816
Epoch 4000, Train Cost 13.61424732208252, Monte Carlo Cost: 9.40000057220459
Epoch 5000, Train Cost 18.913646697998047, Monte Carlo Cost: 9.396599769592285
Epoch 6000, Train Cost 18.032148361206055, Monte Carlo Cost: 9.393178939819336
Epoch 7000, Train Cost 15.284072875976562, Monte Carlo Cost: 9.389723777770996
Epoch 8000, Train Cost 14.849143028259277, Monte Carlo Cost: 9.386280059814453
Epoch 9000, Train Cost 18.32806396484375, Monte Carlo Cost: 9.38284683227539
Epoch 10000, Train Cost 15.584403991699219, Monte Carlo Cost: 9.379410743713379
Epoch 11000, Train Cost 23.84598731994629, Monte Carlo Cost: 9.375986099243164
Epoch 12000, Train Cost 16.934585571289062, Monte Carlo Cost: 9.372540473937988
Epoch 13000, Train Cost 15.715653419494629, Monte Carlo Cost: 9.369119644165039
Epoch 14000, Train Cost 13.55080795288086, Monte Carlo Cost: 9.365679740905762
Epoch 15000, Train Cost 18.1514835357666, Monte Carlo Cost: 9.362264633178711
Epoch 16000, Train Cost 20.788772583007812, Monte Carlo Cost: 9.358844757080078
Epoch 17000, Train Cost 19.838804244995117, Monte Carlo Cost: 9.355417251586914
Epoch 18000, Train Cost 20.920814514160156, Monte Carlo Cost: 9.352020263671875
Epoch 19000, Train Cost 14.32824420928955, Monte Carlo Cost: 9.348591804504395
Epoch 20000, Train Cost 19.86519432067871, Monte Carlo Cost: 9.34517765045166
Seed 129, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.2114667892456055, Monte Carlo Cost: 3.9532876014709473
Epoch 2000, Train Cost 2.013491153717041, Monte Carlo Cost: 1.1728568077087402
Epoch 3000, Train Cost 0.7638489007949829, Monte Carlo Cost: 0.7994253635406494
Epoch 4000, Train Cost 1.7892502546310425, Monte Carlo Cost: 0.7660878896713257
Epoch 5000, Train Cost 1.1502517461776733, Monte Carlo Cost: 0.7389527559280396
Epoch 6000, Train Cost 1.1913270950317383, Monte Carlo Cost: 0.7190937995910645
Epoch 7000, Train Cost 0.7841532826423645, Monte Carlo Cost: 0.7155472636222839
Epoch 8000, Train Cost 0.968264639377594, Monte Carlo Cost: 0.7203220725059509
Epoch 9000, Train Cost 0.8280132412910461, Monte Carlo Cost: 0.7187292575836182
Epoch 10000, Train Cost 0.8948686122894287, Monte Carlo Cost: 0.7221014499664307
Epoch 11000, Train Cost 1.1618373394012451, Monte Carlo Cost: 0.7188493013381958
Epoch 12000, Train Cost 1.3072465658187866, Monte Carlo Cost: 0.7230149507522583
Epoch 13000, Train Cost 1.0888234376907349, Monte Carlo Cost: 0.720165491104126
Epoch 14000, Train Cost 0.6262511014938354, Monte Carlo Cost: 0.7218248248100281
Epoch 15000, Train Cost 0.9192097187042236, Monte Carlo Cost: 0.718677818775177
Epoch 16000, Train Cost 1.0924108028411865, Monte Carlo Cost: 0.7176561951637268
Epoch 17000, Train Cost 1.393100380897522, Monte Carlo Cost: 0.7166576385498047
Epoch 18000, Train Cost 1.0436687469482422, Monte Carlo Cost: 0.7185288667678833
Epoch 19000, Train Cost 0.7106655836105347, Monte Carlo Cost: 0.7197020649909973
Epoch 20000, Train Cost 0.7129611372947693, Monte Carlo Cost: 0.7179245948791504
Seed 129, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 38.529842376708984, Monte Carlo Cost: 18.16840171813965
Epoch 2000, Train Cost 31.204509735107422, Monte Carlo Cost: 17.52616310119629
Epoch 3000, Train Cost 20.18361473083496, Monte Carlo Cost: 16.913654327392578
Epoch 4000, Train Cost 26.935728073120117, Monte Carlo Cost: 16.32610511779785
Epoch 5000, Train Cost 25.510982513427734, Monte Carlo Cost: 15.766651153564453
Epoch 6000, Train Cost 27.33614158630371, Monte Carlo Cost: 15.225870132446289
Epoch 7000, Train Cost 19.187795639038086, Monte Carlo Cost: 14.70163631439209
Epoch 8000, Train Cost 24.349334716796875, Monte Carlo Cost: 14.196210861206055
Epoch 9000, Train Cost 21.314611434936523, Monte Carlo Cost: 13.714856147766113
Epoch 10000, Train Cost 21.520845413208008, Monte Carlo Cost: 13.24688720703125
Epoch 11000, Train Cost 28.640989303588867, Monte Carlo Cost: 12.798295974731445
Epoch 12000, Train Cost 23.760713577270508, Monte Carlo Cost: 12.365392684936523
Epoch 13000, Train Cost 22.21422004699707, Monte Carlo Cost: 11.950767517089844
Epoch 14000, Train Cost 12.852663040161133, Monte Carlo Cost: 11.547015190124512
Epoch 15000, Train Cost 19.653852462768555, Monte Carlo Cost: 11.156846046447754
Epoch 16000, Train Cost 21.04157829284668, Monte Carlo Cost: 10.782691955566406
Epoch 17000, Train Cost 23.591190338134766, Monte Carlo Cost: 10.418170928955078
Epoch 18000, Train Cost 19.84955406188965, Monte Carlo Cost: 10.072315216064453
Epoch 19000, Train Cost 11.911324501037598, Monte Carlo Cost: 9.733235359191895
Epoch 20000, Train Cost 15.21545124053955, Monte Carlo Cost: 9.40750789642334
Seed 129, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 129
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 41.035804748535156, Monte Carlo Cost: 23.40953826904297
Epoch 2000, Train Cost 34.49232864379883, Monte Carlo Cost: 23.40395736694336
Epoch 3000, Train Cost 19.18573760986328, Monte Carlo Cost: 23.398164749145508
Epoch 4000, Train Cost 43.040794372558594, Monte Carlo Cost: 23.392536163330078
Epoch 5000, Train Cost 33.82658767700195, Monte Carlo Cost: 23.38680076599121
Epoch 6000, Train Cost 34.707183837890625, Monte Carlo Cost: 23.380971908569336
Epoch 7000, Train Cost 26.779224395751953, Monte Carlo Cost: 23.375333786010742
Epoch 8000, Train Cost 35.985435485839844, Monte Carlo Cost: 23.369646072387695
Epoch 9000, Train Cost 29.952171325683594, Monte Carlo Cost: 23.364042282104492
Epoch 10000, Train Cost 33.939842224121094, Monte Carlo Cost: 23.358427047729492
Epoch 11000, Train Cost 42.755950927734375, Monte Carlo Cost: 23.352659225463867
Epoch 12000, Train Cost 45.831146240234375, Monte Carlo Cost: 23.347009658813477
Epoch 13000, Train Cost 42.463932037353516, Monte Carlo Cost: 23.341407775878906
Epoch 14000, Train Cost 23.23624038696289, Monte Carlo Cost: 23.335668563842773
Epoch 15000, Train Cost 35.550804138183594, Monte Carlo Cost: 23.32988166809082
Epoch 16000, Train Cost 39.8344612121582, Monte Carlo Cost: 23.32422637939453
Epoch 17000, Train Cost 52.1841926574707, Monte Carlo Cost: 23.31846809387207
Epoch 18000, Train Cost 38.132606506347656, Monte Carlo Cost: 23.31288719177246
Epoch 19000, Train Cost 26.657535552978516, Monte Carlo Cost: 23.307212829589844
Epoch 20000, Train Cost 30.734905242919922, Monte Carlo Cost: 23.301605224609375
Seed 142, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 9.744593620300293, Monte Carlo Cost: 7.683047294616699
Epoch 2000, Train Cost 5.341019153594971, Monte Carlo Cost: 5.018858909606934
Epoch 3000, Train Cost 2.6469767093658447, Monte Carlo Cost: 2.7445037364959717
Epoch 4000, Train Cost 1.2286579608917236, Monte Carlo Cost: 2.2391304969787598
Epoch 5000, Train Cost 1.0453124046325684, Monte Carlo Cost: 2.12984037399292
Epoch 6000, Train Cost 2.326767683029175, Monte Carlo Cost: 2.0760555267333984
Epoch 7000, Train Cost 1.893082857131958, Monte Carlo Cost: 2.034661293029785
Epoch 8000, Train Cost 1.8302607536315918, Monte Carlo Cost: 1.9837955236434937
Epoch 9000, Train Cost 1.133913516998291, Monte Carlo Cost: 1.9618626832962036
Epoch 10000, Train Cost 1.2466574907302856, Monte Carlo Cost: 1.9204635620117188
Epoch 11000, Train Cost 0.8538640141487122, Monte Carlo Cost: 1.8863525390625
Epoch 12000, Train Cost 2.8046703338623047, Monte Carlo Cost: 1.8530558347702026
Epoch 13000, Train Cost 0.9745568037033081, Monte Carlo Cost: 1.8268530368804932
Epoch 14000, Train Cost 0.9972474575042725, Monte Carlo Cost: 1.7981663942337036
Epoch 15000, Train Cost 1.4117615222930908, Monte Carlo Cost: 1.771489143371582
Epoch 16000, Train Cost 1.6002998352050781, Monte Carlo Cost: 1.7490155696868896
Epoch 17000, Train Cost 1.0856785774230957, Monte Carlo Cost: 1.733900547027588
Epoch 18000, Train Cost 2.1706953048706055, Monte Carlo Cost: 1.7114548683166504
Epoch 19000, Train Cost 1.1527762413024902, Monte Carlo Cost: 1.695267677307129
Epoch 20000, Train Cost 1.263803243637085, Monte Carlo Cost: 1.6740003824234009
Seed 142, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 62.16493606567383, Monte Carlo Cost: 54.437923431396484
Epoch 2000, Train Cost 31.48427391052246, Monte Carlo Cost: 34.6959114074707
Epoch 3000, Train Cost 24.618885040283203, Monte Carlo Cost: 24.179399490356445
Epoch 4000, Train Cost 17.67152214050293, Monte Carlo Cost: 18.151220321655273
Epoch 5000, Train Cost 13.083545684814453, Monte Carlo Cost: 14.51203441619873
Epoch 6000, Train Cost 16.73863410949707, Monte Carlo Cost: 12.244036674499512
Epoch 7000, Train Cost 13.7876558303833, Monte Carlo Cost: 10.853857040405273
Epoch 8000, Train Cost 12.893795013427734, Monte Carlo Cost: 9.92375373840332
Epoch 9000, Train Cost 9.596700668334961, Monte Carlo Cost: 9.315442085266113
Epoch 10000, Train Cost 14.812729835510254, Monte Carlo Cost: 8.920928955078125
Epoch 11000, Train Cost 9.655451774597168, Monte Carlo Cost: 8.596844673156738
Epoch 12000, Train Cost 14.889554977416992, Monte Carlo Cost: 8.403355598449707
Epoch 13000, Train Cost 10.882537841796875, Monte Carlo Cost: 8.279403686523438
Epoch 14000, Train Cost 11.029134750366211, Monte Carlo Cost: 8.170004844665527
Epoch 15000, Train Cost 11.093811988830566, Monte Carlo Cost: 8.066998481750488
Epoch 16000, Train Cost 16.290903091430664, Monte Carlo Cost: 8.035099983215332
Epoch 17000, Train Cost 12.139616012573242, Monte Carlo Cost: 8.013106346130371
Epoch 18000, Train Cost 17.232839584350586, Monte Carlo Cost: 8.008973121643066
Epoch 19000, Train Cost 11.39541244506836, Monte Carlo Cost: 8.039676666259766
Epoch 20000, Train Cost 17.70452117919922, Monte Carlo Cost: 8.020594596862793
Seed 142, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 32.32748031616211, Monte Carlo Cost: 30.436784744262695
Epoch 2000, Train Cost 27.712785720825195, Monte Carlo Cost: 30.307863235473633
Epoch 3000, Train Cost 29.793712615966797, Monte Carlo Cost: 30.181102752685547
Epoch 4000, Train Cost 24.575231552124023, Monte Carlo Cost: 30.05597496032715
Epoch 5000, Train Cost 19.001630783081055, Monte Carlo Cost: 29.93133544921875
Epoch 6000, Train Cost 28.91411590576172, Monte Carlo Cost: 29.80682945251465
Epoch 7000, Train Cost 28.372407913208008, Monte Carlo Cost: 29.685117721557617
Epoch 8000, Train Cost 28.118877410888672, Monte Carlo Cost: 29.56292724609375
Epoch 9000, Train Cost 23.138717651367188, Monte Carlo Cost: 29.44227409362793
Epoch 10000, Train Cost 25.839441299438477, Monte Carlo Cost: 29.32178497314453
Epoch 11000, Train Cost 16.917795181274414, Monte Carlo Cost: 29.202238082885742
Epoch 12000, Train Cost 40.500282287597656, Monte Carlo Cost: 29.084177017211914
Epoch 13000, Train Cost 19.568790435791016, Monte Carlo Cost: 28.967763900756836
Epoch 14000, Train Cost 20.11542320251465, Monte Carlo Cost: 28.848342895507812
Epoch 15000, Train Cost 28.82482147216797, Monte Carlo Cost: 28.730178833007812
Epoch 16000, Train Cost 29.611785888671875, Monte Carlo Cost: 28.615455627441406
Epoch 17000, Train Cost 22.850439071655273, Monte Carlo Cost: 28.50115394592285
Epoch 18000, Train Cost 36.57059860229492, Monte Carlo Cost: 28.387208938598633
Epoch 19000, Train Cost 22.530193328857422, Monte Carlo Cost: 28.274621963500977
Epoch 20000, Train Cost 26.630643844604492, Monte Carlo Cost: 28.162338256835938
Seed 142, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 9.765702247619629, Monte Carlo Cost: 7.646938323974609
Epoch 2000, Train Cost 5.306465148925781, Monte Carlo Cost: 5.008822441101074
Epoch 3000, Train Cost 2.571884870529175, Monte Carlo Cost: 2.7036499977111816
Epoch 4000, Train Cost 1.0960749387741089, Monte Carlo Cost: 2.2174196243286133
Epoch 5000, Train Cost 1.1876351833343506, Monte Carlo Cost: 2.116241455078125
Epoch 6000, Train Cost 2.1841089725494385, Monte Carlo Cost: 2.0649900436401367
Epoch 7000, Train Cost 2.1104893684387207, Monte Carlo Cost: 2.027322292327881
Epoch 8000, Train Cost 1.5922532081604004, Monte Carlo Cost: 1.9801115989685059
Epoch 9000, Train Cost 1.1576114892959595, Monte Carlo Cost: 1.958667278289795
Epoch 10000, Train Cost 0.9899234175682068, Monte Carlo Cost: 1.9213849306106567
Epoch 11000, Train Cost 0.674805223941803, Monte Carlo Cost: 1.8889679908752441
Epoch 12000, Train Cost 2.5613913536071777, Monte Carlo Cost: 1.8583145141601562
Epoch 13000, Train Cost 0.8988758325576782, Monte Carlo Cost: 1.8340904712677002
Epoch 14000, Train Cost 0.9288045167922974, Monte Carlo Cost: 1.8070955276489258
Epoch 15000, Train Cost 1.3174676895141602, Monte Carlo Cost: 1.7824499607086182
Epoch 16000, Train Cost 1.5930187702178955, Monte Carlo Cost: 1.7622435092926025
Epoch 17000, Train Cost 1.237939476966858, Monte Carlo Cost: 1.7490607500076294
Epoch 18000, Train Cost 2.137629508972168, Monte Carlo Cost: 1.7275214195251465
Epoch 19000, Train Cost 1.030774712562561, Monte Carlo Cost: 1.7120834589004517
Epoch 20000, Train Cost 1.246698021888733, Monte Carlo Cost: 1.6923747062683105
Seed 142, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 21.20549201965332, Monte Carlo Cost: 20.18410873413086
Epoch 2000, Train Cost 17.18791389465332, Monte Carlo Cost: 15.284093856811523
Epoch 3000, Train Cost 15.584507942199707, Monte Carlo Cost: 12.511614799499512
Epoch 4000, Train Cost 13.317617416381836, Monte Carlo Cost: 10.900571823120117
Epoch 5000, Train Cost 13.299696922302246, Monte Carlo Cost: 9.887953758239746
Epoch 6000, Train Cost 14.7901611328125, Monte Carlo Cost: 9.25307559967041
Epoch 7000, Train Cost 13.931784629821777, Monte Carlo Cost: 8.895864486694336
Epoch 8000, Train Cost 11.813182830810547, Monte Carlo Cost: 8.664177894592285
Epoch 9000, Train Cost 9.384763717651367, Monte Carlo Cost: 8.509973526000977
Epoch 10000, Train Cost 13.358572959899902, Monte Carlo Cost: 8.418070793151855
Epoch 11000, Train Cost 9.23913860321045, Monte Carlo Cost: 8.307241439819336
Epoch 12000, Train Cost 14.29915714263916, Monte Carlo Cost: 8.251815795898438
Epoch 13000, Train Cost 10.24975299835205, Monte Carlo Cost: 8.221729278564453
Epoch 14000, Train Cost 10.460599899291992, Monte Carlo Cost: 8.187027931213379
Epoch 15000, Train Cost 10.576284408569336, Monte Carlo Cost: 8.127665519714355
Epoch 16000, Train Cost 16.259822845458984, Monte Carlo Cost: 8.13192367553711
Epoch 17000, Train Cost 12.307043075561523, Monte Carlo Cost: 8.124157905578613
Epoch 18000, Train Cost 16.667163848876953, Monte Carlo Cost: 8.131268501281738
Epoch 19000, Train Cost 10.566004753112793, Monte Carlo Cost: 8.165892601013184
Epoch 20000, Train Cost 17.244020462036133, Monte Carlo Cost: 8.143098831176758
Seed 142, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 46.7493896484375, Monte Carlo Cost: 42.295291900634766
Epoch 2000, Train Cost 37.87428283691406, Monte Carlo Cost: 42.12874221801758
Epoch 3000, Train Cost 40.99289321899414, Monte Carlo Cost: 41.96482467651367
Epoch 4000, Train Cost 32.020347595214844, Monte Carlo Cost: 41.802467346191406
Epoch 5000, Train Cost 25.92164421081543, Monte Carlo Cost: 41.64109802246094
Epoch 6000, Train Cost 37.974998474121094, Monte Carlo Cost: 41.479827880859375
Epoch 7000, Train Cost 43.14921951293945, Monte Carlo Cost: 41.32157516479492
Epoch 8000, Train Cost 39.758888244628906, Monte Carlo Cost: 41.16239929199219
Epoch 9000, Train Cost 35.05680847167969, Monte Carlo Cost: 41.00515365600586
Epoch 10000, Train Cost 32.131309509277344, Monte Carlo Cost: 40.84819030761719
Epoch 11000, Train Cost 22.752321243286133, Monte Carlo Cost: 40.692344665527344
Epoch 12000, Train Cost 57.50547409057617, Monte Carlo Cost: 40.5383415222168
Epoch 13000, Train Cost 26.97198486328125, Monte Carlo Cost: 40.38631057739258
Epoch 14000, Train Cost 27.831132888793945, Monte Carlo Cost: 40.23009490966797
Epoch 15000, Train Cost 41.7555046081543, Monte Carlo Cost: 40.07573318481445
Epoch 16000, Train Cost 38.31414794921875, Monte Carlo Cost: 39.92518615722656
Epoch 17000, Train Cost 34.70884704589844, Monte Carlo Cost: 39.77544021606445
Epoch 18000, Train Cost 49.58918762207031, Monte Carlo Cost: 39.625797271728516
Epoch 19000, Train Cost 30.136489868164062, Monte Carlo Cost: 39.47760009765625
Epoch 20000, Train Cost 33.70321273803711, Monte Carlo Cost: 39.33013153076172
Seed 142, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 5.192181587219238, Monte Carlo Cost: 4.800408840179443
Epoch 2000, Train Cost 1.7637240886688232, Monte Carlo Cost: 2.1544137001037598
Epoch 3000, Train Cost 1.6762542724609375, Monte Carlo Cost: 1.8910109996795654
Epoch 4000, Train Cost 1.0291038751602173, Monte Carlo Cost: 1.6970068216323853
Epoch 5000, Train Cost 0.8695926070213318, Monte Carlo Cost: 1.5510424375534058
Epoch 6000, Train Cost 1.4710004329681396, Monte Carlo Cost: 1.46091890335083
Epoch 7000, Train Cost 1.4087899923324585, Monte Carlo Cost: 1.4075431823730469
Epoch 8000, Train Cost 1.2126332521438599, Monte Carlo Cost: 1.3683408498764038
Epoch 9000, Train Cost 0.9825290441513062, Monte Carlo Cost: 1.3430140018463135
Epoch 10000, Train Cost 0.9597483277320862, Monte Carlo Cost: 1.3239222764968872
Epoch 11000, Train Cost 0.6326625347137451, Monte Carlo Cost: 1.308046817779541
Epoch 12000, Train Cost 1.741520643234253, Monte Carlo Cost: 1.2937315702438354
Epoch 13000, Train Cost 0.7876044511795044, Monte Carlo Cost: 1.2838159799575806
Epoch 14000, Train Cost 0.8120002150535583, Monte Carlo Cost: 1.2763779163360596
Epoch 15000, Train Cost 1.184174656867981, Monte Carlo Cost: 1.2703605890274048
Epoch 16000, Train Cost 1.2450374364852905, Monte Carlo Cost: 1.2646781206130981
Epoch 17000, Train Cost 1.0421074628829956, Monte Carlo Cost: 1.2586915493011475
Epoch 18000, Train Cost 1.5759549140930176, Monte Carlo Cost: 1.2564747333526611
Epoch 19000, Train Cost 0.8979149460792542, Monte Carlo Cost: 1.250838279724121
Epoch 20000, Train Cost 1.0903306007385254, Monte Carlo Cost: 1.243699550628662
Seed 142, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 14.397745132446289, Monte Carlo Cost: 10.378304481506348
Epoch 2000, Train Cost 15.711636543273926, Monte Carlo Cost: 10.00527286529541
Epoch 3000, Train Cost 14.615638732910156, Monte Carlo Cost: 9.674131393432617
Epoch 4000, Train Cost 13.24294376373291, Monte Carlo Cost: 9.401028633117676
Epoch 5000, Train Cost 14.674543380737305, Monte Carlo Cost: 9.154461860656738
Epoch 6000, Train Cost 15.172954559326172, Monte Carlo Cost: 8.94525146484375
Epoch 7000, Train Cost 15.02098274230957, Monte Carlo Cost: 8.784377098083496
Epoch 8000, Train Cost 12.115307807922363, Monte Carlo Cost: 8.65483283996582
Epoch 9000, Train Cost 9.887272834777832, Monte Carlo Cost: 8.53793716430664
Epoch 10000, Train Cost 13.285440444946289, Monte Carlo Cost: 8.444204330444336
Epoch 11000, Train Cost 9.627634048461914, Monte Carlo Cost: 8.344054222106934
Epoch 12000, Train Cost 14.500273704528809, Monte Carlo Cost: 8.265897750854492
Epoch 13000, Train Cost 10.427251815795898, Monte Carlo Cost: 8.201884269714355
Epoch 14000, Train Cost 10.637803077697754, Monte Carlo Cost: 8.141578674316406
Epoch 15000, Train Cost 10.6033353805542, Monte Carlo Cost: 8.074728012084961
Epoch 16000, Train Cost 16.598173141479492, Monte Carlo Cost: 8.038086891174316
Epoch 17000, Train Cost 12.740693092346191, Monte Carlo Cost: 7.9976582527160645
Epoch 18000, Train Cost 16.563730239868164, Monte Carlo Cost: 7.970424652099609
Epoch 19000, Train Cost 10.411726951599121, Monte Carlo Cost: 7.959061145782471
Epoch 20000, Train Cost 17.31760597229004, Monte Carlo Cost: 7.929488658905029
Seed 142, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 91.98181915283203, Monte Carlo Cost: 75.59584045410156
Epoch 2000, Train Cost 70.51324462890625, Monte Carlo Cost: 75.57797241210938
Epoch 3000, Train Cost 76.39591979980469, Monte Carlo Cost: 75.56007385253906
Epoch 4000, Train Cost 61.05825424194336, Monte Carlo Cost: 75.5422134399414
Epoch 5000, Train Cost 47.391754150390625, Monte Carlo Cost: 75.52428436279297
Epoch 6000, Train Cost 71.12158203125, Monte Carlo Cost: 75.50634002685547
Epoch 7000, Train Cost 85.33382415771484, Monte Carlo Cost: 75.4884262084961
Epoch 8000, Train Cost 86.11761474609375, Monte Carlo Cost: 75.47054290771484
Epoch 9000, Train Cost 75.2061538696289, Monte Carlo Cost: 75.45262908935547
Epoch 10000, Train Cost 64.11893463134766, Monte Carlo Cost: 75.43466186523438
Epoch 11000, Train Cost 51.96698760986328, Monte Carlo Cost: 75.41678619384766
Epoch 12000, Train Cost 121.78014373779297, Monte Carlo Cost: 75.39887237548828
Epoch 13000, Train Cost 58.087371826171875, Monte Carlo Cost: 75.38105773925781
Epoch 14000, Train Cost 60.23538589477539, Monte Carlo Cost: 75.36308288574219
Epoch 15000, Train Cost 91.47422790527344, Monte Carlo Cost: 75.3451156616211
Epoch 16000, Train Cost 71.3723373413086, Monte Carlo Cost: 75.32727813720703
Epoch 17000, Train Cost 73.49340057373047, Monte Carlo Cost: 75.30944061279297
Epoch 18000, Train Cost 97.26383972167969, Monte Carlo Cost: 75.29149627685547
Epoch 19000, Train Cost 65.37477111816406, Monte Carlo Cost: 75.27357482910156
Epoch 20000, Train Cost 65.24894714355469, Monte Carlo Cost: 75.25566864013672
Seed 142, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 7.054528713226318, Monte Carlo Cost: 6.1351799964904785
Epoch 2000, Train Cost 2.3312864303588867, Monte Carlo Cost: 2.6760880947113037
Epoch 3000, Train Cost 1.8960118293762207, Monte Carlo Cost: 2.1764848232269287
Epoch 4000, Train Cost 1.0838755369186401, Monte Carlo Cost: 1.9837942123413086
Epoch 5000, Train Cost 0.958089292049408, Monte Carlo Cost: 1.7876839637756348
Epoch 6000, Train Cost 1.6860158443450928, Monte Carlo Cost: 1.6311843395233154
Epoch 7000, Train Cost 1.512577772140503, Monte Carlo Cost: 1.522247314453125
Epoch 8000, Train Cost 1.26067054271698, Monte Carlo Cost: 1.443070888519287
Epoch 9000, Train Cost 0.9905524253845215, Monte Carlo Cost: 1.3954179286956787
Epoch 10000, Train Cost 0.9625682830810547, Monte Carlo Cost: 1.3618391752243042
Epoch 11000, Train Cost 0.6348493099212646, Monte Carlo Cost: 1.3370463848114014
Epoch 12000, Train Cost 1.779191017150879, Monte Carlo Cost: 1.3166756629943848
Epoch 13000, Train Cost 0.78987056016922, Monte Carlo Cost: 1.3020541667938232
Epoch 14000, Train Cost 0.8144124746322632, Monte Carlo Cost: 1.2914512157440186
Epoch 15000, Train Cost 1.1870484352111816, Monte Carlo Cost: 1.2825558185577393
Epoch 16000, Train Cost 1.249934196472168, Monte Carlo Cost: 1.2752039432525635
Epoch 17000, Train Cost 1.0443862676620483, Monte Carlo Cost: 1.2679532766342163
Epoch 18000, Train Cost 1.5861408710479736, Monte Carlo Cost: 1.2648541927337646
Epoch 19000, Train Cost 0.8997130990028381, Monte Carlo Cost: 1.2580324411392212
Epoch 20000, Train Cost 1.0922096967697144, Monte Carlo Cost: 1.2495994567871094
Seed 142, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 26.619096755981445, Monte Carlo Cost: 25.77200698852539
Epoch 2000, Train Cost 25.733320236206055, Monte Carlo Cost: 24.610309600830078
Epoch 3000, Train Cost 24.388635635375977, Monte Carlo Cost: 23.504852294921875
Epoch 4000, Train Cost 17.76006317138672, Monte Carlo Cost: 22.454227447509766
Epoch 5000, Train Cost 21.551713943481445, Monte Carlo Cost: 21.439197540283203
Epoch 6000, Train Cost 20.825626373291016, Monte Carlo Cost: 20.466724395751953
Epoch 7000, Train Cost 24.286270141601562, Monte Carlo Cost: 19.543729782104492
Epoch 8000, Train Cost 14.958697319030762, Monte Carlo Cost: 18.66443634033203
Epoch 9000, Train Cost 14.79808521270752, Monte Carlo Cost: 17.816720962524414
Epoch 10000, Train Cost 14.1494140625, Monte Carlo Cost: 17.003707885742188
Epoch 11000, Train Cost 10.077688217163086, Monte Carlo Cost: 16.231922149658203
Epoch 12000, Train Cost 18.925819396972656, Monte Carlo Cost: 15.494670867919922
Epoch 13000, Train Cost 11.547307968139648, Monte Carlo Cost: 14.797582626342773
Epoch 14000, Train Cost 11.73585033416748, Monte Carlo Cost: 14.131800651550293
Epoch 15000, Train Cost 12.886324882507324, Monte Carlo Cost: 13.494157791137695
Epoch 16000, Train Cost 19.6815242767334, Monte Carlo Cost: 12.905116081237793
Epoch 17000, Train Cost 15.252602577209473, Monte Carlo Cost: 12.342557907104492
Epoch 18000, Train Cost 18.986494064331055, Monte Carlo Cost: 11.820039749145508
Epoch 19000, Train Cost 10.766647338867188, Monte Carlo Cost: 11.336542129516602
Epoch 20000, Train Cost 18.45545768737793, Monte Carlo Cost: 10.879405975341797
Seed 142, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 142
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 60.5401496887207, Monte Carlo Cost: 51.60685729980469
Epoch 2000, Train Cost 47.73878860473633, Monte Carlo Cost: 51.59146499633789
Epoch 3000, Train Cost 51.09054946899414, Monte Carlo Cost: 51.57608413696289
Epoch 4000, Train Cost 42.57709503173828, Monte Carlo Cost: 51.560707092285156
Epoch 5000, Train Cost 30.152822494506836, Monte Carlo Cost: 51.54533386230469
Epoch 6000, Train Cost 50.38441467285156, Monte Carlo Cost: 51.529964447021484
Epoch 7000, Train Cost 50.77193832397461, Monte Carlo Cost: 51.5146484375
Epoch 8000, Train Cost 59.656803131103516, Monte Carlo Cost: 51.49925994873047
Epoch 9000, Train Cost 47.667518615722656, Monte Carlo Cost: 51.48392105102539
Epoch 10000, Train Cost 48.113037109375, Monte Carlo Cost: 51.468570709228516
Epoch 11000, Train Cost 38.02293014526367, Monte Carlo Cost: 51.453216552734375
Epoch 12000, Train Cost 84.3302230834961, Monte Carlo Cost: 51.437889099121094
Epoch 13000, Train Cost 39.461524963378906, Monte Carlo Cost: 51.422584533691406
Epoch 14000, Train Cost 40.883544921875, Monte Carlo Cost: 51.40718078613281
Epoch 15000, Train Cost 61.14277648925781, Monte Carlo Cost: 51.39179992675781
Epoch 16000, Train Cost 49.89878463745117, Monte Carlo Cost: 51.376529693603516
Epoch 17000, Train Cost 44.110023498535156, Monte Carlo Cost: 51.361263275146484
Epoch 18000, Train Cost 65.66422271728516, Monte Carlo Cost: 51.3459358215332
Epoch 19000, Train Cost 46.14326858520508, Monte Carlo Cost: 51.33064270019531
Epoch 20000, Train Cost 45.47343063354492, Monte Carlo Cost: 51.315330505371094
Seed 158, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 9.438349723815918, Monte Carlo Cost: 4.961860656738281
Epoch 2000, Train Cost 3.2528600692749023, Monte Carlo Cost: 2.2220962047576904
Epoch 3000, Train Cost 1.5128650665283203, Monte Carlo Cost: 1.0531084537506104
Epoch 4000, Train Cost 1.1469982862472534, Monte Carlo Cost: 1.0106693506240845
Epoch 5000, Train Cost 1.1790008544921875, Monte Carlo Cost: 1.0155041217803955
Epoch 6000, Train Cost 1.9714173078536987, Monte Carlo Cost: 1.0091869831085205
Epoch 7000, Train Cost 1.2765862941741943, Monte Carlo Cost: 1.001097321510315
Epoch 8000, Train Cost 1.4100723266601562, Monte Carlo Cost: 0.9875874519348145
Epoch 9000, Train Cost 1.9471633434295654, Monte Carlo Cost: 0.9811316728591919
Epoch 10000, Train Cost 1.2167048454284668, Monte Carlo Cost: 0.9724025130271912
Epoch 11000, Train Cost 1.2796975374221802, Monte Carlo Cost: 0.9655503630638123
Epoch 12000, Train Cost 1.0342588424682617, Monte Carlo Cost: 0.9585977792739868
Epoch 13000, Train Cost 1.3883097171783447, Monte Carlo Cost: 0.9506133794784546
Epoch 14000, Train Cost 1.3133254051208496, Monte Carlo Cost: 0.9451998472213745
Epoch 15000, Train Cost 1.0828286409378052, Monte Carlo Cost: 0.9390830397605896
Epoch 16000, Train Cost 0.8155696392059326, Monte Carlo Cost: 0.9346452355384827
Epoch 17000, Train Cost 1.035030722618103, Monte Carlo Cost: 0.9299187064170837
Epoch 18000, Train Cost 1.765899896621704, Monte Carlo Cost: 0.9251395463943481
Epoch 19000, Train Cost 1.0169973373413086, Monte Carlo Cost: 0.9224741458892822
Epoch 20000, Train Cost 1.4443724155426025, Monte Carlo Cost: 0.9172276854515076
Seed 158, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 48.6746711730957, Monte Carlo Cost: 35.98984146118164
Epoch 2000, Train Cost 26.17361068725586, Monte Carlo Cost: 22.046192169189453
Epoch 3000, Train Cost 17.289623260498047, Monte Carlo Cost: 15.135961532592773
Epoch 4000, Train Cost 15.157224655151367, Monte Carlo Cost: 11.483869552612305
Epoch 5000, Train Cost 16.45110321044922, Monte Carlo Cost: 9.421586036682129
Epoch 6000, Train Cost 18.998445510864258, Monte Carlo Cost: 8.231256484985352
Epoch 7000, Train Cost 12.626402854919434, Monte Carlo Cost: 7.473484992980957
Epoch 8000, Train Cost 11.803668975830078, Monte Carlo Cost: 7.040128707885742
Epoch 9000, Train Cost 12.90169906616211, Monte Carlo Cost: 6.770590305328369
Epoch 10000, Train Cost 11.783074378967285, Monte Carlo Cost: 6.575588226318359
Epoch 11000, Train Cost 10.721407890319824, Monte Carlo Cost: 6.435181617736816
Epoch 12000, Train Cost 11.40097713470459, Monte Carlo Cost: 6.352763652801514
Epoch 13000, Train Cost 12.086099624633789, Monte Carlo Cost: 6.312258720397949
Epoch 14000, Train Cost 10.96496868133545, Monte Carlo Cost: 6.25514554977417
Epoch 15000, Train Cost 10.093119621276855, Monte Carlo Cost: 6.261279106140137
Epoch 16000, Train Cost 10.964226722717285, Monte Carlo Cost: 6.233520984649658
Epoch 17000, Train Cost 11.463871002197266, Monte Carlo Cost: 6.238307952880859
Epoch 18000, Train Cost 15.726278305053711, Monte Carlo Cost: 6.24247932434082
Epoch 19000, Train Cost 10.55092716217041, Monte Carlo Cost: 6.203389644622803
Epoch 20000, Train Cost 13.645210266113281, Monte Carlo Cost: 6.212743282318115
Seed 158, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 29.29552459716797, Monte Carlo Cost: 20.873310089111328
Epoch 2000, Train Cost 25.632509231567383, Monte Carlo Cost: 20.804540634155273
Epoch 3000, Train Cost 26.32878303527832, Monte Carlo Cost: 20.735620498657227
Epoch 4000, Train Cost 22.203866958618164, Monte Carlo Cost: 20.666906356811523
Epoch 5000, Train Cost 24.01913070678711, Monte Carlo Cost: 20.598695755004883
Epoch 6000, Train Cost 35.19723129272461, Monte Carlo Cost: 20.531328201293945
Epoch 7000, Train Cost 26.14675521850586, Monte Carlo Cost: 20.463233947753906
Epoch 8000, Train Cost 27.426862716674805, Monte Carlo Cost: 20.397064208984375
Epoch 9000, Train Cost 32.91533660888672, Monte Carlo Cost: 20.330589294433594
Epoch 10000, Train Cost 25.29934310913086, Monte Carlo Cost: 20.264068603515625
Epoch 11000, Train Cost 25.588464736938477, Monte Carlo Cost: 20.1978759765625
Epoch 12000, Train Cost 23.039337158203125, Monte Carlo Cost: 20.1324462890625
Epoch 13000, Train Cost 28.33290672302246, Monte Carlo Cost: 20.067581176757812
Epoch 14000, Train Cost 26.7888126373291, Monte Carlo Cost: 20.002357482910156
Epoch 15000, Train Cost 21.26908302307129, Monte Carlo Cost: 19.938549041748047
Epoch 16000, Train Cost 18.157974243164062, Monte Carlo Cost: 19.874773025512695
Epoch 17000, Train Cost 20.755699157714844, Monte Carlo Cost: 19.811098098754883
Epoch 18000, Train Cost 27.67497444152832, Monte Carlo Cost: 19.74817657470703
Epoch 19000, Train Cost 21.47620391845703, Monte Carlo Cost: 19.684938430786133
Epoch 20000, Train Cost 27.866317749023438, Monte Carlo Cost: 19.62285614013672
Seed 158, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 10.831748962402344, Monte Carlo Cost: 5.495923042297363
Epoch 2000, Train Cost 4.698920249938965, Monte Carlo Cost: 3.10477614402771
Epoch 3000, Train Cost 1.77220618724823, Monte Carlo Cost: 1.2371912002563477
Epoch 4000, Train Cost 1.163928747177124, Monte Carlo Cost: 1.032557487487793
Epoch 5000, Train Cost 1.2093925476074219, Monte Carlo Cost: 1.040178894996643
Epoch 6000, Train Cost 2.013047218322754, Monte Carlo Cost: 1.035516619682312
Epoch 7000, Train Cost 1.2926472425460815, Monte Carlo Cost: 1.0265568494796753
Epoch 8000, Train Cost 1.4150519371032715, Monte Carlo Cost: 1.0115760564804077
Epoch 9000, Train Cost 1.9691698551177979, Monte Carlo Cost: 1.003615379333496
Epoch 10000, Train Cost 1.2212882041931152, Monte Carlo Cost: 0.9934360980987549
Epoch 11000, Train Cost 1.3019764423370361, Monte Carlo Cost: 0.9852291345596313
Epoch 12000, Train Cost 1.0414378643035889, Monte Carlo Cost: 0.977018415927887
Epoch 13000, Train Cost 1.399719476699829, Monte Carlo Cost: 0.9678832292556763
Epoch 14000, Train Cost 1.3336713314056396, Monte Carlo Cost: 0.9613953828811646
Epoch 15000, Train Cost 1.0995749235153198, Monte Carlo Cost: 0.9542979001998901
Epoch 16000, Train Cost 0.8187857866287231, Monte Carlo Cost: 0.9488701820373535
Epoch 17000, Train Cost 1.053946852684021, Monte Carlo Cost: 0.9433432817459106
Epoch 18000, Train Cost 1.7969985008239746, Monte Carlo Cost: 0.9376915693283081
Epoch 19000, Train Cost 1.019684076309204, Monte Carlo Cost: 0.9343057870864868
Epoch 20000, Train Cost 1.4531900882720947, Monte Carlo Cost: 0.9283863306045532
Seed 158, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 14.697869300842285, Monte Carlo Cost: 5.353847980499268
Epoch 2000, Train Cost 13.645438194274902, Monte Carlo Cost: 5.643247127532959
Epoch 3000, Train Cost 9.837133407592773, Monte Carlo Cost: 5.8301615715026855
Epoch 4000, Train Cost 14.956252098083496, Monte Carlo Cost: 5.969997882843018
Epoch 5000, Train Cost 15.124059677124023, Monte Carlo Cost: 6.042018413543701
Epoch 6000, Train Cost 17.548282623291016, Monte Carlo Cost: 6.088063716888428
Epoch 7000, Train Cost 11.807836532592773, Monte Carlo Cost: 6.09561014175415
Epoch 8000, Train Cost 11.430304527282715, Monte Carlo Cost: 6.124231815338135
Epoch 9000, Train Cost 12.255736351013184, Monte Carlo Cost: 6.1438093185424805
Epoch 10000, Train Cost 11.378341674804688, Monte Carlo Cost: 6.135425567626953
Epoch 11000, Train Cost 10.470566749572754, Monte Carlo Cost: 6.116626262664795
Epoch 12000, Train Cost 11.028103828430176, Monte Carlo Cost: 6.1095123291015625
Epoch 13000, Train Cost 11.751692771911621, Monte Carlo Cost: 6.113749027252197
Epoch 14000, Train Cost 10.634353637695312, Monte Carlo Cost: 6.090119361877441
Epoch 15000, Train Cost 9.822283744812012, Monte Carlo Cost: 6.114856243133545
Epoch 16000, Train Cost 10.493694305419922, Monte Carlo Cost: 6.101415634155273
Epoch 17000, Train Cost 11.079503059387207, Monte Carlo Cost: 6.1097412109375
Epoch 18000, Train Cost 15.327315330505371, Monte Carlo Cost: 6.115877628326416
Epoch 19000, Train Cost 10.168266296386719, Monte Carlo Cost: 6.077409267425537
Epoch 20000, Train Cost 13.257035255432129, Monte Carlo Cost: 6.086294174194336
Seed 158, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 77.56254577636719, Monte Carlo Cost: 47.756404876708984
Epoch 2000, Train Cost 68.23545837402344, Monte Carlo Cost: 47.49921417236328
Epoch 3000, Train Cost 75.38858795166016, Monte Carlo Cost: 47.24207305908203
Epoch 4000, Train Cost 57.81659698486328, Monte Carlo Cost: 46.98581314086914
Epoch 5000, Train Cost 55.07625961303711, Monte Carlo Cost: 46.73216247558594
Epoch 6000, Train Cost 84.23753356933594, Monte Carlo Cost: 46.48279571533203
Epoch 7000, Train Cost 64.91835021972656, Monte Carlo Cost: 46.23164367675781
Epoch 8000, Train Cost 79.6544418334961, Monte Carlo Cost: 45.98715591430664
Epoch 9000, Train Cost 82.0518569946289, Monte Carlo Cost: 45.74239730834961
Epoch 10000, Train Cost 67.42073822021484, Monte Carlo Cost: 45.49848556518555
Epoch 11000, Train Cost 70.72817993164062, Monte Carlo Cost: 45.25619125366211
Epoch 12000, Train Cost 57.670894622802734, Monte Carlo Cost: 45.01765060424805
Epoch 13000, Train Cost 78.54822540283203, Monte Carlo Cost: 44.780704498291016
Epoch 14000, Train Cost 74.49909973144531, Monte Carlo Cost: 44.54409408569336
Epoch 15000, Train Cost 57.945465087890625, Monte Carlo Cost: 44.311763763427734
Epoch 16000, Train Cost 48.20276641845703, Monte Carlo Cost: 44.08066940307617
Epoch 17000, Train Cost 49.107200622558594, Monte Carlo Cost: 43.85054016113281
Epoch 18000, Train Cost 66.80192565917969, Monte Carlo Cost: 43.62358856201172
Epoch 19000, Train Cost 60.33783721923828, Monte Carlo Cost: 43.39714431762695
Epoch 20000, Train Cost 62.1400032043457, Monte Carlo Cost: 43.173675537109375
Seed 158, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 6.426276206970215, Monte Carlo Cost: 3.281445026397705
Epoch 2000, Train Cost 1.3625060319900513, Monte Carlo Cost: 1.0012801885604858
Epoch 3000, Train Cost 1.313968539237976, Monte Carlo Cost: 0.9550571441650391
Epoch 4000, Train Cost 1.0735061168670654, Monte Carlo Cost: 0.901239275932312
Epoch 5000, Train Cost 1.0268142223358154, Monte Carlo Cost: 0.8660085201263428
Epoch 6000, Train Cost 1.5793758630752563, Monte Carlo Cost: 0.8545745611190796
Epoch 7000, Train Cost 1.0923432111740112, Monte Carlo Cost: 0.8403425216674805
Epoch 8000, Train Cost 1.170154094696045, Monte Carlo Cost: 0.8371837735176086
Epoch 9000, Train Cost 1.4340310096740723, Monte Carlo Cost: 0.838898777961731
Epoch 10000, Train Cost 1.0409294366836548, Monte Carlo Cost: 0.8332447409629822
Epoch 11000, Train Cost 1.0502755641937256, Monte Carlo Cost: 0.8291026949882507
Epoch 12000, Train Cost 0.9402765035629272, Monte Carlo Cost: 0.830024778842926
Epoch 13000, Train Cost 1.1625328063964844, Monte Carlo Cost: 0.8278544545173645
Epoch 14000, Train Cost 1.0989352464675903, Monte Carlo Cost: 0.8301258087158203
Epoch 15000, Train Cost 0.8816254734992981, Monte Carlo Cost: 0.8252596259117126
Epoch 16000, Train Cost 0.7483835816383362, Monte Carlo Cost: 0.823356032371521
Epoch 17000, Train Cost 0.8681110143661499, Monte Carlo Cost: 0.8253651261329651
Epoch 18000, Train Cost 1.2216110229492188, Monte Carlo Cost: 0.8252177238464355
Epoch 19000, Train Cost 0.8936086893081665, Monte Carlo Cost: 0.8247280120849609
Epoch 20000, Train Cost 1.1797925233840942, Monte Carlo Cost: 0.8246305584907532
Perturbing at epoch 20000
Seed 158, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 52.995296478271484, Monte Carlo Cost: 41.30698776245117
Epoch 2000, Train Cost 45.25196838378906, Monte Carlo Cost: 39.64449691772461
Epoch 3000, Train Cost 46.66239929199219, Monte Carlo Cost: 38.04389953613281
Epoch 4000, Train Cost 33.69687271118164, Monte Carlo Cost: 36.513023376464844
Epoch 5000, Train Cost 35.95375061035156, Monte Carlo Cost: 35.04269790649414
Epoch 6000, Train Cost 47.74161911010742, Monte Carlo Cost: 33.64219665527344
Epoch 7000, Train Cost 35.413333892822266, Monte Carlo Cost: 32.2706298828125
Epoch 8000, Train Cost 32.72160720825195, Monte Carlo Cost: 30.969303131103516
Epoch 9000, Train Cost 40.68122482299805, Monte Carlo Cost: 29.71681785583496
Epoch 10000, Train Cost 29.148029327392578, Monte Carlo Cost: 28.49972915649414
Epoch 11000, Train Cost 33.207481384277344, Monte Carlo Cost: 27.32724380493164
Epoch 12000, Train Cost 25.901199340820312, Monte Carlo Cost: 26.214876174926758
Epoch 13000, Train Cost 30.689281463623047, Monte Carlo Cost: 25.131546020507812
Epoch 14000, Train Cost 30.977928161621094, Monte Carlo Cost: 24.09244155883789
Epoch 15000, Train Cost 24.317625045776367, Monte Carlo Cost: 23.09621238708496
Epoch 16000, Train Cost 17.931278228759766, Monte Carlo Cost: 22.132633209228516
Epoch 17000, Train Cost 22.11186408996582, Monte Carlo Cost: 21.213104248046875
Epoch 18000, Train Cost 26.287931442260742, Monte Carlo Cost: 20.328857421875
Epoch 19000, Train Cost 18.564743041992188, Monte Carlo Cost: 19.46954917907715
Epoch 20000, Train Cost 23.101598739624023, Monte Carlo Cost: 18.645423889160156
Seed 158, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr 1e-08
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-08
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 81.32807159423828, Monte Carlo Cost: 58.945335388183594
Epoch 2000, Train Cost 71.13176727294922, Monte Carlo Cost: 58.9257698059082
Epoch 3000, Train Cost 80.9820785522461, Monte Carlo Cost: 58.906158447265625
Epoch 4000, Train Cost 59.75465774536133, Monte Carlo Cost: 58.8865852355957
Epoch 5000, Train Cost 57.579254150390625, Monte Carlo Cost: 58.86697006225586
Epoch 6000, Train Cost 85.70748138427734, Monte Carlo Cost: 58.84748458862305
Epoch 7000, Train Cost 68.61795043945312, Monte Carlo Cost: 58.827877044677734
Epoch 8000, Train Cost 71.16158294677734, Monte Carlo Cost: 58.80830001831055
Epoch 9000, Train Cost 82.08879089355469, Monte Carlo Cost: 58.78889846801758
Epoch 10000, Train Cost 66.80680084228516, Monte Carlo Cost: 58.769378662109375
Epoch 11000, Train Cost 78.66021728515625, Monte Carlo Cost: 58.74980163574219
Epoch 12000, Train Cost 61.26062774658203, Monte Carlo Cost: 58.73044967651367
Epoch 13000, Train Cost 81.59449005126953, Monte Carlo Cost: 58.71080780029297
Epoch 14000, Train Cost 89.80250549316406, Monte Carlo Cost: 58.69146728515625
Epoch 15000, Train Cost 70.67786407470703, Monte Carlo Cost: 58.671974182128906
Epoch 16000, Train Cost 56.743988037109375, Monte Carlo Cost: 58.652462005615234
Epoch 17000, Train Cost 67.63217163085938, Monte Carlo Cost: 58.63310623168945
Epoch 18000, Train Cost 73.62564086914062, Monte Carlo Cost: 58.613773345947266
Epoch 19000, Train Cost 65.68317413330078, Monte Carlo Cost: 58.59437942504883
Epoch 20000, Train Cost 65.80326843261719, Monte Carlo Cost: 58.57481002807617
Seed 158, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 8.515761375427246, Monte Carlo Cost: 4.158072471618652
Epoch 2000, Train Cost 1.3990695476531982, Monte Carlo Cost: 0.9855525493621826
Epoch 3000, Train Cost 1.2979727983474731, Monte Carlo Cost: 0.9559736251831055
Epoch 4000, Train Cost 1.0696965456008911, Monte Carlo Cost: 0.9143486022949219
Epoch 5000, Train Cost 1.0406417846679688, Monte Carlo Cost: 0.8772430419921875
Epoch 6000, Train Cost 1.6041226387023926, Monte Carlo Cost: 0.8614060282707214
Epoch 7000, Train Cost 1.0964735746383667, Monte Carlo Cost: 0.8438827395439148
Epoch 8000, Train Cost 1.1737754344940186, Monte Carlo Cost: 0.8390019536018372
Epoch 9000, Train Cost 1.4372751712799072, Monte Carlo Cost: 0.8397276997566223
Epoch 10000, Train Cost 1.0428071022033691, Monte Carlo Cost: 0.8336160182952881
Epoch 11000, Train Cost 1.0510001182556152, Monte Carlo Cost: 0.8294600248336792
Epoch 12000, Train Cost 0.941554069519043, Monte Carlo Cost: 0.8300104141235352
Epoch 13000, Train Cost 1.1638679504394531, Monte Carlo Cost: 0.8279663920402527
Epoch 14000, Train Cost 1.099345088005066, Monte Carlo Cost: 0.830194354057312
Epoch 15000, Train Cost 0.8815038800239563, Monte Carlo Cost: 0.8254730105400085
Epoch 16000, Train Cost 0.7487514019012451, Monte Carlo Cost: 0.8234514594078064
Epoch 17000, Train Cost 0.8690404295921326, Monte Carlo Cost: 0.8254020810127258
Epoch 18000, Train Cost 1.2273672819137573, Monte Carlo Cost: 0.8251334428787231
Epoch 19000, Train Cost 0.8937831521034241, Monte Carlo Cost: 0.8247873187065125
Epoch 20000, Train Cost 1.181761384010315, Monte Carlo Cost: 0.8247405886650085
Perturbing at epoch 20000
Seed 158, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_1:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 35.4014892578125, Monte Carlo Cost: 27.228179931640625
Epoch 2000, Train Cost 30.42398452758789, Monte Carlo Cost: 26.165443420410156
Epoch 3000, Train Cost 29.63067054748535, Monte Carlo Cost: 25.14100456237793
Epoch 4000, Train Cost 22.8781795501709, Monte Carlo Cost: 24.159194946289062
Epoch 5000, Train Cost 26.153501510620117, Monte Carlo Cost: 23.215044021606445
Epoch 6000, Train Cost 33.765533447265625, Monte Carlo Cost: 22.314010620117188
Epoch 7000, Train Cost 24.11241912841797, Monte Carlo Cost: 21.427534103393555
Epoch 8000, Train Cost 21.683687210083008, Monte Carlo Cost: 20.589481353759766
Epoch 9000, Train Cost 28.06222915649414, Monte Carlo Cost: 19.77901268005371
Epoch 10000, Train Cost 19.63863754272461, Monte Carlo Cost: 18.989303588867188
Epoch 11000, Train Cost 21.686809539794922, Monte Carlo Cost: 18.22775650024414
Epoch 12000, Train Cost 17.937545776367188, Monte Carlo Cost: 17.50420570373535
Epoch 13000, Train Cost 20.18566131591797, Monte Carlo Cost: 16.80232048034668
Epoch 14000, Train Cost 19.590595245361328, Monte Carlo Cost: 16.124584197998047
Epoch 15000, Train Cost 16.037012100219727, Monte Carlo Cost: 15.478355407714844
Epoch 16000, Train Cost 12.369144439697266, Monte Carlo Cost: 14.85119915008545
Epoch 17000, Train Cost 15.385241508483887, Monte Carlo Cost: 14.253835678100586
Epoch 18000, Train Cost 19.563508987426758, Monte Carlo Cost: 13.679712295532227
Epoch 19000, Train Cost 12.742430686950684, Monte Carlo Cost: 13.12021255493164
Epoch 20000, Train Cost 17.28359031677246, Monte Carlo Cost: 12.58883285522461
Seed 158, optimizer <class 'tensorflow.python.training.adam.AdamOptimizer'>, lr Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 158
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: Tensor("InverseTimeDecay_2:0", shape=(), dtype=float32)
Optimizer: <class 'tensorflow.python.training.adam.AdamOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 35.627479553222656, Monte Carlo Cost: 24.418697357177734
Epoch 2000, Train Cost 31.295455932617188, Monte Carlo Cost: 24.412195205688477
Epoch 3000, Train Cost 33.48815155029297, Monte Carlo Cost: 24.405689239501953
Epoch 4000, Train Cost 26.964134216308594, Monte Carlo Cost: 24.399166107177734
Epoch 5000, Train Cost 28.015546798706055, Monte Carlo Cost: 24.392641067504883
Epoch 6000, Train Cost 42.343238830566406, Monte Carlo Cost: 24.38616943359375
Epoch 7000, Train Cost 32.095863342285156, Monte Carlo Cost: 24.379621505737305
Epoch 8000, Train Cost 36.30306625366211, Monte Carlo Cost: 24.373126983642578
Epoch 9000, Train Cost 41.16081619262695, Monte Carlo Cost: 24.366657257080078
Epoch 10000, Train Cost 32.45887756347656, Monte Carlo Cost: 24.36012840270996
Epoch 11000, Train Cost 33.2741813659668, Monte Carlo Cost: 24.353605270385742
Epoch 12000, Train Cost 28.93536376953125, Monte Carlo Cost: 24.347137451171875
Epoch 13000, Train Cost 37.435516357421875, Monte Carlo Cost: 24.340625762939453
Epoch 14000, Train Cost 35.39192199707031, Monte Carlo Cost: 24.33414077758789
Epoch 15000, Train Cost 27.86767578125, Monte Carlo Cost: 24.327669143676758
Epoch 16000, Train Cost 23.54572296142578, Monte Carlo Cost: 24.321163177490234
Epoch 17000, Train Cost 25.64940071105957, Monte Carlo Cost: 24.314701080322266
Epoch 18000, Train Cost 34.93894577026367, Monte Carlo Cost: 24.30824089050293
Epoch 19000, Train Cost 29.266433715820312, Monte Carlo Cost: 24.30175018310547
Epoch 20000, Train Cost 34.66224670410156, Monte Carlo Cost: 24.295255661010742
Seed 7, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 0.0001
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 7
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 0.0001
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------

Beginning Training....
Training Batch Size: 50, MC Batch Size: 50
Epoch 1000, Train Cost 10.842073440551758, Monte Carlo Cost: 6.095582962036133
Epoch 2000, Train Cost 4.499393939971924, Monte Carlo Cost: 4.0191650390625
Epoch 3000, Train Cost 1.2643861770629883, Monte Carlo Cost: 1.92701256275177
Epoch 4000, Train Cost 1.114264965057373, Monte Carlo Cost: 1.5095264911651611
Epoch 5000, Train Cost 1.867448091506958, Monte Carlo Cost: 1.4491498470306396
Epoch 6000, Train Cost 1.1170713901519775, Monte Carlo Cost: 1.4215866327285767
Epoch 7000, Train Cost 0.9566181302070618, Monte Carlo Cost: 1.4050723314285278
Epoch 8000, Train Cost 1.0505293607711792, Monte Carlo Cost: 1.389543056488037
Epoch 9000, Train Cost 1.190461277961731, Monte Carlo Cost: 1.370228886604309
Epoch 10000, Train Cost 0.8643597960472107, Monte Carlo Cost: 1.3570618629455566
Epoch 11000, Train Cost 0.8667188882827759, Monte Carlo Cost: 1.344783067703247
Epoch 12000, Train Cost 1.0635616779327393, Monte Carlo Cost: 1.3314826488494873
Epoch 13000, Train Cost 1.178372859954834, Monte Carlo Cost: 1.3216569423675537
Epoch 14000, Train Cost 1.366537094116211, Monte Carlo Cost: 1.3136756420135498
Epoch 15000, Train Cost 1.210431694984436, Monte Carlo Cost: 1.3021438121795654
Epoch 16000, Train Cost 2.093000888824463, Monte Carlo Cost: 1.2968965768814087
Epoch 17000, Train Cost 0.8203909993171692, Monte Carlo Cost: 1.2900466918945312
Epoch 18000, Train Cost 1.343940019607544, Monte Carlo Cost: 1.2816747426986694
Epoch 19000, Train Cost 0.8978590369224548, Monte Carlo Cost: 1.2746493816375732
Epoch 20000, Train Cost 1.0045750141143799, Monte Carlo Cost: 1.2678457498550415
Seed 7, optimizer <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>, lr 1e-06
--------------------------------------------------
HYPERPARAMETER DETAILS FOR THIS RUN:
RANDOM SEED: 7
----------------------
PROBLEM SPECIFICATION
Dimension: 1, K-Squared: 0.04
X Standard Deviation: 5, Z Standard Deviation: 1
----------------------
Network Units: [1, 150, 1, 30, 1]
----------------------
ENCODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
----------------------
DECODER SPECS
Learning Rate: 1e-06
Optimizer: <class 'tensorflow.python.training.gradient_descent.GradientDescentOptimizer'>
Activation Functions: [<function sigmoid at 0x1a104aae18>, <function identity at 0x1a1002bd08>]
Pre-Initialized Weights: No
Weight Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a1884ef60>
Bias Initialization Function: <tensorflow.python.ops.init_ops.VarianceScaling object at 0x1a18af63c8>
--------------------------------------------------
