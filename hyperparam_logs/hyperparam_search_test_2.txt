NOTE: Decay was always 1 - 1e-10
RUN NUMBER 1
RUNNING FOR learning_rate: 0.001, num_units_1: 100, num_units_2: 20, k_sq: 0.5, epochs: 25000, activation_fn_1: <function sigmoid at 0x114cfdea0>, activation_fn_2: <function sigmoid at 0x114cfdea0>
-----------------------------------------------

step: 0, loss: 7.607312202453613
step: 100, loss: 7.843149662017822
step: 200, loss: 8.102782249450684
step: 300, loss: 8.710657119750977
step: 400, loss: 7.831283092498779
step: 500, loss: 7.876296043395996
step: 600, loss: 6.34389591217041
step: 700, loss: 7.191333293914795
step: 800, loss: 5.740078449249268
step: 900, loss: 4.999862194061279
step: 1000, loss: 7.263905048370361
step: 1100, loss: 5.744967937469482
step: 1200, loss: 5.565399646759033
step: 1300, loss: 6.39827823638916
step: 1400, loss: 8.3673734664917
step: 1500, loss: 6.738277912139893
step: 1600, loss: 8.154458999633789
step: 1700, loss: 6.7805094718933105
step: 1800, loss: 4.902860641479492
step: 1900, loss: 5.897399425506592
step: 2000, loss: 5.047150611877441
step: 2100, loss: 5.3065571784973145
step: 2200, loss: 6.635120391845703
step: 2300, loss: 6.74006462097168
step: 2400, loss: 5.667145729064941
step: 2500, loss: 5.704464435577393
step: 2600, loss: 4.835781574249268
step: 2700, loss: 5.533454418182373
step: 2800, loss: 5.218203067779541
step: 2900, loss: 4.287289142608643
step: 3000, loss: 5.9701828956604
step: 3100, loss: 5.215230941772461
step: 3200, loss: 6.990509033203125
step: 3300, loss: 6.16970682144165
step: 3400, loss: 6.0717692375183105
step: 3500, loss: 5.927662372589111
step: 3600, loss: 4.831292152404785
step: 3700, loss: 4.597212314605713
step: 3800, loss: 6.112159252166748
step: 3900, loss: 6.827862739562988
step: 4000, loss: 5.084651470184326
step: 4100, loss: 6.927620887756348
step: 4200, loss: 6.649537563323975
step: 4300, loss: 7.459415912628174
step: 4400, loss: 6.3178558349609375
step: 4500, loss: 6.465470790863037
step: 4600, loss: 4.960171222686768
step: 4700, loss: 4.483030319213867
step: 4800, loss: 4.291321754455566
step: 4900, loss: 6.993824481964111
step: 5000, loss: 4.698447227478027
step: 5100, loss: 6.357895374298096
step: 5200, loss: 5.565497875213623
step: 5300, loss: 5.062906742095947
step: 5400, loss: 6.693744659423828
step: 5500, loss: 5.818550109863281
step: 5600, loss: 4.990453720092773
step: 5700, loss: 4.513396263122559
step: 5800, loss: 5.262054443359375
step: 5900, loss: 6.822458267211914
step: 6000, loss: 5.283138751983643
step: 6100, loss: 5.355081558227539
step: 6200, loss: 4.713415145874023
step: 6300, loss: 6.701007843017578
step: 6400, loss: 5.907814979553223
step: 6500, loss: 5.59275484085083
step: 6600, loss: 5.278071880340576
step: 6700, loss: 5.025417804718018
step: 6800, loss: 4.865289688110352
step: 6900, loss: 5.6949896812438965
step: 7000, loss: 5.463691711425781
step: 7100, loss: 5.606734275817871
step: 7200, loss: 7.890275478363037
step: 7300, loss: 7.169734954833984
step: 7400, loss: 5.039151668548584
step: 7500, loss: 5.18470573425293
step: 7600, loss: 5.345582962036133
step: 7700, loss: 5.610236644744873
step: 7800, loss: 5.136681079864502
step: 7900, loss: 4.237648963928223
step: 8000, loss: 6.040578842163086
step: 8100, loss: 6.637079238891602
step: 8200, loss: 5.969001293182373
step: 8300, loss: 5.5760040283203125
step: 8400, loss: 5.630486488342285
step: 8500, loss: 6.695770263671875
step: 8600, loss: 7.61889123916626
step: 8700, loss: 6.041531562805176
step: 8800, loss: 5.330872535705566
step: 8900, loss: 5.889496803283691
step: 9000, loss: 5.1913604736328125
step: 9100, loss: 5.248228073120117
step: 9200, loss: 4.842404365539551
step: 9300, loss: 5.117396354675293
step: 9400, loss: 3.4500155448913574
step: 9500, loss: 5.465107440948486
step: 9600, loss: 4.955482006072998
step: 9700, loss: 5.01935338973999
step: 9800, loss: 4.90587043762207
step: 9900, loss: 5.364416599273682
step: 10000, loss: 3.787599563598633
step: 10100, loss: 5.8047261238098145
step: 10200, loss: 4.756577491760254
step: 10300, loss: 5.722859859466553
step: 10400, loss: 6.307718753814697
step: 10500, loss: 5.824419975280762
step: 10600, loss: 5.979339599609375
step: 10700, loss: 6.094178199768066
step: 10800, loss: 4.98520040512085
step: 10900, loss: 4.836050987243652
step: 11000, loss: 6.36544942855835
step: 11100, loss: 6.625669479370117
step: 11200, loss: 4.435271739959717
step: 11300, loss: 5.30194091796875
step: 11400, loss: 4.615682125091553
step: 11500, loss: 4.536461353302002
step: 11600, loss: 6.6945719718933105
step: 11700, loss: 6.758110523223877
step: 11800, loss: 5.770319938659668
step: 11900, loss: 5.796020030975342
step: 12000, loss: 5.288244724273682
step: 12100, loss: 6.823719501495361
step: 12200, loss: 6.187778949737549
step: 12300, loss: 4.809633731842041
step: 12400, loss: 6.632535457611084
step: 12500, loss: 4.077066898345947
step: 12600, loss: 4.3997111320495605
step: 12700, loss: 3.941983938217163
step: 12800, loss: 5.263469219207764
step: 12900, loss: 6.6512274742126465
step: 13000, loss: 5.918768882751465
step: 13100, loss: 6.0769572257995605
step: 13200, loss: 6.051058292388916
step: 13300, loss: 4.9464945793151855
step: 13400, loss: 4.370560646057129
step: 13500, loss: 5.461174964904785
step: 13600, loss: 6.128078937530518
step: 13700, loss: 5.163210391998291
step: 13800, loss: 5.6421217918396
step: 13900, loss: 6.469634532928467
step: 14000, loss: 5.155922889709473
step: 14100, loss: 4.91090726852417
step: 14200, loss: 7.088547229766846
step: 14300, loss: 6.757668972015381
step: 14400, loss: 4.375601291656494
step: 14500, loss: 5.977997303009033
step: 14600, loss: 4.179718971252441
step: 14700, loss: 4.769705772399902
step: 14800, loss: 5.218704700469971
step: 14900, loss: 8.881048202514648
step: 15000, loss: 6.008771896362305
step: 15100, loss: 4.017458438873291
step: 15200, loss: 5.755553245544434
step: 15300, loss: 4.921792507171631
step: 15400, loss: 7.771457672119141
step: 15500, loss: 5.191714286804199
step: 15600, loss: 5.149304389953613
step: 15700, loss: 5.8185038566589355
step: 15800, loss: 4.667052745819092
step: 15900, loss: 5.752682209014893
step: 16000, loss: 6.001420021057129
step: 16100, loss: 3.9826695919036865
step: 16200, loss: 4.831284523010254
step: 16300, loss: 3.8249714374542236
step: 16400, loss: 6.837386131286621
step: 16500, loss: 5.153385639190674
step: 16600, loss: 5.496487617492676
step: 16700, loss: 4.793839454650879
step: 16800, loss: 7.717238426208496
step: 16900, loss: 4.805902004241943
step: 17000, loss: 7.177842140197754
step: 17100, loss: 5.709907054901123
step: 17200, loss: 5.024785041809082
step: 17300, loss: 7.436349391937256
step: 17400, loss: 6.573741436004639
step: 17500, loss: 5.014702320098877
step: 17600, loss: 5.597906112670898
step: 17700, loss: 5.174971103668213
step: 17800, loss: 7.044604778289795
step: 17900, loss: 4.0705976486206055
step: 18000, loss: 5.576981544494629
step: 18100, loss: 5.072922229766846
step: 18200, loss: 4.861825942993164
step: 18300, loss: 4.987496376037598
step: 18400, loss: 4.2201385498046875
step: 18500, loss: 6.2507243156433105
step: 18600, loss: 6.203164577484131
step: 18700, loss: 4.826888084411621
step: 18800, loss: 4.119563102722168
step: 18900, loss: 5.911398887634277
step: 19000, loss: 4.382330894470215
step: 19100, loss: 5.700955390930176
step: 19200, loss: 5.457331657409668
step: 19300, loss: 4.873878479003906
step: 19400, loss: 6.248476982116699
step: 19500, loss: 5.230525016784668
step: 19600, loss: 5.443535804748535
step: 19700, loss: 6.328268527984619
step: 19800, loss: 5.649352073669434
step: 19900, loss: 6.341439247131348
step: 20000, loss: 8.352532386779785
step: 20100, loss: 5.9100341796875
step: 20200, loss: 6.428572654724121
step: 20300, loss: 5.874992847442627
step: 20400, loss: 5.115213871002197
step: 20500, loss: 3.9070985317230225
step: 20600, loss: 5.296538352966309
step: 20700, loss: 5.5431013107299805
step: 20800, loss: 6.812294960021973
step: 20900, loss: 5.285912036895752
step: 21000, loss: 5.129921913146973
step: 21100, loss: 6.5664381980896
step: 21200, loss: 7.303416728973389
step: 21300, loss: 5.840334415435791
step: 21400, loss: 5.4805731773376465
step: 21500, loss: 5.019271373748779
step: 21600, loss: 5.68595552444458
step: 21700, loss: 4.748937606811523
step: 21800, loss: 4.3373942375183105
step: 21900, loss: 6.042829990386963
step: 22000, loss: 5.782602787017822
step: 22100, loss: 4.766026496887207
step: 22200, loss: 5.231788158416748
step: 22300, loss: 5.002823829650879
step: 22400, loss: 6.316131591796875
step: 22500, loss: 4.579311370849609
step: 22600, loss: 6.4525628089904785
step: 22700, loss: 5.494283199310303
step: 22800, loss: 4.775090217590332
step: 22900, loss: 5.362667560577393
step: 23000, loss: 5.39292049407959
step: 23100, loss: 5.576749324798584
step: 23200, loss: 5.46682596206665
step: 23300, loss: 4.927933216094971
step: 23400, loss: 4.629030227661133
step: 23500, loss: 5.680417537689209
step: 23600, loss: 5.9494428634643555
step: 23700, loss: 4.519582271575928
step: 23800, loss: 5.121947288513184
step: 23900, loss: 5.44638729095459
step: 24000, loss: 5.653218746185303
step: 24100, loss: 6.022618293762207
step: 24200, loss: 4.9597978591918945
step: 24300, loss: 6.33544397354126
step: 24400, loss: 4.722706317901611
step: 24500, loss: 5.204754829406738
step: 24600, loss: 5.614094257354736
step: 24700, loss: 5.636285305023193
step: 24800, loss: 4.933198928833008
step: 24900, loss: 7.498426914215088
Mean loss is 0.002919146263797757
-----------------------------------------------

RUN NUMBER 2
RUNNING FOR learning_rate: 0.0001, num_units_1: 100, num_units_2: 20, k_sq: 0.5, epochs: 25000, activation_fn_1: <function sigmoid at 0x114cfdea0>, activation_fn_2: <function sigmoid at 0x114cfdea0>
-----------------------------------------------

step: 0, loss: 9.88598346710205
step: 100, loss: 11.269152641296387
step: 200, loss: 8.654858589172363
step: 300, loss: 9.45964241027832
step: 400, loss: 8.570846557617188
step: 500, loss: 9.2174072265625
step: 600, loss: 8.065103530883789
step: 700, loss: 8.429524421691895
step: 800, loss: 8.785500526428223
step: 900, loss: 7.103394985198975
step: 1000, loss: 7.533290863037109
step: 1100, loss: 7.200931549072266
step: 1200, loss: 7.542022228240967
step: 1300, loss: 8.75820541381836
step: 1400, loss: 10.073541641235352
step: 1500, loss: 7.067766189575195
step: 1600, loss: 7.749814033508301
step: 1700, loss: 7.908708095550537
step: 1800, loss: 7.09785270690918
step: 1900, loss: 8.070393562316895
step: 2000, loss: 6.197052955627441
step: 2100, loss: 9.356735229492188
step: 2200, loss: 9.918791770935059
step: 2300, loss: 7.994999408721924
step: 2400, loss: 8.136772155761719
step: 2500, loss: 6.65263032913208
step: 2600, loss: 7.523231029510498
step: 2700, loss: 9.690041542053223
step: 2800, loss: 8.431641578674316
step: 2900, loss: 10.031207084655762
step: 3000, loss: 10.773408889770508
step: 3100, loss: 8.236007690429688
step: 3200, loss: 8.646611213684082
step: 3300, loss: 7.036998748779297
step: 3400, loss: 8.039844512939453
step: 3500, loss: 6.897496223449707
step: 3600, loss: 7.369786262512207
step: 3700, loss: 7.186796188354492
step: 3800, loss: 7.757132530212402
step: 3900, loss: 8.022993087768555
step: 4000, loss: 8.280021667480469
step: 4100, loss: 5.623536109924316
step: 4200, loss: 6.51870059967041
step: 4300, loss: 7.035726547241211
step: 4400, loss: 6.517234802246094
step: 4500, loss: 5.808835983276367
step: 4600, loss: 6.302365779876709
step: 4700, loss: 8.2735595703125
step: 4800, loss: 8.58518123626709
step: 4900, loss: 7.173524856567383
step: 5000, loss: 7.86392068862915
step: 5100, loss: 6.018571853637695
step: 5200, loss: 6.784978866577148
step: 5300, loss: 7.35334587097168
step: 5400, loss: 5.820188045501709
step: 5500, loss: 7.088442802429199
step: 5600, loss: 6.688212871551514
step: 5700, loss: 7.73441743850708
step: 5800, loss: 8.22185230255127
step: 5900, loss: 6.4778218269348145
step: 6000, loss: 6.365397930145264
step: 6100, loss: 6.67546272277832
step: 6200, loss: 5.936837196350098
step: 6300, loss: 8.397613525390625
step: 6400, loss: 7.703507423400879
step: 6500, loss: 7.943633079528809
step: 6600, loss: 6.487305164337158
step: 6700, loss: 5.879980564117432
step: 6800, loss: 7.719459056854248
step: 6900, loss: 6.247681617736816
step: 7000, loss: 7.945613384246826
step: 7100, loss: 5.553769588470459
step: 7200, loss: 8.83802318572998
step: 7300, loss: 7.317737579345703
step: 7400, loss: 7.6743927001953125
step: 7500, loss: 6.455471992492676
step: 7600, loss: 9.176409721374512
step: 7700, loss: 5.904788970947266
step: 7800, loss: 6.176458358764648
step: 7900, loss: 5.490374565124512
step: 8000, loss: 7.261054039001465
step: 8100, loss: 5.995811462402344
step: 8200, loss: 4.738716125488281
step: 8300, loss: 5.751193523406982
step: 8400, loss: 6.303826808929443
step: 8500, loss: 5.674795150756836
step: 8600, loss: 8.765302658081055
step: 8700, loss: 5.615273952484131
step: 8800, loss: 7.49956750869751
step: 8900, loss: 6.7043280601501465
step: 9000, loss: 6.316164493560791
step: 9100, loss: 5.982845783233643
step: 9200, loss: 5.858772277832031
step: 9300, loss: 5.067344665527344
step: 9400, loss: 4.5684661865234375
step: 9500, loss: 7.818877220153809
step: 9600, loss: 6.890273571014404
step: 9700, loss: 7.246854782104492
step: 9800, loss: 5.274859428405762
step: 9900, loss: 4.9773945808410645
step: 10000, loss: 5.424541473388672
step: 10100, loss: 7.139496326446533
step: 10200, loss: 7.047134876251221
step: 10300, loss: 5.795129299163818
step: 10400, loss: 5.807517051696777
step: 10500, loss: 4.335722923278809
step: 10600, loss: 6.1059088706970215
step: 10700, loss: 6.852846145629883
step: 10800, loss: 8.993993759155273
step: 10900, loss: 8.330973625183105
step: 11000, loss: 5.460546970367432
step: 11100, loss: 7.297577857971191
step: 11200, loss: 7.164680480957031
step: 11300, loss: 7.091019630432129
step: 11400, loss: 6.679254055023193
step: 11500, loss: 4.519354820251465
step: 11600, loss: 6.057711601257324
step: 11700, loss: 5.739029884338379
step: 11800, loss: 6.449687480926514
step: 11900, loss: 6.141017913818359
step: 12000, loss: 6.685166835784912
step: 12100, loss: 5.474523067474365
step: 12200, loss: 7.1779632568359375
step: 12300, loss: 5.531686305999756
step: 12400, loss: 7.814335823059082
step: 12500, loss: 6.5388102531433105
step: 12600, loss: 5.624863147735596
step: 12700, loss: 5.551468849182129
step: 12800, loss: 7.159173488616943
step: 12900, loss: 6.640570640563965
step: 13000, loss: 6.274289608001709
step: 13100, loss: 5.780191421508789
step: 13200, loss: 5.066187858581543
step: 13300, loss: 6.721771717071533
step: 13400, loss: 7.361982345581055
step: 13500, loss: 6.194204330444336
step: 13600, loss: 4.076966762542725
step: 13700, loss: 6.0212788581848145
step: 13800, loss: 5.920095443725586
step: 13900, loss: 7.140442371368408
step: 14000, loss: 6.018367290496826
step: 14100, loss: 6.718879222869873
step: 14200, loss: 8.23784065246582
step: 14300, loss: 5.737714767456055
step: 14400, loss: 5.9377055168151855
step: 14500, loss: 5.3726348876953125
step: 14600, loss: 7.742526054382324
step: 14700, loss: 5.697425842285156
step: 14800, loss: 7.325944900512695
step: 14900, loss: 5.824836730957031
step: 15000, loss: 6.438165187835693
step: 15100, loss: 7.301222324371338
step: 15200, loss: 4.890763282775879
step: 15300, loss: 6.61675500869751
step: 15400, loss: 8.012375831604004
step: 15500, loss: 6.177684783935547
step: 15600, loss: 6.9659318923950195
step: 15700, loss: 5.329334259033203
step: 15800, loss: 5.413791179656982
step: 15900, loss: 7.005307674407959
step: 16000, loss: 5.545317649841309
step: 16100, loss: 6.046409606933594
step: 16200, loss: 4.955483913421631
step: 16300, loss: 6.570723056793213
step: 16400, loss: 6.413555145263672
step: 16500, loss: 5.214598178863525
step: 16600, loss: 5.025464057922363
step: 16700, loss: 7.0714311599731445
step: 16800, loss: 7.650794506072998
step: 16900, loss: 6.407621383666992
step: 17000, loss: 6.75537109375
step: 17100, loss: 7.157235622406006
step: 17200, loss: 5.266052722930908
step: 17300, loss: 5.951895713806152
step: 17400, loss: 5.256125450134277
step: 17500, loss: 5.716119766235352
step: 17600, loss: 8.447807312011719
step: 17700, loss: 6.062943458557129
step: 17800, loss: 5.189138412475586
step: 17900, loss: 5.045941352844238
step: 18000, loss: 5.961847305297852
step: 18100, loss: 7.787669658660889
step: 18200, loss: 7.019747734069824
step: 18300, loss: 6.246338844299316
step: 18400, loss: 4.986668586730957
step: 18500, loss: 5.691166877746582
step: 18600, loss: 6.3713274002075195
step: 18700, loss: 5.50478982925415
step: 18800, loss: 4.7018585205078125
step: 18900, loss: 5.262357711791992
step: 19000, loss: 6.943792343139648
step: 19100, loss: 7.911406517028809
step: 19200, loss: 5.3058180809021
step: 19300, loss: 7.83821439743042
step: 19400, loss: 6.1734747886657715
step: 19500, loss: 7.124332427978516
step: 19600, loss: 6.221804618835449
step: 19700, loss: 5.435659408569336
step: 19800, loss: 6.357921600341797
step: 19900, loss: 4.822882652282715
step: 20000, loss: 5.192744255065918
step: 20100, loss: 6.577375411987305
step: 20200, loss: 4.551931381225586
step: 20300, loss: 5.803896903991699
step: 20400, loss: 6.29831075668335
step: 20500, loss: 4.938915729522705
step: 20600, loss: 3.9502880573272705
step: 20700, loss: 6.612320423126221
step: 20800, loss: 7.024219036102295
step: 20900, loss: 6.940830230712891
step: 21000, loss: 6.425718307495117
step: 21100, loss: 6.027665615081787
step: 21200, loss: 7.344264507293701
step: 21300, loss: 5.2318549156188965
step: 21400, loss: 5.822484016418457
step: 21500, loss: 7.329771995544434
step: 21600, loss: 5.526362895965576
step: 21700, loss: 7.406130313873291
step: 21800, loss: 6.668457984924316
step: 21900, loss: 5.177209854125977
step: 22000, loss: 7.034834861755371
step: 22100, loss: 5.58966588973999
step: 22200, loss: 4.944741725921631
step: 22300, loss: 6.097631454467773
step: 22400, loss: 4.985325813293457
step: 22500, loss: 7.886486053466797
step: 22600, loss: 5.806057929992676
step: 22700, loss: 4.75344705581665
step: 22800, loss: 7.314589977264404
step: 22900, loss: 4.6610822677612305
step: 23000, loss: 4.061829090118408
step: 23100, loss: 4.485743522644043
step: 23200, loss: 4.941198348999023
step: 23300, loss: 5.569526195526123
step: 23400, loss: 5.241635322570801
step: 23500, loss: 5.399377822875977
step: 23600, loss: 7.701114177703857
step: 23700, loss: 6.1957478523254395
step: 23800, loss: 6.746422290802002
step: 23900, loss: 6.515584945678711
step: 24000, loss: 5.627889156341553
step: 24100, loss: 5.707550048828125
step: 24200, loss: 5.145153522491455
step: 24300, loss: 6.596126556396484
step: 24400, loss: 6.901065826416016
step: 24500, loss: 5.470958709716797
step: 24600, loss: 5.837861061096191
step: 24700, loss: 5.19789457321167
step: 24800, loss: 4.475378036499023
step: 24900, loss: 7.500101089477539
Mean loss is 0.003125390098323861
-----------------------------------------------

RUN NUMBER 3
RUNNING FOR learning_rate: 1e-05, num_units_1: 100, num_units_2: 20, k_sq: 0.5, epochs: 25000, activation_fn_1: <function sigmoid at 0x114cfdea0>, activation_fn_2: <function sigmoid at 0x114cfdea0>
-----------------------------------------------

step: 0, loss: 10.539836883544922
step: 100, loss: 7.113948345184326
step: 200, loss: 10.482067108154297
step: 300, loss: 10.872127532958984
step: 400, loss: 8.184857368469238
step: 500, loss: 9.468124389648438
step: 600, loss: 9.530341148376465
step: 700, loss: 7.168969631195068
step: 800, loss: 9.5994234085083
step: 900, loss: 8.556228637695312
step: 1000, loss: 11.16122817993164
step: 1100, loss: 8.704107284545898
step: 1200, loss: 10.970804214477539
step: 1300, loss: 7.672084331512451
step: 1400, loss: 9.997551918029785
step: 1500, loss: 8.48557186126709
step: 1600, loss: 11.034732818603516
step: 1700, loss: 8.19468879699707
step: 1800, loss: 7.1671671867370605
step: 1900, loss: 10.395252227783203
step: 2000, loss: 9.037890434265137
step: 2100, loss: 7.295888423919678
step: 2200, loss: 9.008894920349121
step: 2300, loss: 7.862851142883301
step: 2400, loss: 8.053759574890137
step: 2500, loss: 8.234600067138672
step: 2600, loss: 8.458569526672363
step: 2700, loss: 7.63549280166626
step: 2800, loss: 8.76052474975586
step: 2900, loss: 6.860021114349365
step: 3000, loss: 8.5009183883667
step: 3100, loss: 8.614768981933594
step: 3200, loss: 9.043374061584473
step: 3300, loss: 6.8897318840026855
step: 3400, loss: 10.059170722961426
step: 3500, loss: 10.126090049743652
step: 3600, loss: 8.722917556762695
step: 3700, loss: 11.366201400756836
step: 3800, loss: 9.907944679260254
step: 3900, loss: 10.6264009475708
step: 4000, loss: 8.78885269165039
step: 4100, loss: 7.079709053039551
step: 4200, loss: 9.901025772094727
step: 4300, loss: 10.223726272583008
step: 4400, loss: 6.943389892578125
step: 4500, loss: 8.457808494567871
step: 4600, loss: 7.95642614364624
step: 4700, loss: 9.204769134521484
step: 4800, loss: 8.805036544799805
step: 4900, loss: 8.212203979492188
step: 5000, loss: 8.139351844787598
step: 5100, loss: 9.634381294250488
step: 5200, loss: 7.180039882659912
step: 5300, loss: 9.063885688781738
step: 5400, loss: 9.160368919372559
step: 5500, loss: 8.33552074432373
step: 5600, loss: 9.083197593688965
step: 5700, loss: 8.755866050720215
step: 5800, loss: 9.030145645141602
step: 5900, loss: 7.30318546295166
step: 6000, loss: 6.808088779449463
step: 6100, loss: 9.089322090148926
step: 6200, loss: 9.337597846984863
step: 6300, loss: 7.937832355499268
step: 6400, loss: 11.132192611694336
step: 6500, loss: 6.722132682800293
step: 6600, loss: 7.738603591918945
step: 6700, loss: 8.809208869934082
step: 6800, loss: 9.763715744018555
step: 6900, loss: 7.315123558044434
step: 7000, loss: 11.238920211791992
step: 7100, loss: 9.714075088500977
step: 7200, loss: 7.9111714363098145
step: 7300, loss: 9.201558113098145
step: 7400, loss: 8.040766716003418
step: 7500, loss: 6.379043102264404
step: 7600, loss: 9.852035522460938
step: 7700, loss: 11.686890602111816
step: 7800, loss: 8.59864616394043
step: 7900, loss: 10.470251083374023
step: 8000, loss: 7.646914005279541
step: 8100, loss: 10.345928192138672
step: 8200, loss: 7.492863178253174
step: 8300, loss: 7.425793647766113
step: 8400, loss: 9.17748737335205
step: 8500, loss: 9.148887634277344
step: 8600, loss: 8.555699348449707
step: 8700, loss: 9.22607421875
step: 8800, loss: 6.718168258666992
step: 8900, loss: 8.698405265808105
step: 9000, loss: 8.519872665405273
step: 9100, loss: 8.01964282989502
step: 9200, loss: 9.047134399414062
step: 9300, loss: 9.905318260192871
step: 9400, loss: 6.933111190795898
step: 9500, loss: 8.977771759033203
step: 9600, loss: 6.073920726776123
step: 9700, loss: 8.62493896484375
step: 9800, loss: 7.282333850860596
step: 9900, loss: 8.925029754638672
step: 10000, loss: 7.865416049957275
step: 10100, loss: 8.485811233520508
step: 10200, loss: 7.187961578369141
step: 10300, loss: 7.914943218231201
step: 10400, loss: 8.951610565185547
step: 10500, loss: 7.669200420379639
step: 10600, loss: 8.162355422973633
step: 10700, loss: 9.287188529968262
step: 10800, loss: 7.555001735687256
step: 10900, loss: 8.46217155456543
step: 11000, loss: 7.72627067565918
step: 11100, loss: 8.932171821594238
step: 11200, loss: 6.210336685180664
step: 11300, loss: 9.692341804504395
step: 11400, loss: 9.766100883483887
step: 11500, loss: 6.089061737060547
step: 11600, loss: 7.786397933959961
step: 11700, loss: 8.147089004516602
step: 11800, loss: 7.751468181610107
step: 11900, loss: 7.788028240203857
step: 12000, loss: 7.089295387268066
step: 12100, loss: 9.277739524841309
step: 12200, loss: 9.645772933959961
step: 12300, loss: 7.592135429382324
step: 12400, loss: 9.385631561279297
step: 12500, loss: 8.398935317993164
step: 12600, loss: 9.165304183959961
step: 12700, loss: 7.7837114334106445
step: 12800, loss: 9.297588348388672
step: 12900, loss: 7.745972633361816
step: 13000, loss: 7.036226749420166
step: 13100, loss: 8.477592468261719
step: 13200, loss: 8.024569511413574
step: 13300, loss: 7.304498195648193
step: 13400, loss: 5.939248561859131
step: 13500, loss: 7.778163909912109
step: 13600, loss: 5.732496738433838
step: 13700, loss: 9.045165061950684
step: 13800, loss: 8.974688529968262
step: 13900, loss: 8.226393699645996
step: 14000, loss: 7.121640205383301
step: 14100, loss: 7.418637752532959
step: 14200, loss: 7.685995101928711
step: 14300, loss: 7.383601665496826
step: 14400, loss: 10.227560043334961
step: 14500, loss: 9.208651542663574
step: 14600, loss: 10.474750518798828
step: 14700, loss: 9.01937484741211
step: 14800, loss: 9.674479484558105
step: 14900, loss: 10.076550483703613
step: 15000, loss: 7.979445457458496
step: 15100, loss: 9.296992301940918
step: 15200, loss: 10.658159255981445
step: 15300, loss: 9.579235076904297
step: 15400, loss: 7.854320526123047
step: 15500, loss: 7.992910861968994
step: 15600, loss: 6.718493938446045
step: 15700, loss: 11.79271411895752
step: 15800, loss: 7.107073783874512
step: 15900, loss: 6.714292526245117
step: 16000, loss: 9.371155738830566
step: 16100, loss: 9.06989860534668
step: 16200, loss: 7.808785915374756
step: 16300, loss: 7.6208415031433105
step: 16400, loss: 9.238225936889648
step: 16500, loss: 8.610361099243164
step: 16600, loss: 6.805987358093262
step: 16700, loss: 8.6046724319458
step: 16800, loss: 7.096522808074951
step: 16900, loss: 7.805721282958984
step: 17000, loss: 6.476334571838379
step: 17100, loss: 8.674649238586426
step: 17200, loss: 9.154723167419434
step: 17300, loss: 9.171868324279785
step: 17400, loss: 7.385018825531006
step: 17500, loss: 7.312846660614014
step: 17600, loss: 7.400465488433838
step: 17700, loss: 5.622341632843018
step: 17800, loss: 8.104470252990723
step: 17900, loss: 7.891554832458496
step: 18000, loss: 7.353149890899658
step: 18100, loss: 7.258561134338379
step: 18200, loss: 8.640572547912598
step: 18300, loss: 10.432308197021484
step: 18400, loss: 7.917527675628662
step: 18500, loss: 5.572973251342773
step: 18600, loss: 6.469017028808594
step: 18700, loss: 7.443446636199951
step: 18800, loss: 7.75441312789917
step: 18900, loss: 6.9515533447265625
step: 19000, loss: 6.575918197631836
step: 19100, loss: 7.755939960479736
step: 19200, loss: 9.94918155670166
step: 19300, loss: 9.574019432067871
step: 19400, loss: 7.330530643463135
step: 19500, loss: 7.312005043029785
step: 19600, loss: 9.619497299194336
step: 19700, loss: 8.31807804107666
step: 19800, loss: 7.718775749206543
step: 19900, loss: 7.108491897583008
step: 20000, loss: 8.046356201171875
step: 20100, loss: 6.877959251403809
step: 20200, loss: 6.544802665710449
step: 20300, loss: 9.196455001831055
step: 20400, loss: 9.222321510314941
step: 20500, loss: 6.804684638977051
step: 20600, loss: 7.319615840911865
step: 20700, loss: 8.0602445602417
step: 20800, loss: 8.891793251037598
step: 20900, loss: 6.848404884338379
step: 21000, loss: 7.115944862365723
step: 21100, loss: 6.395579814910889
step: 21200, loss: 8.442584991455078
step: 21300, loss: 8.145161628723145
step: 21400, loss: 8.770767211914062
step: 21500, loss: 8.906662940979004
step: 21600, loss: 6.844125270843506
step: 21700, loss: 8.674564361572266
step: 21800, loss: 7.964833736419678
step: 21900, loss: 8.26257038116455
step: 22000, loss: 9.633424758911133
step: 22100, loss: 8.626920700073242
step: 22200, loss: 6.694660186767578
step: 22300, loss: 6.996037483215332
step: 22400, loss: 5.786394119262695
step: 22500, loss: 8.25622844696045
step: 22600, loss: 7.899767875671387
step: 22700, loss: 8.178852081298828
step: 22800, loss: 8.99190902709961
step: 22900, loss: 7.26945686340332
step: 23000, loss: 8.661035537719727
step: 23100, loss: 9.534344673156738
step: 23200, loss: 8.142664909362793
step: 23300, loss: 8.915970802307129
step: 23400, loss: 8.524741172790527
step: 23500, loss: 8.194549560546875
step: 23600, loss: 7.76328182220459
step: 23700, loss: 6.3646721839904785
step: 23800, loss: 7.2966132164001465
step: 23900, loss: 7.616511821746826
step: 24000, loss: 8.536867141723633
step: 24100, loss: 7.8380913734436035
step: 24200, loss: 8.593818664550781
step: 24300, loss: 6.692955017089844
step: 24400, loss: 9.975387573242188
step: 24500, loss: 7.169905185699463
step: 24600, loss: 7.419315338134766
step: 24700, loss: 7.716905117034912
step: 24800, loss: 6.680332183837891
step: 24900, loss: 8.883042335510254
Mean loss is 0.004151735582832224
-----------------------------------------------

