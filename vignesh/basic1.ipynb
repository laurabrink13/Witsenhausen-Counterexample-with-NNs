{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import uuid\n",
    "import sys\n",
    "import scipy.stats \n",
    "import matplotlib\n",
    "import itertools \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "---Epoch: 0, Cost: 10.662944793701172\n",
      "---Epoch: 1, Cost: 1.9072867631912231\n",
      "---Epoch: 2, Cost: 2.05507493019104\n",
      "---Epoch: 3, Cost: 4.6709303855896\n",
      "---Epoch: 4, Cost: 4.890200138092041\n",
      "---Epoch: 5, Cost: 3.2700562477111816\n",
      "---Epoch: 6, Cost: 1.7496429681777954\n",
      "---Epoch: 7, Cost: 1.2418804168701172\n",
      "---Epoch: 8, Cost: 1.7021156549453735\n",
      "---Epoch: 9, Cost: 2.397653818130493\n",
      "---Epoch: 10, Cost: 2.688009023666382\n",
      "---Epoch: 11, Cost: 2.3686726093292236\n",
      "---Epoch: 12, Cost: 1.7773725986480713\n",
      "---Epoch: 13, Cost: 1.3059738874435425\n",
      "---Epoch: 14, Cost: 1.1445101499557495\n",
      "---Epoch: 15, Cost: 1.3295968770980835\n",
      "---Epoch: 16, Cost: 1.6315572261810303\n",
      "---Epoch: 17, Cost: 1.8079979419708252\n",
      "---Epoch: 18, Cost: 1.6949056386947632\n",
      "---Epoch: 19, Cost: 1.4120787382125854\n",
      "---Epoch: 20, Cost: 1.1458392143249512\n",
      "---Epoch: 21, Cost: 1.0380823612213135\n",
      "---Epoch: 22, Cost: 1.1386785507202148\n",
      "---Epoch: 23, Cost: 1.3389225006103516\n",
      "---Epoch: 24, Cost: 1.4194092750549316\n",
      "---Epoch: 25, Cost: 1.3673579692840576\n",
      "---Epoch: 26, Cost: 1.182630181312561\n",
      "---Epoch: 27, Cost: 1.0339620113372803\n",
      "---Epoch: 28, Cost: 1.0093644857406616\n",
      "---Epoch: 29, Cost: 1.1022224426269531\n",
      "---Epoch: 30, Cost: 1.2089638710021973\n",
      "---Epoch: 31, Cost: 1.2274435758590698\n",
      "---Epoch: 32, Cost: 1.1471891403198242\n",
      "---Epoch: 33, Cost: 1.0559600591659546\n",
      "---Epoch: 34, Cost: 1.0046592950820923\n",
      "---Epoch: 35, Cost: 1.0319480895996094\n",
      "---Epoch: 36, Cost: 1.091550588607788\n",
      "---Epoch: 37, Cost: 1.1145535707473755\n",
      "---Epoch: 38, Cost: 1.0895291566848755\n",
      "---Epoch: 39, Cost: 1.0463467836380005\n",
      "---Epoch: 40, Cost: 1.0041216611862183\n",
      "---Epoch: 41, Cost: 1.0128506422042847\n",
      "---Epoch: 42, Cost: 1.0418566465377808\n",
      "---Epoch: 43, Cost: 1.0557442903518677\n",
      "---Epoch: 44, Cost: 1.0526823997497559\n",
      "---Epoch: 45, Cost: 1.022777795791626\n",
      "---Epoch: 46, Cost: 1.0106041431427002\n",
      "---Epoch: 47, Cost: 1.0134758949279785\n",
      "---Epoch: 48, Cost: 1.0213581323623657\n",
      "---Epoch: 49, Cost: 1.0280264616012573\n",
      "---Epoch: 50, Cost: 1.0256980657577515\n",
      "---Epoch: 51, Cost: 1.0142165422439575\n",
      "---Epoch: 52, Cost: 1.0036344528198242\n",
      "---Epoch: 53, Cost: 0.9973053336143494\n",
      "---Epoch: 54, Cost: 1.0138072967529297\n",
      "---Epoch: 55, Cost: 1.0199280977249146\n",
      "---Epoch: 56, Cost: 1.0112577676773071\n",
      "---Epoch: 57, Cost: 1.0082927942276\n",
      "---Epoch: 58, Cost: 1.0040638446807861\n",
      "---Epoch: 59, Cost: 0.9998752474784851\n",
      "---Epoch: 60, Cost: 1.0019903182983398\n",
      "---Epoch: 61, Cost: 1.0079808235168457\n",
      "---Epoch: 62, Cost: 1.0152041912078857\n",
      "---Epoch: 63, Cost: 1.000206708908081\n",
      "---Epoch: 64, Cost: 0.9970176815986633\n",
      "---Epoch: 65, Cost: 1.0029610395431519\n",
      "---Epoch: 66, Cost: 0.9995453953742981\n",
      "---Epoch: 67, Cost: 1.0009170770645142\n",
      "---Epoch: 68, Cost: 0.9965088963508606\n",
      "---Epoch: 69, Cost: 0.9967557787895203\n",
      "---Epoch: 70, Cost: 1.0045236349105835\n",
      "---Epoch: 71, Cost: 1.002845048904419\n",
      "---Epoch: 72, Cost: 1.0106778144836426\n",
      "---Epoch: 73, Cost: 1.0095101594924927\n",
      "---Epoch: 74, Cost: 1.0026451349258423\n",
      "---Epoch: 75, Cost: 0.9950255751609802\n",
      "---Epoch: 76, Cost: 1.0028079748153687\n",
      "---Epoch: 77, Cost: 1.004599928855896\n",
      "---Epoch: 78, Cost: 1.0003858804702759\n",
      "---Epoch: 79, Cost: 1.0089945793151855\n",
      "---Epoch: 80, Cost: 0.9991189241409302\n",
      "---Epoch: 81, Cost: 0.9957075119018555\n",
      "---Epoch: 82, Cost: 1.0010766983032227\n",
      "---Epoch: 83, Cost: 0.9944515824317932\n",
      "---Epoch: 84, Cost: 1.0000284910202026\n",
      "---Epoch: 85, Cost: 1.0034674406051636\n",
      "---Epoch: 86, Cost: 1.006497859954834\n",
      "---Epoch: 87, Cost: 1.003588318824768\n",
      "---Epoch: 88, Cost: 1.001779556274414\n",
      "---Epoch: 89, Cost: 0.9999218583106995\n",
      "---Epoch: 90, Cost: 0.9960565567016602\n",
      "---Epoch: 91, Cost: 0.9889164566993713\n",
      "---Epoch: 92, Cost: 0.9981577396392822\n",
      "---Epoch: 93, Cost: 1.0057599544525146\n",
      "---Epoch: 94, Cost: 0.9991506338119507\n",
      "---Epoch: 95, Cost: 1.0019153356552124\n",
      "---Epoch: 96, Cost: 0.9958318471908569\n",
      "---Epoch: 97, Cost: 0.9979777932167053\n",
      "---Epoch: 98, Cost: 0.9980499744415283\n",
      "---Epoch: 99, Cost: 1.0026559829711914\n",
      "---Epoch: 100, Cost: 0.9992555975914001\n",
      "---Epoch: 101, Cost: 0.9913992285728455\n",
      "---Epoch: 102, Cost: 1.001891851425171\n",
      "---Epoch: 103, Cost: 1.0030957460403442\n",
      "---Epoch: 104, Cost: 0.9992926716804504\n",
      "---Epoch: 105, Cost: 1.003950595855713\n",
      "---Epoch: 106, Cost: 0.997678279876709\n",
      "---Epoch: 107, Cost: 0.9871492385864258\n",
      "---Epoch: 108, Cost: 0.9906923174858093\n",
      "---Epoch: 109, Cost: 1.0026990175247192\n",
      "---Epoch: 110, Cost: 0.9986556172370911\n",
      "---Epoch: 111, Cost: 1.001243233680725\n",
      "---Epoch: 112, Cost: 1.0078758001327515\n",
      "---Epoch: 113, Cost: 0.9960818886756897\n",
      "---Epoch: 114, Cost: 0.9943483471870422\n",
      "---Epoch: 115, Cost: 0.9957645535469055\n",
      "---Epoch: 116, Cost: 0.9957739114761353\n",
      "---Epoch: 117, Cost: 0.9994239211082458\n",
      "---Epoch: 118, Cost: 0.9973872900009155\n",
      "---Epoch: 119, Cost: 0.9997804164886475\n",
      "---Epoch: 120, Cost: 1.005440592765808\n",
      "---Epoch: 121, Cost: 0.9938843846321106\n",
      "---Epoch: 122, Cost: 0.9999904632568359\n",
      "---Epoch: 123, Cost: 0.9954013824462891\n",
      "---Epoch: 124, Cost: 0.9971045255661011\n",
      "---Epoch: 125, Cost: 1.0016508102416992\n",
      "---Epoch: 126, Cost: 1.007249355316162\n",
      "---Epoch: 127, Cost: 0.995724081993103\n",
      "---Epoch: 128, Cost: 1.0064376592636108\n",
      "---Epoch: 129, Cost: 1.004622220993042\n",
      "---Epoch: 130, Cost: 0.9949097633361816\n",
      "---Epoch: 131, Cost: 1.000854730606079\n",
      "---Epoch: 132, Cost: 0.995934247970581\n",
      "---Epoch: 133, Cost: 0.9932869672775269\n",
      "---Epoch: 134, Cost: 0.995991587638855\n",
      "---Epoch: 135, Cost: 0.9978386163711548\n",
      "---Epoch: 136, Cost: 1.0034432411193848\n",
      "---Epoch: 137, Cost: 1.005709171295166\n",
      "---Epoch: 138, Cost: 1.0000922679901123\n",
      "---Epoch: 139, Cost: 1.0055915117263794\n",
      "---Epoch: 140, Cost: 1.0000529289245605\n",
      "---Epoch: 141, Cost: 0.998673141002655\n",
      "---Epoch: 142, Cost: 0.99875408411026\n",
      "---Epoch: 143, Cost: 0.9948837757110596\n",
      "---Epoch: 144, Cost: 1.0000685453414917\n",
      "---Epoch: 145, Cost: 1.0024558305740356\n",
      "---Epoch: 146, Cost: 0.9991516470909119\n",
      "---Epoch: 147, Cost: 1.0002946853637695\n",
      "---Epoch: 148, Cost: 0.9985532760620117\n",
      "---Epoch: 149, Cost: 0.9926720857620239\n",
      "---Epoch: 150, Cost: 0.9954415559768677\n",
      "---Epoch: 151, Cost: 1.0100234746932983\n",
      "---Epoch: 152, Cost: 0.9977232813835144\n",
      "---Epoch: 153, Cost: 1.0061205625534058\n",
      "---Epoch: 154, Cost: 1.0034384727478027\n",
      "---Epoch: 155, Cost: 1.0032109022140503\n",
      "---Epoch: 156, Cost: 0.9986581206321716\n",
      "---Epoch: 157, Cost: 0.9944857954978943\n",
      "---Epoch: 158, Cost: 0.9931899905204773\n",
      "---Epoch: 159, Cost: 0.9984114170074463\n",
      "---Epoch: 160, Cost: 1.0020368099212646\n",
      "---Epoch: 161, Cost: 1.0015628337860107\n",
      "---Epoch: 162, Cost: 0.9982925653457642\n",
      "---Epoch: 163, Cost: 0.997238039970398\n",
      "---Epoch: 164, Cost: 0.9954317212104797\n",
      "---Epoch: 165, Cost: 0.9947571754455566\n",
      "---Epoch: 166, Cost: 0.9981889724731445\n",
      "---Epoch: 167, Cost: 1.0023183822631836\n",
      "---Epoch: 168, Cost: 0.9966310262680054\n",
      "---Epoch: 169, Cost: 1.002013087272644\n",
      "---Epoch: 170, Cost: 0.9954574108123779\n",
      "---Epoch: 171, Cost: 1.0001673698425293\n",
      "---Epoch: 172, Cost: 1.0040149688720703\n",
      "---Epoch: 173, Cost: 1.0039993524551392\n",
      "---Epoch: 174, Cost: 0.9941259622573853\n",
      "---Epoch: 175, Cost: 1.0102120637893677\n",
      "---Epoch: 176, Cost: 0.9975112676620483\n",
      "---Epoch: 177, Cost: 1.004825472831726\n",
      "---Epoch: 178, Cost: 1.002105712890625\n",
      "---Epoch: 179, Cost: 0.9896625280380249\n",
      "---Epoch: 180, Cost: 0.9995076656341553\n",
      "---Epoch: 181, Cost: 0.9993611574172974\n",
      "---Epoch: 182, Cost: 1.0011265277862549\n",
      "---Epoch: 183, Cost: 0.9901371598243713\n",
      "---Epoch: 184, Cost: 1.0036600828170776\n",
      "---Epoch: 185, Cost: 1.0012859106063843\n",
      "---Epoch: 186, Cost: 0.9998835921287537\n",
      "---Epoch: 187, Cost: 1.0041258335113525\n",
      "---Epoch: 188, Cost: 0.9912015795707703\n",
      "---Epoch: 189, Cost: 0.9983956813812256\n",
      "---Epoch: 190, Cost: 1.0058810710906982\n",
      "---Epoch: 191, Cost: 1.0009169578552246\n",
      "---Epoch: 192, Cost: 1.00342857837677\n",
      "---Epoch: 193, Cost: 1.0002495050430298\n",
      "---Epoch: 194, Cost: 1.0026174783706665\n",
      "---Epoch: 195, Cost: 0.9956178665161133\n",
      "---Epoch: 196, Cost: 0.9992343187332153\n",
      "---Epoch: 197, Cost: 1.0068453550338745\n",
      "---Epoch: 198, Cost: 0.9963711500167847\n",
      "---Epoch: 199, Cost: 0.9958608746528625\n",
      "---Epoch: 200, Cost: 1.0082695484161377\n",
      "---Epoch: 201, Cost: 0.9955241680145264\n",
      "---Epoch: 202, Cost: 1.0015443563461304\n",
      "---Epoch: 203, Cost: 1.0088555812835693\n",
      "---Epoch: 204, Cost: 1.0020688772201538\n",
      "---Epoch: 205, Cost: 0.9965121150016785\n",
      "---Epoch: 206, Cost: 0.9933481812477112\n",
      "---Epoch: 207, Cost: 0.9947142004966736\n",
      "---Epoch: 208, Cost: 1.002313494682312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch: 209, Cost: 0.9993327856063843\n",
      "---Epoch: 210, Cost: 1.0027765035629272\n",
      "---Epoch: 211, Cost: 1.0009390115737915\n",
      "---Epoch: 212, Cost: 1.0032278299331665\n",
      "---Epoch: 213, Cost: 1.0035709142684937\n",
      "---Epoch: 214, Cost: 1.004224181175232\n",
      "---Epoch: 215, Cost: 0.9951908588409424\n",
      "---Epoch: 216, Cost: 0.9980842471122742\n",
      "---Epoch: 217, Cost: 1.001580834388733\n",
      "---Epoch: 218, Cost: 1.0002614259719849\n",
      "---Epoch: 219, Cost: 0.9982234239578247\n",
      "---Epoch: 220, Cost: 0.999026894569397\n",
      "---Epoch: 221, Cost: 1.005328893661499\n",
      "---Epoch: 222, Cost: 0.996045708656311\n",
      "---Epoch: 223, Cost: 1.0012542009353638\n",
      "---Epoch: 224, Cost: 0.9980506300926208\n",
      "---Epoch: 225, Cost: 0.998698353767395\n",
      "---Epoch: 226, Cost: 1.000641107559204\n",
      "---Epoch: 227, Cost: 0.9963085651397705\n",
      "---Epoch: 228, Cost: 0.9917452931404114\n",
      "---Epoch: 229, Cost: 0.9984707236289978\n",
      "---Epoch: 230, Cost: 0.9991679787635803\n",
      "---Epoch: 231, Cost: 0.9930846095085144\n",
      "---Epoch: 232, Cost: 0.9985942244529724\n",
      "---Epoch: 233, Cost: 1.0009957551956177\n",
      "---Epoch: 234, Cost: 0.9938256144523621\n",
      "---Epoch: 235, Cost: 0.9960102438926697\n",
      "---Epoch: 236, Cost: 0.9978125095367432\n",
      "---Epoch: 237, Cost: 0.9931339025497437\n",
      "---Epoch: 238, Cost: 1.0032213926315308\n",
      "---Epoch: 239, Cost: 0.9897103309631348\n",
      "---Epoch: 240, Cost: 1.0015970468521118\n",
      "---Epoch: 241, Cost: 1.0014199018478394\n",
      "---Epoch: 242, Cost: 1.0049415826797485\n",
      "---Epoch: 243, Cost: 0.9998129606246948\n",
      "---Epoch: 244, Cost: 1.0035579204559326\n",
      "---Epoch: 245, Cost: 0.9984302520751953\n",
      "---Epoch: 246, Cost: 1.00565505027771\n",
      "---Epoch: 247, Cost: 1.0048567056655884\n",
      "---Epoch: 248, Cost: 1.0070596933364868\n",
      "---Epoch: 249, Cost: 1.0051934719085693\n",
      "---Epoch: 250, Cost: 1.0004632472991943\n",
      "---Epoch: 251, Cost: 1.0040889978408813\n",
      "---Epoch: 252, Cost: 0.9910929799079895\n",
      "---Epoch: 253, Cost: 1.0072273015975952\n",
      "---Epoch: 254, Cost: 1.0021837949752808\n",
      "---Epoch: 255, Cost: 0.9959539771080017\n",
      "---Epoch: 256, Cost: 0.99515700340271\n",
      "---Epoch: 257, Cost: 0.9979752898216248\n",
      "---Epoch: 258, Cost: 0.9973099231719971\n",
      "---Epoch: 259, Cost: 0.996167004108429\n",
      "---Epoch: 260, Cost: 1.002323865890503\n",
      "---Epoch: 261, Cost: 0.9919606447219849\n",
      "---Epoch: 262, Cost: 0.9994335174560547\n",
      "---Epoch: 263, Cost: 0.998167097568512\n",
      "---Epoch: 264, Cost: 1.003482460975647\n",
      "---Epoch: 265, Cost: 0.994969367980957\n",
      "---Epoch: 266, Cost: 1.001160979270935\n",
      "---Epoch: 267, Cost: 0.9898734092712402\n",
      "---Epoch: 268, Cost: 1.002873182296753\n",
      "---Epoch: 269, Cost: 0.9937403202056885\n",
      "---Epoch: 270, Cost: 0.9985181093215942\n",
      "---Epoch: 271, Cost: 0.9994687438011169\n",
      "---Epoch: 272, Cost: 1.002516508102417\n",
      "---Epoch: 273, Cost: 0.9989809989929199\n",
      "---Epoch: 274, Cost: 1.0015581846237183\n",
      "---Epoch: 275, Cost: 0.9896224737167358\n",
      "---Epoch: 276, Cost: 1.0026464462280273\n",
      "---Epoch: 277, Cost: 0.9990246891975403\n",
      "---Epoch: 278, Cost: 1.0023176670074463\n",
      "---Epoch: 279, Cost: 0.9917901754379272\n",
      "---Epoch: 280, Cost: 0.9986346364021301\n",
      "---Epoch: 281, Cost: 1.0028761625289917\n",
      "---Epoch: 282, Cost: 0.9923607707023621\n",
      "---Epoch: 283, Cost: 1.007571816444397\n",
      "---Epoch: 284, Cost: 1.0011836290359497\n",
      "---Epoch: 285, Cost: 1.0048702955245972\n",
      "---Epoch: 286, Cost: 0.9982312321662903\n",
      "---Epoch: 287, Cost: 0.9990929961204529\n",
      "---Epoch: 288, Cost: 0.9947243928909302\n",
      "---Epoch: 289, Cost: 0.9975844025611877\n",
      "---Epoch: 290, Cost: 1.0019556283950806\n",
      "---Epoch: 291, Cost: 1.003659725189209\n",
      "---Epoch: 292, Cost: 0.9986621737480164\n",
      "---Epoch: 293, Cost: 0.996735155582428\n",
      "---Epoch: 294, Cost: 1.0065573453903198\n",
      "---Epoch: 295, Cost: 1.0027472972869873\n",
      "---Epoch: 296, Cost: 1.008069396018982\n",
      "---Epoch: 297, Cost: 1.0057153701782227\n",
      "---Epoch: 298, Cost: 1.0117526054382324\n",
      "---Epoch: 299, Cost: 1.003056526184082\n",
      "---Epoch: 300, Cost: 1.004220724105835\n",
      "---Epoch: 301, Cost: 1.0036207437515259\n",
      "---Epoch: 302, Cost: 1.001033067703247\n",
      "---Epoch: 303, Cost: 0.9923657774925232\n",
      "---Epoch: 304, Cost: 1.004040002822876\n",
      "---Epoch: 305, Cost: 1.0039256811141968\n",
      "---Epoch: 306, Cost: 1.0063607692718506\n",
      "---Epoch: 307, Cost: 1.0022165775299072\n",
      "---Epoch: 308, Cost: 0.995782732963562\n",
      "---Epoch: 309, Cost: 0.994717001914978\n",
      "---Epoch: 310, Cost: 1.0018278360366821\n",
      "---Epoch: 311, Cost: 1.003550410270691\n",
      "---Epoch: 312, Cost: 0.9990546703338623\n",
      "---Epoch: 313, Cost: 1.0025485754013062\n",
      "---Epoch: 314, Cost: 1.0065032243728638\n",
      "---Epoch: 315, Cost: 1.0071940422058105\n",
      "---Epoch: 316, Cost: 0.9991574287414551\n",
      "---Epoch: 317, Cost: 0.9929455518722534\n",
      "---Epoch: 318, Cost: 1.0001542568206787\n",
      "---Epoch: 319, Cost: 1.0026708841323853\n",
      "---Epoch: 320, Cost: 0.9981335997581482\n",
      "---Epoch: 321, Cost: 0.9948893785476685\n",
      "---Epoch: 322, Cost: 0.9945899844169617\n",
      "---Epoch: 323, Cost: 1.0059376955032349\n",
      "---Epoch: 324, Cost: 0.9925450086593628\n",
      "---Epoch: 325, Cost: 0.9992879033088684\n",
      "---Epoch: 326, Cost: 1.0047067403793335\n",
      "---Epoch: 327, Cost: 1.0025004148483276\n",
      "---Epoch: 328, Cost: 1.0013426542282104\n",
      "---Epoch: 329, Cost: 1.0072627067565918\n",
      "---Epoch: 330, Cost: 0.9989709258079529\n",
      "---Epoch: 331, Cost: 0.9939125180244446\n",
      "---Epoch: 332, Cost: 1.002947449684143\n",
      "---Epoch: 333, Cost: 0.9969897866249084\n",
      "---Epoch: 334, Cost: 0.9971394538879395\n",
      "---Epoch: 335, Cost: 1.00559401512146\n",
      "---Epoch: 336, Cost: 0.9992510676383972\n",
      "---Epoch: 337, Cost: 1.001152753829956\n",
      "---Epoch: 338, Cost: 1.0002542734146118\n",
      "---Epoch: 339, Cost: 0.9943398237228394\n",
      "---Epoch: 340, Cost: 0.9950960278511047\n",
      "---Epoch: 341, Cost: 1.0047212839126587\n",
      "---Epoch: 342, Cost: 1.0094658136367798\n",
      "---Epoch: 343, Cost: 0.9954973459243774\n",
      "---Epoch: 344, Cost: 1.0002115964889526\n",
      "---Epoch: 345, Cost: 1.0047836303710938\n",
      "---Epoch: 346, Cost: 0.9999174475669861\n",
      "---Epoch: 347, Cost: 1.0068117380142212\n",
      "---Epoch: 348, Cost: 0.9984092116355896\n",
      "---Epoch: 349, Cost: 0.9960939288139343\n",
      "---Epoch: 350, Cost: 0.9884493947029114\n",
      "---Epoch: 351, Cost: 1.0010080337524414\n",
      "---Epoch: 352, Cost: 1.0052101612091064\n",
      "---Epoch: 353, Cost: 1.0016167163848877\n",
      "---Epoch: 354, Cost: 1.0050146579742432\n",
      "---Epoch: 355, Cost: 0.9989109635353088\n",
      "---Epoch: 356, Cost: 1.0037331581115723\n",
      "---Epoch: 357, Cost: 1.000759482383728\n",
      "---Epoch: 358, Cost: 1.0003217458724976\n",
      "---Epoch: 359, Cost: 1.005450963973999\n",
      "---Epoch: 360, Cost: 0.9906980991363525\n",
      "---Epoch: 361, Cost: 1.0103559494018555\n",
      "---Epoch: 362, Cost: 0.999157190322876\n",
      "---Epoch: 363, Cost: 1.0006511211395264\n",
      "---Epoch: 364, Cost: 0.9998109340667725\n",
      "---Epoch: 365, Cost: 0.9941370487213135\n",
      "---Epoch: 366, Cost: 1.0021764039993286\n",
      "---Epoch: 367, Cost: 1.004624843597412\n",
      "---Epoch: 368, Cost: 1.0027008056640625\n",
      "---Epoch: 369, Cost: 0.9985564351081848\n",
      "---Epoch: 370, Cost: 1.0042400360107422\n",
      "---Epoch: 371, Cost: 1.0035924911499023\n",
      "---Epoch: 372, Cost: 1.0014013051986694\n",
      "---Epoch: 373, Cost: 0.9944061040878296\n",
      "---Epoch: 374, Cost: 1.0005757808685303\n",
      "---Epoch: 375, Cost: 0.9996075630187988\n",
      "---Epoch: 376, Cost: 0.991209864616394\n",
      "---Epoch: 377, Cost: 0.9924002885818481\n",
      "---Epoch: 378, Cost: 0.9885568618774414\n",
      "---Epoch: 379, Cost: 1.0016508102416992\n",
      "---Epoch: 380, Cost: 0.9976843595504761\n",
      "---Epoch: 381, Cost: 1.0070985555648804\n",
      "---Epoch: 382, Cost: 1.0065512657165527\n",
      "---Epoch: 383, Cost: 1.0004210472106934\n",
      "---Epoch: 384, Cost: 1.0005993843078613\n",
      "---Epoch: 385, Cost: 1.0017893314361572\n",
      "---Epoch: 386, Cost: 1.0028445720672607\n",
      "---Epoch: 387, Cost: 0.9989510774612427\n",
      "---Epoch: 388, Cost: 0.9990319013595581\n",
      "---Epoch: 389, Cost: 1.0004929304122925\n",
      "---Epoch: 390, Cost: 0.9963168501853943\n",
      "---Epoch: 391, Cost: 0.9990050196647644\n",
      "---Epoch: 392, Cost: 0.9995145797729492\n",
      "---Epoch: 393, Cost: 1.0046403408050537\n",
      "---Epoch: 394, Cost: 0.9982876777648926\n",
      "---Epoch: 395, Cost: 0.9941310882568359\n",
      "---Epoch: 396, Cost: 0.9930556416511536\n",
      "---Epoch: 397, Cost: 0.9970257878303528\n",
      "---Epoch: 398, Cost: 1.004522442817688\n",
      "---Epoch: 399, Cost: 1.003251075744629\n",
      "---Epoch: 400, Cost: 0.9958521723747253\n",
      "---Epoch: 401, Cost: 0.9995189905166626\n",
      "---Epoch: 402, Cost: 1.0023962259292603\n",
      "---Epoch: 403, Cost: 1.001898169517517\n",
      "---Epoch: 404, Cost: 0.9946679472923279\n",
      "---Epoch: 405, Cost: 1.0005507469177246\n",
      "---Epoch: 406, Cost: 0.9950757622718811\n",
      "---Epoch: 407, Cost: 1.000905156135559\n",
      "---Epoch: 408, Cost: 1.0116610527038574\n",
      "---Epoch: 409, Cost: 0.9955044388771057\n",
      "---Epoch: 410, Cost: 0.9907069802284241\n",
      "---Epoch: 411, Cost: 1.0007327795028687\n",
      "---Epoch: 412, Cost: 0.9973480701446533\n",
      "---Epoch: 413, Cost: 1.001698613166809\n",
      "---Epoch: 414, Cost: 0.9995899200439453\n",
      "---Epoch: 415, Cost: 0.9963845014572144\n",
      "---Epoch: 416, Cost: 1.002378225326538\n",
      "---Epoch: 417, Cost: 1.0002315044403076\n",
      "---Epoch: 418, Cost: 0.9991447925567627\n",
      "---Epoch: 419, Cost: 1.0058995485305786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch: 420, Cost: 0.9955219030380249\n",
      "---Epoch: 421, Cost: 1.006416916847229\n",
      "---Epoch: 422, Cost: 1.003395676612854\n",
      "---Epoch: 423, Cost: 0.9960865378379822\n",
      "---Epoch: 424, Cost: 1.003659725189209\n",
      "---Epoch: 425, Cost: 1.002113699913025\n",
      "---Epoch: 426, Cost: 0.9989617466926575\n",
      "---Epoch: 427, Cost: 1.0020192861557007\n",
      "---Epoch: 428, Cost: 1.0022387504577637\n",
      "---Epoch: 429, Cost: 1.003105640411377\n",
      "---Epoch: 430, Cost: 0.9993565678596497\n",
      "---Epoch: 431, Cost: 0.9936535358428955\n",
      "---Epoch: 432, Cost: 0.9910346269607544\n",
      "---Epoch: 433, Cost: 1.0010002851486206\n",
      "---Epoch: 434, Cost: 0.9973610639572144\n",
      "---Epoch: 435, Cost: 1.0066142082214355\n",
      "---Epoch: 436, Cost: 1.006606101989746\n",
      "---Epoch: 437, Cost: 0.994981586933136\n",
      "---Epoch: 438, Cost: 0.9986860156059265\n",
      "---Epoch: 439, Cost: 0.994005560874939\n",
      "---Epoch: 440, Cost: 1.0052363872528076\n",
      "---Epoch: 441, Cost: 0.9953849911689758\n",
      "---Epoch: 442, Cost: 0.9964863061904907\n",
      "---Epoch: 443, Cost: 0.9992861151695251\n",
      "---Epoch: 444, Cost: 1.0032850503921509\n",
      "---Epoch: 445, Cost: 0.9915792346000671\n",
      "---Epoch: 446, Cost: 0.9970993995666504\n",
      "---Epoch: 447, Cost: 0.9961335062980652\n",
      "---Epoch: 448, Cost: 1.0022165775299072\n",
      "---Epoch: 449, Cost: 0.9992286562919617\n",
      "---Epoch: 450, Cost: 0.9971781373023987\n",
      "---Epoch: 451, Cost: 1.0014528036117554\n",
      "---Epoch: 452, Cost: 1.0068503618240356\n",
      "---Epoch: 453, Cost: 1.0046030282974243\n",
      "---Epoch: 454, Cost: 0.9957782626152039\n",
      "---Epoch: 455, Cost: 0.9968506097793579\n",
      "---Epoch: 456, Cost: 1.0027055740356445\n",
      "---Epoch: 457, Cost: 0.9998370409011841\n",
      "---Epoch: 458, Cost: 0.999247670173645\n",
      "---Epoch: 459, Cost: 1.000099539756775\n",
      "---Epoch: 460, Cost: 1.0069656372070312\n",
      "---Epoch: 461, Cost: 0.9950781464576721\n",
      "---Epoch: 462, Cost: 1.0047411918640137\n",
      "---Epoch: 463, Cost: 1.0021735429763794\n",
      "---Epoch: 464, Cost: 1.0060384273529053\n",
      "---Epoch: 465, Cost: 1.0038862228393555\n",
      "---Epoch: 466, Cost: 1.0003260374069214\n",
      "---Epoch: 467, Cost: 1.0051136016845703\n",
      "---Epoch: 468, Cost: 1.0060367584228516\n",
      "---Epoch: 469, Cost: 1.002599835395813\n",
      "---Epoch: 470, Cost: 1.0017738342285156\n",
      "---Epoch: 471, Cost: 1.0014792680740356\n",
      "---Epoch: 472, Cost: 1.0068861246109009\n",
      "---Epoch: 473, Cost: 0.9969504475593567\n",
      "---Epoch: 474, Cost: 0.9962825179100037\n",
      "---Epoch: 475, Cost: 1.0051320791244507\n",
      "---Epoch: 476, Cost: 1.0031274557113647\n",
      "---Epoch: 477, Cost: 0.9973986744880676\n",
      "---Epoch: 478, Cost: 1.002397060394287\n",
      "---Epoch: 479, Cost: 1.001168131828308\n",
      "---Epoch: 480, Cost: 0.9922806024551392\n",
      "---Epoch: 481, Cost: 0.9972307085990906\n",
      "---Epoch: 482, Cost: 0.997265100479126\n",
      "---Epoch: 483, Cost: 0.9994632601737976\n",
      "---Epoch: 484, Cost: 0.998971164226532\n",
      "---Epoch: 485, Cost: 1.005239725112915\n",
      "---Epoch: 486, Cost: 0.9997105598449707\n",
      "---Epoch: 487, Cost: 1.0042880773544312\n",
      "---Epoch: 488, Cost: 0.9889108538627625\n",
      "---Epoch: 489, Cost: 1.000738263130188\n",
      "---Epoch: 490, Cost: 1.0014485120773315\n",
      "---Epoch: 491, Cost: 0.9975802898406982\n",
      "---Epoch: 492, Cost: 0.9925490617752075\n",
      "---Epoch: 493, Cost: 1.003334641456604\n",
      "---Epoch: 494, Cost: 0.99495929479599\n",
      "---Epoch: 495, Cost: 0.9990628957748413\n",
      "---Epoch: 496, Cost: 1.0020465850830078\n",
      "---Epoch: 497, Cost: 0.9935925006866455\n",
      "---Epoch: 498, Cost: 1.0038995742797852\n",
      "---Epoch: 499, Cost: 1.0018483400344849\n",
      "Evaluating on sampled gaussians...\n",
      "---Batch: 0, Cost: 0.9976402521133423\n",
      "---Batch: 1, Cost: 1.0020866394042969\n",
      "---Batch: 2, Cost: 0.996889591217041\n",
      "---Batch: 3, Cost: 1.000609040260315\n",
      "---Batch: 4, Cost: 0.9917024970054626\n",
      "---Batch: 5, Cost: 0.9991300106048584\n",
      "---Batch: 6, Cost: 0.9996742010116577\n",
      "---Batch: 7, Cost: 1.0042071342468262\n",
      "---Batch: 8, Cost: 1.0065863132476807\n",
      "---Batch: 9, Cost: 1.0059175491333008\n",
      "Average test cost: 1.0004443228244781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0004443228244781"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neural_net(params={}, m=1, mode='train', verbose=False):\n",
    "    '''m: Dimension of x0 (default =1)\n",
    "       \n",
    "       params: parameter dictionary that contains\n",
    "       num_batches: number of batches \n",
    "       batch_size: number of samples per batch\n",
    "       sigma_x0: standard deviation of x0\n",
    "       sigma_z: standard deviation of noise\n",
    "       optimizer: the optimizer used to minimize cost\n",
    "    '''\n",
    "    #Placeholders for inputs\n",
    "    x0 = tf.placeholder(tf.float32, [None, m])\n",
    "    z = tf.placeholder(tf.float32, [None, m])\n",
    "\n",
    "\n",
    "    #The layers\n",
    "   \n",
    "    x1 = tf.layers.dense(inputs=x0, units=1, activation=None , use_bias=True, name = 'layer1')  #Linear activation\n",
    "    y1 = x1 + z\n",
    "    \n",
    "    with tf.variable_scope('layer1', reuse=True):\n",
    "        w1 = tf.get_variable('kernel')\n",
    "        b1 = tf.get_variable('bias')\n",
    "    \n",
    "    #Define loss function    \n",
    "    cost = tf.reduce_mean(tf.reduce_mean((y1-1)**2,axis=1))\n",
    "\n",
    "    #Learning rate and optimizer\n",
    "    optimizer_function = params['optimizer_function']\n",
    "    learning_rate = params['learning_rate']\n",
    "    adaptive_learning_rate = tf.placeholder_with_default(learning_rate, [])\n",
    "    optimizer = optimizer_function(adaptive_learning_rate).minimize(cost)\n",
    "            \n",
    "   \n",
    "    tf.summary.scalar(\"Cost\", cost)\n",
    "    tf.summary.scalar(\"w1\", tf.norm(w1))\n",
    "    tf.summary.scalar(\"b1\", tf.norm(b1))\n",
    "    merged_summary_op = tf.summary.merge_all()   \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "            uniq_id = \"/tmp/tensorboard-layers-api/basic2\" + uuid.uuid1().__str__()[:6]\n",
    "            summary_writer = tf.summary.FileWriter(uniq_id, graph=tf.get_default_graph())\n",
    "            \n",
    "            if verbose is True:\n",
    "                print(\"Training...\")\n",
    "           \n",
    "        \n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op) \n",
    "            \n",
    "            batch_size = params['batch_size']\n",
    "            sigma_x0 = params['sigma_x0']\n",
    "            sigma_z = params['sigma_z']\n",
    "            max_epochs = params['max_epochs']\n",
    "            \n",
    "            \n",
    "           \n",
    "            '''Train the nn on training set constructed by sampling x0 and z independently from gaussian distributions\\\n",
    "            with means 0 and standard deviations sigma_x0 and sigma_z respectively'''\n",
    "            #WARNING: Can only be used when marginals along dimensions are independent \n",
    "            train_costs = np.zeros((max_epochs,1))\n",
    "            for i in range(max_epochs): #Splitting into multiple batches so as to not run into memory issues\n",
    "                batch_x0 = np.random.normal(loc=np.zeros((m,)), scale = sigma_x0, size=[batch_size,m])\n",
    "                batch_z = np.random.normal(loc=np.zeros((m,)), scale = sigma_z, size=[batch_size,m])\n",
    "\n",
    "                _,w1_tmp,b1_tmp,batch_cost,summary = sess.run([optimizer,w1,b1,cost,merged_summary_op], feed_dict = {x0:batch_x0, z:batch_z})\n",
    "                train_costs[i] = batch_cost\n",
    "                summary_writer.add_summary(summary, i)\n",
    "           \n",
    "              \n",
    "                if verbose is True:\n",
    "                    print(\"---Epoch: {}, Cost: {}\".format(i,batch_cost))\n",
    "#             return train_costs\n",
    "\n",
    "#         if mode == 'evaluate_sampled':\n",
    "            if verbose is True:\n",
    "                print(\"Evaluating on sampled gaussians...\")\n",
    "            num_batches = params['num_batches']\n",
    "            batch_size = params['batch_size']\n",
    "            sigma_x0 = params['sigma_x0']\n",
    "            sigma_z = params['sigma_z']\n",
    "            '''Evaluate the nn on test set constructed by sampling x0 and z independently from gaussian distributions\\\n",
    "            with means 0 and standard deviations sigma_x0 and sigma_z respectively'''\n",
    "            #WARNING: Can only be used when marginals along dimensions are independent \n",
    "            test_costs = np.zeros((num_batches,1))\n",
    "            for i in range(num_batches): #Splitting into multiple batches so as to not run into memory issues\n",
    "                batch_x0 = np.random.normal(loc=np.zeros((m,)), scale = sigma_x0, size=[batch_size,m])\n",
    "                batch_z = np.random.normal(loc=np.zeros((m,)), scale = sigma_z, size=[batch_size,m])\n",
    "\n",
    "                batch_cost = sess.run(cost, feed_dict = {x0:batch_x0, z:batch_z})\n",
    "                test_costs[i] = batch_cost\n",
    "                if verbose is True:\n",
    "                    print(\"---Batch: {}, Cost: {}\".format(i,batch_cost))\n",
    "\n",
    "            avg_test_cost = float(np.mean(test_costs, axis = 0))\n",
    "            if verbose is True:\n",
    "                print(\"Average test cost: {}\".format(avg_test_cost))\n",
    "            return avg_test_cost\n",
    "\n",
    "\n",
    "#Evaluate on sampled gaussians\n",
    "params = {'num_batches':10, 'batch_size':100000, 'sigma_x0':2, 'sigma_z':1,\\\n",
    "          'optimizer_function':tf.train.AdamOptimizer, 'learning_rate':1, 'max_epochs':500}\n",
    "\n",
    "neural_net(params=params, mode = 'train', verbose = True)\n",
    "# neural_net(params=params, mode = 'evaluate_sampled', verbose = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.         -2.33333333 -1.66666667 -1.         -0.33333333  0.33333333\n",
      "  1.          1.66666667  2.33333333  3.        ]\n",
      "[0.00443185 0.02622189 0.09947714 0.24197072 0.37738323 0.37738323\n",
      " 0.24197072 0.09947714 0.02622189 0.00443185]\n"
     ]
    }
   ],
   "source": [
    " # Test over a continuous range of X\n",
    "    \n",
    "num_x0_points = 10\n",
    "x_stddev = 1\n",
    "x0_test = np.linspace(-3 * x_stddev, 3 * x_stddev, num=num_x0_points)  \n",
    "x0_distribution = scipy.stats.norm(loc=0.0, scale=x_stddev)\n",
    "print(x0_test)\n",
    "print(x0_distribution.pdf(x0_test))\n",
    "#       total_density = 0.0\n",
    "#       for i in range(num_x0_points):\n",
    "#           u1t, u2t, wits_cost_t  = 0, 0, 0\n",
    "          \n",
    "\n",
    "#           for _ in range(test_averaging):\n",
    "#             u1tmp, u2tmp, wits_cost_tmp = sess.run(\n",
    "#                   [u1, u2, wits_cost],\n",
    "#                   feed_dict={x0: x0_test[i].reshape((1, 1)), x1: x1_test[i].reshape((1, 1)),\n",
    "#                   z: z_test[i].reshape((1, 1)), y2: y2_test[i].reshape((1, 1))\n",
    "#             })\n",
    "#             wits_cost_t += wits_cost_tmp\n",
    "#             u1t += u1tmp\n",
    "#             u2t += u2tmp\n",
    "            \n",
    "#           x0_density = x0_distribution.pdf(x0_test[i])\n",
    "#           total_density += x0_density\n",
    "#           scaled_wits_cost = wits_cost_t * x0_density\n",
    "#           wits_cost_test[0, i] = scaled_wits_cost / test_averaging\n",
    "#           u1_test[0, i] = u1t / test_averaging\n",
    "#           u2_test[0, i] = -u2t / test_averaging\n",
    "#           #x1_test[0, i] = x1t / test_averaging\n",
    "#       total_cost = np.sum(wits_cost_test) / total_density\n",
    "#       print('Mean loss over {} points is {}'.format(num_x0_points, total_cost))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
